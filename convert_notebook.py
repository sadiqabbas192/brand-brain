
import json
import os

# Load v1.5
with open('brand_brain_v1.5.ipynb', 'r', encoding='utf-8') as f:
    nb = json.load(f)

# Helper to find cell by unique string
def find_cell_index(notebook, search_string):
    for i, cell in enumerate(notebook['cells']):
        source = "".join(cell['source'])
        if search_string in source:
            return i
    return -1

# 1. Update Header
header_idx = 0 # Assuming first cell
nb['cells'][header_idx]['source'][0] = "# **Brand Brain v1.6 - Memory Governance Upgrade**\n"

# 2. Update retrieve_context (Section B)
retrieve_idx = find_cell_index(nb, "def retrieve_context")
if retrieve_idx != -1:
    print(f"Found retrieve_context at cell {retrieve_idx}")
    # Replace the Code
    new_retrieve_code = [
        "# 7. Retrieval & Validation Logic (v1.6)\n",
        "\n",
        "def retrieve_context(brand_name_str: str, query: str, vector_type: str = \"brand_voice\", top_k: int = 3):\n",
        "    if brand_name_str == \"wh_india_001\":\n",
        "        brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_name_str))\n",
        "        org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
        "    else:\n",
        "        brand_uuid = brand_name_str\n",
        "        org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
        "\n",
        "    print(f\"\\nðŸ”Ž Querying Brand {brand_name_str} (UUID: {brand_uuid}) [{vector_type}]: '{query}'\")\n",
        "    \n",
        "    # New SDK for Query Embedding\n",
        "    try:\n",
        "        query_embedding_result = client.models.embed_content(\n",
        "            model=\"gemini-embedding-001\",\n",
        "            contents=query,\n",
        "            config={\n",
        "                'output_dimensionality': 768,\n",
        "                'task_type': 'RETRIEVAL_QUERY'\n",
        "            }\n",
        "        )\n",
        "        query_embedding = query_embedding_result.embeddings[0].values\n",
        "    except Exception as e:\n",
        "        print(f\"Embedding Error during retrieval: {e}\")\n",
        "        return []\n",
        "    \n",
        "    namespace = f\"{org_id}:{brand_uuid}:{vector_type}\"\n",
        "    index_name = \"brand-brain-index\"\n",
        "    idx = pc.Index(index_name)\n",
        "    \n",
        "    # Retrieve more candidates to allow for filtering\n",
        "    results = idx.query(\n",
        "        vector=query_embedding,\n",
        "        top_k=top_k * 3,\n",
        "        namespace=namespace,\n",
        "        include_metadata=True\n",
        "    )\n",
        "    \n",
        "    if not results['matches']:\n",
        "        print(\"   âš ï¸ No matches found in namespace:\", namespace)\n",
        "        return []\n",
        "        \n",
        "    conn = get_db_connection()\n",
        "    cur = conn.cursor()\n",
        "    \n",
        "    retrieved_docs = []\n",
        "    chunk_ids = [m['id'] for m in results['matches']]\n",
        "    \n",
        "    if chunk_ids:\n",
        "        placeholders = ', '.join(['%s'] * len(chunk_ids))\n",
        "        # [MODIFIED v1.6] Join with brand_assets to get confidence\n",
        "        query_sql = f\"\"\"\n",
        "            SELECT c.chunk_id, c.content, c.vector_type, a.confidence \n",
        "            FROM brand_chunks c\n",
        "            JOIN brand_assets a ON c.asset_id = a.asset_id\n",
        "            WHERE c.chunk_id IN ({placeholders})\n",
        "        \"\"\"\n",
        "        cur.execute(query_sql, tuple(chunk_ids))\n",
        "        rows = cur.fetchall()\n",
        "        \n",
        "        # Create lookup\n",
        "        db_map = {row[0]: {\"content\": row[1], \"confidence\": row[3]} for row in rows}\n",
        "        \n",
        "        valid_candidates = []\n",
        "        \n",
        "        for match in results['matches']:\n",
        "            c_id = match['id']\n",
        "            score = match['score']\n",
        "            if c_id not in db_map: \n",
        "                continue\n",
        "                \n",
        "            data = db_map[c_id]\n",
        "            confidence = data['confidence'] or 'inferred' \n",
        "            \n",
        "            # [RULE] Exclude Deprecated\n",
        "            if confidence == 'deprecated':\n",
        "                continue\n",
        "                \n",
        "            # [RULE] Prioritize: approved > reviewed > inferred\n",
        "            priority_score = 1\n",
        "            if confidence == 'approved': priority_score = 3\n",
        "            elif confidence == 'reviewed': priority_score = 2\n",
        "            \n",
        "            valid_candidates.append({\n",
        "                \"content\": data['content'],\n",
        "                \"score\": score,\n",
        "                \"confidence\": confidence,\n",
        "                \"priority\": priority_score\n",
        "            })\n",
        "            \n",
        "        # Sort by Priority (desc), then Similarity Score (desc)\n",
        "        valid_candidates.sort(key=lambda x: (x['priority'], x['score']), reverse=True)\n",
        "        \n",
        "        # Take top_k\n",
        "        final_results = valid_candidates[:top_k]\n",
        "        \n",
        "        for i, res in enumerate(final_results):\n",
        "            print(f\"   [{i+1}] [{res['confidence'].upper()}] Score: {res['score']:.4f} | Content: {res['content'][:100]}...\")\n",
        "            retrieved_docs.append(res)\n",
        "            \n",
        "    cur.close()\n",
        "    conn.close()\n",
        "    return retrieved_docs\n",
        "\n",
        "# 8. Run Validation Tests\n",
        "def run_validation():\n",
        "    print(\"\\n--- TEST 1: Westinghouse Brand Voice ---\")\n",
        "    retrieve_context(\"wh_india_001\", \"Describe our design philosophy.\", vector_type=\"brand_voice\")\n",
        "    retrieve_context(\"wh_india_001\", \"Who are we fighting against?\", vector_type=\"strategy\")\n",
        "    print(\"\\n--- TEST 3: Isolation / Irrelevant Query ---\")\n",
        "    retrieve_context(\"wh_india_001\", \"How to be cheap and loud?\", vector_type=\"brand_voice\")\n",
        "run_validation()"
    ]
    nb['cells'][retrieve_idx]['source'] = new_retrieve_code

# 3. Update ingest_single_asset (Section A)
ingest_idx = find_cell_index(nb, "def ingest_single_asset")
if ingest_idx != -1:
    print(f"Found ingest_single_asset at cell {ingest_idx}")
    source = nb['cells'][ingest_idx]['source']
    
    # We want to find the INSERT INTO brand_assets line and ensure it includes confidence
    # It is roughly: "INSERT INTO brand_assets (asset_id, ... source) VALUES ..."
    # We will replace the whole function to be safe.
    
    # Reconstructing the cell content with the fix
    new_ingest_code = [
        "# SECTION A: Grounding-Assisted Ingestion (Type B Memory)\n",
        "\n",
        "def grounding_assisted_ingest(brand_data: Dict, target_vector_type=\"strategy\"):\n",
        "    \"\"\"\n",
        "    Uses Gemini Google Search tools to extract ONLY evergreen brand philosophy.\n",
        "    Enforces strict prompt filters.\n",
        "    Stores as Type B memory with version tags.\n",
        "    \"\"\"\n",
        "    brand_name = brand_data['name']\n",
        "    website = brand_data.get('website', '')\n",
        "    \n",
        "    print(f\"\\nðŸŒ Starting Grounding-Assisted Ingestion for {brand_name}...\")\n",
        "\n",
        "    # 1. Define Prompt with HARD FILTERS\n",
        "    prompt = f\"\"\"\n",
        "    You are a Brand Identity Expert.\n",
        "    SEARCH for \"{brand_name} brand philosophy design principles manifesto\".\n",
        "    Also check the provided website: {website}\n",
        "    EXTRACT ONLY evergreen, high-level brand identity content.\n",
        "    âŒ STRICTLY IGNORE:\n",
        "    - pricing, offers, discounts\n",
        "    - launches, new arrivals\n",
        "    - comparisons, awards\n",
        "    - timelines, history dates\n",
        "    - \"latest\", \"new\", \"recent\", \"2024\", \"2025\"\n",
        "    âœ… EXTRACT ONLY:\n",
        "    - philosophy & mission\n",
        "    - design principles\n",
        "    - core values\n",
        "    - identity statements\n",
        "    RETURN JSON in this format:\n",
        "    {{\n",
        "      \"brand_philosophy\": \"string\",\n",
        "      \"design_principles\": \"string\",\n",
        "      \"positioning\": \"string\"\n",
        "    }}\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 2. Call Gemini with Search Tool\n",
        "        response = client.models.generate_content(\n",
        "            model=\"gemini-2.5-flash\", # Using Flash for speed/tools\n",
        "            contents=prompt,\n",
        "            config=types.GenerateContentConfig(\n",
        "                tools=[types.Tool(google_search=types.GoogleSearchRetrieval)]\n",
        "            )\n",
        "        )\n",
        "        # 3. Robust JSON Parsing (Manual)\n",
        "        text = response.text.strip()\n",
        "        if text.startswith(\"```json\"):\n",
        "            text = text[7:]\n",
        "        elif text.startswith(\"```\"):\n",
        "            text = text[3:]\n",
        "        if text.endswith(\"```\"):\n",
        "            text = text[:-3]\n",
        "            \n",
        "        extracted_data = json.loads(text.strip())\n",
        "        print(f\"   âœ… Extracted Grounded Data: {list(extracted_data.keys())}\")\n",
        "\n",
        "        # 3. Format as Assets (Type B)\n",
        "        combined_text = f\"Philosophy: {extracted_data.get('brand_philosophy', '')}\\n\"\n",
        "        combined_text += f\"Design Principles: {extracted_data.get('design_principles', '')}\\n\"\n",
        "        combined_text += f\"Positioning: {extracted_data.get('positioning', '')}\"\n",
        "\n",
        "        grounded_asset = {\n",
        "            \"asset_id\": str(uuid.uuid4()),\n",
        "            \"brand_id\": brand_data['brandId'],\n",
        "            \"asset_type\": \"guideline\",\n",
        "            \"vector_type\": target_vector_type,\n",
        "            \"source_field\": \"grounding_assisted_ingestion\",\n",
        "            \"content\": combined_text\n",
        "        }\n",
        "\n",
        "        # 4. Store & Embed (Reusing ingestion logic pattern)\n",
        "        ingest_single_asset(grounded_asset, brand_data) \n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Grounding Ingestion Failed: {e}\")\n",
        "\n",
        "def ingest_single_asset(asset: Dict, brand_data: Dict):\n",
        "    \"\"\"Helper to ingest a single constructed asset.\"\"\"\n",
        "    brand_id_str = brand_data['brandId']\n",
        "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
        "    org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
        "    \n",
        "    conn = get_db_connection()\n",
        "    cur = conn.cursor()\n",
        "    idx = pc.Index(\"brand-brain-index\")\n",
        "\n",
        "    try:\n",
        "        # Store Asset in Postgres\n",
        "        source_tag = f\"{asset['source_field']} | v1.5 | confidence:inferred\"\n",
        "        \n",
        "        # [MODIFIED v1.6] Explicitly inserting confidence='inferred'\n",
        "        cur.execute(\n",
        "            \"INSERT INTO brand_assets (asset_id, brand_id, asset_type, raw_text, source, confidence) VALUES (%s, %s, %s, %s, %s, %s) ON CONFLICT (asset_id) DO NOTHING\",\n",
        "            (asset['asset_id'], brand_uuid, asset['asset_type'], asset['content'], source_tag, 'inferred')\n",
        "        )\n",
        "\n",
        "        chunks = chunk_text(asset['content'])\n",
        "        for chunk_text_content in chunks:\n",
        "            chunk_id = str(uuid.uuid4())\n",
        "            embedding_id = str(uuid.uuid4())\n",
        "            vector = generate_embedding(chunk_text_content)\n",
        "            \n",
        "            if not vector: continue\n",
        "            \n",
        "            # Check vector type or default\n",
        "            vt = asset.get('vector_type', 'strategy')\n",
        "\n",
        "            cur.execute(\n",
        "                \"INSERT INTO brand_chunks (chunk_id, asset_id, brand_id, vector_type, content, token_count) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
        "                (chunk_id, asset['asset_id'], brand_uuid, vt, chunk_text_content, len(chunk_text_content.split()))\n",
        "            )\n",
        "            \n",
        "            namespace = f\"{org_id}:{brand_uuid}:{vt}\"\n",
        "            \n",
        "            cur.execute(\n",
        "                 \"INSERT INTO embeddings (embedding_id, chunk_id, brand_id, vector_type, namespace, model) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
        "                (embedding_id, chunk_id, brand_uuid, vt, namespace, \"gemini-embedding-001\")\n",
        "            )\n",
        "            \n",
        "            idx.upsert(\n",
        "                vectors=[(chunk_id, vector, {\"source\": source_tag})],\n",
        "                namespace=namespace\n",
        "            )\n",
        "        \n",
        "        conn.commit()\n",
        "        print(f\"   âœ… Successfully stored Type B memory for {brand_data['name']}\")\n",
        "    finally:\n",
        "        cur.close()\n",
        "        conn.close()\n",
        "    print(\"âœ… Section A: Grounding-Assisted Ingestion Implementation Ready (v1.6)\")"
    ]
    nb['cells'][ingest_idx]['source'] = new_ingest_code

# 4. Append Section C and D (New Cells)
# We find where to append. Before 'def ephemeral_live_fetch'? 
ephemeral_idx = find_cell_index(nb, "def ephemeral_live_fetch")

if ephemeral_idx != -1:
    print(f"Inserting new sections before cell {ephemeral_idx}")
    
    new_cells = [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": ["## ðŸ”¹ SECTION C â€” Memory Review Functions (v1.6)\n"]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SECTION C: Memory Review Functions\n",
                "\n",
                "def list_inferred_assets(brand_id_str: str):\n",
                "    print(f\"\\nðŸ“‹ Listing Inferred Assets for {brand_id_str}...\")\n",
                "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor(cursor_factory=RealDictCursor)\n",
                "    cur.execute(\"SELECT asset_id, asset_type, raw_text, source, confidence FROM brand_assets WHERE brand_id = %s AND confidence = 'inferred'\", (brand_uuid,))\n",
                "    rows = cur.fetchall()\n",
                "    cur.close()\n",
                "    conn.close()\n",
                "    for r in rows:\n",
                "        print(f\"   [ID: {r['asset_id']}] {r['raw_text'][:50]}... (Source: {r['source']})\")\n",
                "    return rows\n",
                "\n",
                "def approve_asset(asset_id: str, reviewer: str, notes: str):\n",
                "    print(f\"\\nâœ… Approving Asset {asset_id}...\")\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    try:\n",
                "        cur.execute(\"SELECT confidence FROM brand_assets WHERE asset_id = %s\", (asset_id,))\n",
                "        res = cur.fetchone()\n",
                "        if not res: return\n",
                "        prev_conf = res[0]\n",
                "        cur.execute(\"UPDATE brand_assets SET confidence = 'approved', reviewed_by = %s, review_notes = %s, reviewed_at = NOW() WHERE asset_id = %s\", (reviewer, notes, asset_id))\n",
                "        cur.execute(\"INSERT INTO memory_reviews (review_id, asset_id, action, previous_confidence, new_confidence, reviewer, notes) VALUES (%s, %s, %s, %s, %s, %s, %s)\", (str(uuid.uuid4()), asset_id, 'approve', prev_conf, 'approved', reviewer, notes))\n",
                "        conn.commit()\n",
                "        print(\"   -> Asset Approved.\")\n",
                "    except Exception as e:\n",
                "        conn.rollback(); print(f\"âŒ {e}\")\n",
                "    finally:\n",
                "        cur.close(); conn.close()\n",
                "\n",
                "def reject_asset(asset_id: str, reviewer: str, notes: str):\n",
                "    print(f\"\\nâ›” Rejecting Asset {asset_id}...\")\n",
                "    conn = get_db_connection(); cur = conn.cursor()\n",
                "    try:\n",
                "        cur.execute(\"SELECT confidence FROM brand_assets WHERE asset_id = %s\", (asset_id,))\n",
                "        res = cur.fetchone()\n",
                "        if not res: return\n",
                "        prev_conf = res[0]\n",
                "        cur.execute(\"UPDATE brand_assets SET confidence = 'deprecated', reviewed_by = %s, review_notes = %s, reviewed_at = NOW() WHERE asset_id = %s\", (reviewer, notes, asset_id))\n",
                "        cur.execute(\"INSERT INTO memory_reviews (review_id, asset_id, action, previous_confidence, new_confidence, reviewer, notes) VALUES (%s, %s, %s, %s, %s, %s, %s)\", (str(uuid.uuid4()), asset_id, 'deprecate', prev_conf, 'deprecated', reviewer, notes))\n",
                "        conn.commit()\n",
                "        print(\"   -> Asset Deprecated.\")\n",
                "    except Exception as e:\n",
                "        conn.rollback(); print(f\"âŒ {e}\")\n",
                "    finally:\n",
                "        cur.close(); conn.close()\n",
                "\n",
                "def edit_and_promote_asset(asset_id: str, new_text: str, reviewer: str):\n",
                "    print(f\"\\nðŸ“ Editing & Promoting Asset {asset_id}...\")\n",
                "    conn = get_db_connection(); cur = conn.cursor(cursor_factory=RealDictCursor)\n",
                "    try:\n",
                "        cur.execute(\"SELECT * FROM brand_assets WHERE asset_id = %s\", (asset_id,))\n",
                "        original = cur.fetchone()\n",
                "        if not original: return\n",
                "        # Deprecate Old\n",
                "        cur.execute(\"UPDATE brand_assets SET confidence = 'deprecated', reviewed_by = %s, review_notes = 'Replaced by edit', reviewed_at = NOW() WHERE asset_id = %s\", (reviewer, asset_id))\n",
                "        # Insert New Approved\n",
                "        new_asset_id = str(uuid.uuid4())\n",
                "        cur.execute(\"INSERT INTO brand_assets (asset_id, brand_id, asset_type, raw_text, source, confidence, reviewed_by, reviewed_at, review_notes) VALUES (%s, %s, %s, %s, %s, %s, %s, NOW(), 'Created via Edit')\", (new_asset_id, original['brand_id'], original['asset_type'], new_text, original['source'], 'approved', reviewer))\n",
                "        conn.commit()\n",
                "        print(f\"   -> Old Asset Deprecated. New Asset {new_asset_id} Created.\")\n",
                "        # Chunk & Embed New Asset\n",
                "        chunks = chunk_text(new_text)\n",
                "        idx = pc.Index(\"brand-brain-index\")\n",
                "        org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
                "        # Need vector_type\n",
                "        cur.execute(\"SELECT vector_type FROM brand_chunks WHERE asset_id = %s LIMIT 1\", (asset_id,))\n",
                "        vt = cur.fetchone()['vector_type']\n",
                "        for i, chunk in enumerate(chunks):\n",
                "            chunk_id = str(uuid.uuid4())\n",
                "            vec = generate_embedding(chunk)\n",
                "            cur.execute(\"INSERT INTO brand_chunks (chunk_id, asset_id, brand_id, vector_type, content, token_count) VALUES (%s, %s, %s, %s, %s, %s)\", (chunk_id, new_asset_id, original['brand_id'], vt, chunk, len(chunk.split())))\n",
                "            cur.execute(\"INSERT INTO embeddings (embedding_id, chunk_id, brand_id, vector_type, namespace, model) VALUES (%s, %s, %s, %s, %s, %s)\", (str(uuid.uuid4()), chunk_id, original['brand_id'], vt, f\"{org_id}:{original['brand_id']}:{vt}\", \"gemini-embedding-001\"))\n",
                "            idx.upsert(vectors=[(chunk_id, vec, {\"source\": original['source']})], namespace=f\"{org_id}:{original['brand_id']}:{vt}\")\n",
                "        conn.commit()\n",
                "        print(\"   -> New/Edited Asset Embeddings Generated.\")\n",
                "    except Exception as e:\n",
                "        conn.rollback(); print(f\"âŒ Edit Failed: {e}\")\n",
                "    finally:\n",
                "        cur.close(); conn.close()\n",
                "print(\"âœ… Section C: Functions Ready (v1.6)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": ["## ðŸ”¹ SECTION D â€” Validation Tests (v1.6)\n"]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SECTION D: Validation Tests\n",
                "\n",
                "def run_v1_6_validation():\n",
                "    brand_id_str = \"wh_india_001\"\n",
                "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
                "    \n",
                "    print(\"\\n\\n--- ðŸ§ª TEST 1: Ingestion starts as 'inferred' ---\")\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    cur.execute(\"SELECT count(*) FROM brand_assets WHERE brand_id = %s AND confidence = 'inferred'\", (brand_uuid,))\n",
                "    count = cur.fetchone()[0]\n",
                "    cur.close(); conn.close()\n",
                "    print(f\"âœ… Found {count} 'inferred' assets\")\n",
                "    \n",
                "    print(\"\\n--- ðŸ§ª TEST 2: Retrieval Priority (Approved > Inferred) ---\")\n",
                "    inferred = list_inferred_assets(brand_id_str)\n",
                "    if inferred:\n",
                "        target = inferred[0]\n",
                "        print(f\"   Targeting: {target['raw_text'][:20]}...\")\n",
                "        approve_asset(target['asset_id'], \"Admin\", \"Accurate\")\n",
                "        res = retrieve_context(brand_id_str, \"brand philosophy\", \"strategy\")\n",
                "        if res and res[0]['confidence'] == 'approved':\n",
                "             print(\"âœ… Approved asset prioritized.\")\n",
                "        else:\n",
                "             print(f\"âš ï¸ Top result confidence: {res[0]['confidence'] if res else 'None'}\")\n",
                "\n",
                "    print(\"\\n--- ðŸ§ª TEST 3: Deprecation (Exclude from Retrieval) ---\")\n",
                "    if inferred:\n",
                "        reject_asset(target['asset_id'], \"Admin\", \"Deprecating\")\n",
                "        res = retrieve_context(brand_id_str, \"brand philosophy\", \"strategy\")\n",
                "        found = any(d['content'] == target['raw_text'] for d in res)\n",
                "        if not found:\n",
                "            print(\"âœ… Deprecated asset successfully EXCLUDED.\")\n",
                "        else:\n",
                "            print(\"âŒ FAILURE: Deprecated asset still retrieved!\")\n",
                "\n",
                "    print(\"\\n--- ðŸ§ª TEST 4: Audit Trail ---\")\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    cur.execute(\"SELECT * FROM memory_reviews ORDER BY created_at DESC LIMIT 5\")\n",
                "    for r in cur.fetchall():\n",
                "        print(f\"   - Action: {r[3]} | Old: {r[4]} -> New: {r[5]}\")\n",
                "    cur.close(); conn.close()\n",
                "\n",
                "run_v1_6_validation()"
            ]
        }
    ]
    
    # insert before
    for i, c in enumerate(new_cells):
        nb['cells'].insert(ephemeral_idx + i, c)

# Save
with open('brand_brain_v1.6.ipynb', 'w', encoding='utf-8') as f:
    json.dump(nb, f, indent=4)
print("Transformation Complete. Saved to brand_brain_v1.6.ipynb")
