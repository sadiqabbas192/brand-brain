{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# **Brand Brain v1 - Development & Validation Harness**\n",
                "\n",
                "This notebook implements and validates the Brand Brain v1 architecture end-to-end. \n",
                "It covers data ingestion, semantic asset extraction, chunking, embedding, storage (Postgres + Pinecone), and brand-scoped retrieval.\n",
                "\n",
                "## **Architecture Recap**\n",
                "\n",
                "1.  **Input**: Brand JSON (simulating DynamoDB export)\n",
                "2.  **Ingestion**: \n",
                "    *   Extract Semantic Assets\n",
                "    *   Chunking (200-350 tokens)\n",
                "    *   Embedding (Gemini `gemini-embedding-001` @ 768 dims)\n",
                "3.  **Storage**:\n",
                "    *   **Postgres**: Structured memory (Assets, Chunks)\n",
                "    *   **Pinecone**: Semantic vectors (Namespace: `org:brand:type`)\n",
                "4.  **Retrieval**: Brand-scoped semantic search\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Configuration Loaded & Clients Initialized\n"
                    ]
                }
            ],
            "source": [
                "# 1. Setup & Configuration\n",
                "import os\n",
                "import json\n",
                "import uuid\n",
                "import time\n",
                "from typing import List, Dict, Any, Optional\n",
                "import pandas as pd\n",
                "import psycopg2\n",
                "from psycopg2.extras import RealDictCursor, Json\n",
                "from pinecone import Pinecone, ServerlessSpec\n",
                "from google import genai\n",
                "from dotenv import load_dotenv\n",
                "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
                "\n",
                "# Load environment variables\n",
                "load_dotenv(override=True) # Ensure we reload if .env changed\n",
                "\n",
                "NEON_DB_URL = os.getenv(\"NEON_DB_URL\")\n",
                "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
                "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
                "\n",
                "if not all([NEON_DB_URL, PINECONE_API_KEY, GEMINI_API_KEY]):\n",
                "    raise ValueError(\"Missing required environment variables. Please check your .env file.\")\n",
                "\n",
                "# Initialize Clients\n",
                "client = genai.Client(api_key=GEMINI_API_KEY)\n",
                "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
                "\n",
                "# Database Connection Helper\n",
                "def get_db_connection():\n",
                "    return psycopg2.connect(NEON_DB_URL)\n",
                "\n",
                "print(\"‚úÖ Configuration Loaded & Clients Initialized\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Connected to Neon DB. Tables exist.\n"
                    ]
                }
            ],
            "source": [
                "# 2. Database Pre-checks (No Table Creation)\n",
                "def check_connection():\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    try:\n",
                "        cur.execute(\"SELECT count(*) FROM information_schema.tables WHERE table_name = 'brand_assets'\")\n",
                "        if cur.fetchone()[0] == 0:\n",
                "            print(\"‚ùå ERROR: Tables not found! Please run tables.sql in Neon console.\")\n",
                "        else:\n",
                "            print(\"‚úÖ Connected to Neon DB. Tables exist.\")\n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Connection Failed: {e}\")\n",
                "    finally:\n",
                "        cur.close()\n",
                "        conn.close()\n",
                "\n",
                "check_connection()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Input Brand Data\n",
                "\n",
                "# Parsed from Westinghouse India.txt\n",
                "westinghouse_json = {\n",
                "    \"brandId\": \"wh_india_001\",\n",
                "    \"name\": \"Westinghouse India\",\n",
                "    \"industry\": \"FMEG\",\n",
                "    \"mission\": \"To enrich everyday living with reliable, thoughtfully engineered appliances that combine global heritage, modern innovation, and timeless design‚Äîdelivering confidence, comfort, and consistency to Indian homes.\",\n",
                "    \"brandVoice\": \"Confident & Reassuring. Premium yet Approachable. Clear & Functional. Trust-First. Design-Conscious.\",\n",
                "    \"visualStyle\": \"Design-forward minimalism. Product as hero. Lifestyle-led context. Retro-modern blend. Premium finishes. Colors: Orange, Red, White, Green, Blue, Black.\",\n",
                "    \"audience\": \"All genders, 25‚Äì45 years (core). Upper-middle to affluent households. Interests: Premium home & kitchen appliances, Modern kitchen aesthetics, Smart living. Focus: Tier 1 metros (Mumbai, Delhi NCR...) and affluent Tier 2.\",\n",
                "    \"competitors\": \"Morphy Richards (Strong British Heritage, Wide Portfolio). Weaknesses: Inconsistent Visual Identity, Limited Design Differentiation.\",\n",
                "    \"inspiration\": \"Morphy Richards\",\n",
                "    \"website\": \"https://www.westinghousehomeware.in/\"\n",
                "}\n",
                "\n",
                "brands_to_ingest = [westinghouse_json]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Asset Extraction Logic Defined\n"
                    ]
                }
            ],
            "source": [
                "# 4. Semantic Asset Extraction Logic\n",
                "\n",
                "def extract_assets(brand_data: Dict) -> List[Dict]:\n",
                "    assets = []\n",
                "    brand_id = brand_data.get(\"brandId\")\n",
                "    \n",
                "    # Extraction Rules Mapping\n",
                "    # Source Field -> (Asset Type [copy/guideline/website], Vector Type [brand_voice/strategy/performance])\n",
                "    mapping = {\n",
                "        \"mission\": (\"guideline\", \"strategy\"),\n",
                "        \"brandVoice\": (\"guideline\", \"brand_voice\"),\n",
                "        \"visualStyle\": (\"guideline\", \"brand_voice\"),\n",
                "        \"audience\": (\"guideline\", \"strategy\"),\n",
                "        \"competitors\": (\"guideline\", \"strategy\"),\n",
                "        \"inspiration\": (\"guideline\", \"strategy\"),\n",
                "        \"website\": (\"website\", \"strategy\")\n",
                "    }\n",
                "    \n",
                "    for field, (asset_type, vector_type) in mapping.items():\n",
                "        content = brand_data.get(field)\n",
                "        if content:\n",
                "            assets.append({\n",
                "                \"asset_id\": str(uuid.uuid4()),\n",
                "                \"brand_id\": brand_id,\n",
                "                \"asset_type\": asset_type,\n",
                "                \"vector_type\": vector_type,\n",
                "                \"source_field\": field,\n",
                "                \"content\": content\n",
                "            })\n",
                "            \n",
                "    return assets\n",
                "\n",
                "print(\"‚úÖ Asset Extraction Logic Defined\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Chunking & Embedding Functions Defined (New SDK - 768 dims)\n"
                    ]
                }
            ],
            "source": [
                "# 5. Chunking & Embedding Logic\n",
                "\n",
                "text_splitter = RecursiveCharacterTextSplitter(\n",
                "    chunk_size=350,\n",
                "    chunk_overlap=50,\n",
                "    length_function=len,\n",
                "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
                ")\n",
                "\n",
                "def chunk_text(text: str) -> List[str]:\n",
                "    return text_splitter.split_text(text)\n",
                "\n",
                "def generate_embedding(text: str) -> List[float]:\n",
                "    # Using gemini-embedding-001 with truncation to 768 dimensions\n",
                "    try:\n",
                "        result = client.models.embed_content(\n",
                "            model=\"gemini-embedding-001\",\n",
                "            contents=text,\n",
                "            config={\n",
                "                'output_dimensionality': 768,\n",
                "                'task_type': 'RETRIEVAL_DOCUMENT',\n",
                "                'title': 'Brand Asset'\n",
                "            }\n",
                "        )\n",
                "        return result.embeddings[0].values\n",
                "    except Exception as e:\n",
                "        print(f\"Embedding Error: {e}\")\n",
                "        return []\n",
                "\n",
                "print(\"‚úÖ Chunking & Embedding Functions Defined (New SDK - 768 dims)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. Ingestion Pipeline (Production Schema)\n",
                "\n",
                "def ingest_brand(brand_data: Dict):\n",
                "    brand_id_str = brand_data['brandId']\n",
                "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
                "    \n",
                "    brand_name = brand_data.get('name', 'Unknown')\n",
                "    org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org')) # Placeholder Org\n",
                "\n",
                "    print(f\"\\nüß† Ingesting Brand: {brand_name} (UUID: {brand_uuid}) ...\")\n",
                "    \n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    \n",
                "    try:\n",
                "        # 1. Ensure Organization Exists\n",
                "        cur.execute(\n",
                "            \"INSERT INTO organizations (org_id, name) VALUES (%s, %s) ON CONFLICT (org_id) DO NOTHING\",\n",
                "            (org_id, \"Test Org\")\n",
                "        )\n",
                "\n",
                "        # 2. Ensure Brand Exists\n",
                "        cur.execute(\n",
                "            \"INSERT INTO brands (brand_id, org_id, name, industry) VALUES (%s, %s, %s, %s) ON CONFLICT (brand_id) DO NOTHING\",\n",
                "            (brand_uuid, org_id, brand_name, brand_data.get('industry', 'Unknown'))\n",
                "        )\n",
                "\n",
                "        # 3. Extract Assets\n",
                "        assets = extract_assets(brand_data)\n",
                "        print(f\"   -> Extracted {len(assets)} semantic assets\")\n",
                "\n",
                "        # Prepare Pinecone\n",
                "        index_name = \"brand-brain-index\"\n",
                "        \n",
                "        # DEBUG: Check what key is actually being used\n",
                "        masked = PINECONE_API_KEY[:5] + \"...\" if PINECONE_API_KEY else \"None\"\n",
                "        print(f\"   [DEBUG] Checking Pinecone Index with Key: {masked}\")\n",
                "        \n",
                "        # Create index if not exists\n",
                "        if index_name not in pc.list_indexes().names():\n",
                "             pc.create_index(\n",
                "                name=index_name,\n",
                "                dimension=768,\n",
                "                metric=\"cosine\",\n",
                "                spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
                "            )\n",
                "        idx = pc.Index(index_name)\n",
                "\n",
                "        total_chunks = 0\n",
                "        \n",
                "        for asset in assets:\n",
                "            # Insert Asset Metadata\n",
                "            cur.execute(\n",
                "                \"INSERT INTO brand_assets (asset_id, brand_id, asset_type, raw_text, source) VALUES (%s, %s, %s, %s, %s) ON CONFLICT (asset_id) DO NOTHING\",\n",
                "                (asset['asset_id'], brand_uuid, asset['asset_type'], asset['content'], asset['source_field'])\n",
                "            )\n",
                "            \n",
                "            chunks = chunk_text(asset['content'])\n",
                "            \n",
                "            for i, chunk_text_content in enumerate(chunks):\n",
                "                chunk_id = str(uuid.uuid4())\n",
                "                embedding_id = str(uuid.uuid4())\n",
                "                vector = generate_embedding(chunk_text_content)\n",
                "                \n",
                "                if not vector:\n",
                "                    print(f\"Skipping chunk due to embedding failure\")\n",
                "                    continue\n",
                "\n",
                "                cur.execute(\n",
                "                    \"INSERT INTO brand_chunks (chunk_id, asset_id, brand_id, vector_type, content, token_count) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
                "                    (chunk_id, asset['asset_id'], brand_uuid, asset['vector_type'], chunk_text_content, len(chunk_text_content.split()))\n",
                "                )\n",
                "                \n",
                "                namespace = f\"{org_id}:{brand_uuid}:{asset['vector_type']}\"\n",
                "                cur.execute(\n",
                "                    \"INSERT INTO embeddings (embedding_id, chunk_id, brand_id, vector_type, namespace, model) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
                "                    (embedding_id, chunk_id, brand_uuid, asset['vector_type'], namespace, \"gemini-embedding-001\")\n",
                "                )\n",
                "\n",
                "                idx.upsert(\n",
                "                    vectors=[(chunk_id, vector, {\"source\": asset['source_field']})],\n",
                "                    namespace=namespace\n",
                "                )\n",
                "                total_chunks += 1\n",
                "        \n",
                "        conn.commit()\n",
                "        print(f\"‚úÖ Successfully ingested {total_chunks} chunks for {brand_name}.\")\n",
                "        \n",
                "    except Exception as e:\n",
                "        conn.rollback()\n",
                "        print(f\"‚ùå Ingestion Failed: {e}\")\n",
                "    finally:\n",
                "        cur.close()\n",
                "        conn.close()\n",
                "\n",
                "# Run Ingestion\n",
                "for brand in brands_to_ingest:\n",
                "    ingest_brand(brand)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- TEST 1: Westinghouse Brand Voice ---\n",
                        "\n",
                        "üîé Querying Brand wh_india_001 (UUID: 25ecf8da-150a-506d-aef6-7b2794b4b114) [brand_voice]: 'Describe our design philosophy.'\n",
                        "   [1] Score: 0.6904 | Content: Confident & Reassuring. Premium yet Approachable. Clear & Functional. Trust-First. Design-Conscious....\n",
                        "   [2] Score: 0.6477 | Content: Design-forward minimalism. Product as hero. Lifestyle-led context. Retro-modern blend. Premium finis...\n",
                        "\n",
                        "--- TEST 2: Westinghouse Strategy ---\n",
                        "\n",
                        "üîé Querying Brand wh_india_001 (UUID: 25ecf8da-150a-506d-aef6-7b2794b4b114) [strategy]: 'Who are we fighting against?'\n",
                        "   [1] Score: 0.5286 | Content: To enrich everyday living with reliable, thoughtfully engineered appliances that combine global heri...\n",
                        "   [2] Score: 0.5266 | Content: All genders, 25‚Äì45 years (core). Upper-middle to affluent households. Interests: Premium home & kitc...\n",
                        "   [3] Score: 0.5213 | Content: https://www.westinghousehomeware.in/...\n",
                        "\n",
                        "--- TEST 3: Isolation / Irrelevant Query ---\n",
                        "\n",
                        "üîé Querying Brand wh_india_001 (UUID: 25ecf8da-150a-506d-aef6-7b2794b4b114) [brand_voice]: 'How to be cheap and loud?'\n",
                        "   [1] Score: 0.5464 | Content: Confident & Reassuring. Premium yet Approachable. Clear & Functional. Trust-First. Design-Conscious....\n",
                        "   [2] Score: 0.5446 | Content: Design-forward minimalism. Product as hero. Lifestyle-led context. Retro-modern blend. Premium finis...\n"
                    ]
                }
            ],
            "source": [
                "# 7. Retrieval & Validation Logic\n",
                "\n",
                "def retrieve_context(brand_name_str: str, query: str, vector_type: str = \"brand_voice\", top_k: int = 3):\n",
                "    if brand_name_str == \"wh_india_001\":\n",
                "        brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_name_str))\n",
                "        org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
                "    else:\n",
                "        brand_uuid = brand_name_str\n",
                "        org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
                "\n",
                "    print(f\"\\nüîé Querying Brand {brand_name_str} (UUID: {brand_uuid}) [{vector_type}]: '{query}'\")\n",
                "    \n",
                "    # New SDK for Query Embedding\n",
                "    try:\n",
                "        query_embedding_result = client.models.embed_content(\n",
                "            model=\"gemini-embedding-001\",\n",
                "            contents=query,\n",
                "            config={\n",
                "                'output_dimensionality': 768,\n",
                "                'task_type': 'RETRIEVAL_QUERY'\n",
                "            }\n",
                "        )\n",
                "        query_embedding = query_embedding_result.embeddings[0].values\n",
                "    except Exception as e:\n",
                "        print(f\"Embedding Error during retrieval: {e}\")\n",
                "        return []\n",
                "    \n",
                "    namespace = f\"{org_id}:{brand_uuid}:{vector_type}\"\n",
                "    index_name = \"brand-brain-index\"\n",
                "    idx = pc.Index(index_name)\n",
                "    \n",
                "    results = idx.query(\n",
                "        vector=query_embedding,\n",
                "        top_k=top_k,\n",
                "        namespace=namespace,\n",
                "        include_metadata=True\n",
                "    )\n",
                "    \n",
                "    if not results['matches']:\n",
                "        print(\"   ‚ö†Ô∏è No matches found in namespace:\", namespace)\n",
                "        return []\n",
                "        \n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    \n",
                "    retrieved_docs = []\n",
                "    chunk_ids = [m['id'] for m in results['matches']]\n",
                "    \n",
                "    if chunk_ids:\n",
                "        placeholders = ', '.join(['%s'] * len(chunk_ids))\n",
                "        query_sql = f\"SELECT content, vector_type FROM brand_chunks WHERE chunk_id IN ({placeholders})\"\n",
                "        cur.execute(query_sql, tuple(chunk_ids))\n",
                "        rows = cur.fetchall()\n",
                "        \n",
                "        for i, row in enumerate(rows):\n",
                "            score = results['matches'][i]['score']\n",
                "            print(f\"   [{i+1}] Score: {score:.4f} | Content: {row[0][:100]}...\")\n",
                "            retrieved_docs.append({\"content\": row[0], \"score\": score})\n",
                "            \n",
                "    cur.close()\n",
                "    conn.close()\n",
                "    return retrieved_docs\n",
                "\n",
                "# 8. Run Validation Tests\n",
                "def run_validation():\n",
                "    # Test 1: Westinghouse Brand Voice\n",
                "    print(\"\\n--- TEST 1: Westinghouse Brand Voice ---\")\n",
                "    retrieve_context(\"wh_india_001\", \"Describe our design philosophy.\", vector_type=\"brand_voice\")\n",
                "    \n",
                "    # Test 2: Westinghouse Competitor Context\n",
                "    print(\"\\n--- TEST 2: Westinghouse Strategy ---\")\n",
                "    retrieve_context(\"wh_india_001\", \"Who are we fighting against?\", vector_type=\"strategy\")\n",
                "    \n",
                "    # Test 3: Off-Brand check\n",
                "    print(\"\\n--- TEST 3: Isolation / Irrelevant Query ---\")\n",
                "    retrieve_context(\"wh_india_001\", \"How to be cheap and loud?\", vector_type=\"brand_voice\")\n",
                "\n",
                "run_validation()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## **Brand Brain v1.5 - Grounded Cognition Extensions**\n",
                "\n",
                "The following sections implement **Brand Brain v1.5** with strict adherence to:\n",
                "1. **Type A/B/C Memory separation**\n",
                "2. **Evidence-based Grounding**\n",
                "3. **Deterministic Safety Rules**\n",
                "4. **No implicit memory growth**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "347a5efd",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ v1.5 Libraries Loaded\n"
                    ]
                }
            ],
            "source": [
                "# v1.5 Imports\n",
                "import numpy as np\n",
                "from google.genai import types\n",
                "import statistics\n",
                "\n",
                "print(\"‚úÖ v1.5 Libraries Loaded\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "300959cb",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Section A: Grounding-Assisted Ingestion Implementation Ready\n"
                    ]
                }
            ],
            "source": [
                "# SECTION A: Grounding-Assisted Ingestion (Type B Memory)\n",
                "\n",
                "def grounding_assisted_ingest(brand_data: Dict, target_vector_type=\"strategy\"):\n",
                "    \"\"\"\n",
                "    Uses Gemini Google Search tools to extract ONLY evergreen brand philosophy.\n",
                "    Enforces strict prompt filters.\n",
                "    Stores as Type B memory with version tags.\n",
                "    \"\"\"\n",
                "    brand_name = brand_data['name']\n",
                "    website = brand_data.get('website', '')\n",
                "    \n",
                "    print(f\"\\nüåç Starting Grounding-Assisted Ingestion for {brand_name}...\")\n",
                "\n",
                "    # 1. Define Prompt with HARD FILTERS\n",
                "    prompt = f\"\"\"\n",
                "    You are a Brand Identity Expert.\n",
                "    SEARCH for \"{brand_name} brand philosophy design principles manifesto\".\n",
                "    Also check the provided website: {website}\n",
                "\n",
                "    EXTRACT ONLY evergreen, high-level brand identity content.\n",
                "    \n",
                "    ‚ùå STRICTLY IGNORE:\n",
                "    - pricing, offers, discounts\n",
                "    - launches, new arrivals\n",
                "    - comparisons, awards\n",
                "    - timelines, history dates\n",
                "    - \"latest\", \"new\", \"recent\", \"2024\", \"2025\"\n",
                "\n",
                "    ‚úÖ EXTRACT ONLY:\n",
                "    - philosophy & mission\n",
                "    - design principles\n",
                "    - core values\n",
                "    - identity statements\n",
                "    \n",
                "    RETURN JSON in this format:\n",
                "    {{\n",
                "      \"brand_philosophy\": \"string\",\n",
                "      \"design_principles\": \"string\",\n",
                "      \"positioning\": \"string\"\n",
                "    }}\n",
                "    \"\"\"\n",
                "\n",
                "    try:\n",
                "        # 2. Call Gemini with Search Tool\n",
                "        # [FIX] Removed response_mime_type to allow Tools to work correctly\n",
                "        response = client.models.generate_content(\n",
                "            model=\"gemini-2.5-flash\", # Using Flash for speed/tools\n",
                "            contents=prompt,\n",
                "            config=types.GenerateContentConfig(\n",
                "                tools=[types.Tool(google_search=types.GoogleSearchRetrieval)]\n",
                "            )\n",
                "        )\n",
                "        \n",
                "        # 3. Robust JSON Parsing (Manual)\n",
                "        text = response.text.strip()\n",
                "        if text.startswith(\"```json\"):\n",
                "            text = text[7:]\n",
                "        elif text.startswith(\"```\"):\n",
                "            text = text[3:]\n",
                "        if text.endswith(\"```\"):\n",
                "            text = text[:-3]\n",
                "            \n",
                "        extracted_data = json.loads(text.strip())\n",
                "        print(f\"   ‚úÖ Extracted Grounded Data: {list(extracted_data.keys())}\")\n",
                "\n",
                "        # 3. Format as Assets (Type B)\n",
                "        # Merging into a single text block for embedding is usually better for 'strategy'\n",
                "        combined_text = f\"Philosophy: {extracted_data.get('brand_philosophy', '')}\\n\"\n",
                "        combined_text += f\"Design Principles: {extracted_data.get('design_principles', '')}\\n\"\n",
                "        combined_text += f\"Positioning: {extracted_data.get('positioning', '')}\"\n",
                "\n",
                "        grounded_asset = {\n",
                "            \"asset_id\": str(uuid.uuid4()),\n",
                "            \"brand_id\": brand_data['brandId'],\n",
                "            \"asset_type\": \"guideline\", # Fixed: Must be one of 'copy', 'guideline', 'website'\n",
                "            \"vector_type\": target_vector_type,\n",
                "            \"source_field\": \"grounding_assisted_ingestion\",\n",
                "            \"content\": combined_text\n",
                "        }\n",
                "\n",
                "        # 4. Store & Embed (Reusing ingestion logic pattern)\n",
                "        ingest_single_asset(grounded_asset, brand_data) # Helper to be defined below\n",
                "\n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Grounding Ingestion Failed: {e}\")\n",
                "\n",
                "\n",
                "def ingest_single_asset(asset: Dict, brand_data: Dict):\n",
                "    \"\"\"Helper to ingest a single constructed asset.\"\"\"\n",
                "    brand_id_str = brand_data['brandId']\n",
                "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
                "    org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
                "    \n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    idx = pc.Index(\"brand-brain-index\")\n",
                "\n",
                "    try:\n",
                "        # Store Asset in Postgres\n",
                "        # Note: metadata like source_version is stored in source or handled via separate columns in prod\n",
                "        # Here we pack it into 'source' string or similar for v1 demo\n",
                "        source_tag = f\"{asset['source_field']} | v1.5 | confidence:inferred\"\n",
                "        \n",
                "        cur.execute(\n",
                "            \"INSERT INTO brand_assets (asset_id, brand_id, asset_type, raw_text, source) VALUES (%s, %s, %s, %s, %s) ON CONFLICT (asset_id) DO NOTHING\",\n",
                "            (asset['asset_id'], brand_uuid, asset['asset_type'], asset['content'], source_tag)\n",
                "        )\n",
                "\n",
                "        chunks = chunk_text(asset['content'])\n",
                "        for chunk_text_content in chunks:\n",
                "            chunk_id = str(uuid.uuid4())\n",
                "            embedding_id = str(uuid.uuid4())\n",
                "            vector = generate_embedding(chunk_text_content)\n",
                "            \n",
                "            if not vector: continue\n",
                "\n",
                "            cur.execute(\n",
                "                \"INSERT INTO brand_chunks (chunk_id, asset_id, brand_id, vector_type, content, token_count) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
                "                (chunk_id, asset['asset_id'], brand_uuid, asset['vector_type'], chunk_text_content, len(chunk_text_content.split()))\n",
                "            )\n",
                "            \n",
                "            namespace = f\"{org_id}:{brand_uuid}:{asset['vector_type']}\"\n",
                "            \n",
                "            cur.execute(\n",
                "                 \"INSERT INTO embeddings (embedding_id, chunk_id, brand_id, vector_type, namespace, model) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
                "                (embedding_id, chunk_id, brand_uuid, asset['vector_type'], namespace, \"gemini-embedding-001\")\n",
                "            )\n",
                "            \n",
                "            idx.upsert(\n",
                "                vectors=[(chunk_id, vector, {\"source\": source_tag})],\n",
                "                namespace=namespace\n",
                "            )\n",
                "        \n",
                "        conn.commit()\n",
                "        print(f\"   ‚úÖ Successfully stored Type B memory for {brand_data['name']}\")\n",
                "    finally:\n",
                "        cur.close()\n",
                "        conn.close()\n",
                "\n",
                "print(\"‚úÖ Section A: Grounding-Assisted Ingestion Implementation Ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "a7312ee2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Section B: Off-Brand Rule Engine Ready\n"
                    ]
                }
            ],
            "source": [
                "# SECTION B: Off-Brand Rule Engine (Deterministic)\n",
                "\n",
                "ALLOWED_INTENTS = {\"explain_brand\", \"validate_copy\", \"justify_decision\", \"minimal_rewrite\"}\n",
                "FORBIDDEN_KEYWORDS = {\"cheap\", \"discount\", \"free\", \"lowest price\", \"clearance\", \"sale\", \"loud\"}\n",
                "\n",
                "def calculate_brand_centroid(brand_id: str, org_id: str, top_n=5) -> List[float]:\n",
                "    \"\"\"\n",
                "    Calculates deterministic centroid from top-N 'brand_voice' chunks.\n",
                "    In a real system, this is pre-computed. Here we fetch via a 'neutral' query.\n",
                "    \"\"\"\n",
                "    idx = pc.Index(\"brand-brain-index\")\n",
                "    namespace = f\"{org_id}:{brand_id}:brand_voice\"\n",
                "    \n",
                "    # Deterministic query to fetch representative chunks\n",
                "    # We use a static string that represents the ideal voice to find core chunks\n",
                "    query_vec = generate_embedding(\"brand voice tone philosophy identity\")\n",
                "    \n",
                "    results = idx.query(\n",
                "        vector=query_vec,\n",
                "        top_k=top_n,\n",
                "        namespace=namespace\n",
                "    )\n",
                "    \n",
                "    vectors = []\n",
                "    # Pinecone doesn't always return vectors in query results unless requested\n",
                "    # Assuming we need to fetch items. Actually idx.query(..., include_values=True)\n",
                "    if results['matches']:\n",
                "         # Re-query by ID to get values if needed, or just set include_values=True above\n",
                "         # Let's adjust query to include values\n",
                "         results_with_values = idx.query(\n",
                "            vector=query_vec,\n",
                "            top_k=top_n,\n",
                "            namespace=namespace,\n",
                "            include_values=True\n",
                "        )\n",
                "         for m in results_with_values['matches']:\n",
                "             vectors.append(m['values'])\n",
                "             \n",
                "    if not vectors:\n",
                "        return []\n",
                "    \n",
                "    return np.mean(vectors, axis=0).tolist()\n",
                "\n",
                "def check_brand_safety(user_query: str, brand_id_str: str, intent: str) -> Dict:\n",
                "    # 1. Intent Check\n",
                "    if intent not in ALLOWED_INTENTS:\n",
                "        return {\"status\": \"FAIL\", \"reason\": f\"Intent '{intent}' is not allowed in v1.5\"}\n",
                "    \n",
                "    # 2. Keyword Check\n",
                "    query_lower = user_query.lower()\n",
                "    violated_keywords = [kw for kw in FORBIDDEN_KEYWORDS if kw in query_lower]\n",
                "    if violated_keywords:\n",
                "         return {\"status\": \"FAIL\", \"reason\": f\"Forbidden keywords detected: {violated_keywords}\"}\n",
                "    \n",
                "    # 3. Semantic Drift Check\n",
                "    # Setup IDs\n",
                "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
                "    org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
                "    \n",
                "    centroid = calculate_brand_centroid(brand_uuid, org_id)\n",
                "    if not centroid:\n",
                "        # Fallback if no memory exists yet\n",
                "        return {\"status\": \"PASS\", \"reason\": \"No brand memory to validate against (Cold Start)\"}\n",
                "        \n",
                "    query_vec = generate_embedding(user_query)\n",
                "    similarity = np.dot(query_vec, centroid) / (np.linalg.norm(query_vec) * np.linalg.norm(centroid))\n",
                "    \n",
                "    # Threshold: If query is extremely dissimilar to brand voice AND contains questionable terms (handled by keywords)\n",
                "    # For v1.5, we enforce a baseline relevance\n",
                "    if similarity < 0.4: # Arbitrary strictness\n",
                "         return {\"status\": \"FAIL\", \"reason\": f\"Semantic drift detected (Score: {similarity:.2f}). Query not aligned with Brand Voice.\"}\n",
                "\n",
                "    return {\"status\": \"PASS\", \"reason\": \"All checks passed\"}\n",
                "\n",
                "print(\"‚úÖ Section B: Off-Brand Rule Engine Ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "1679150f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Section C: Brand Reasoner Ready\n"
                    ]
                }
            ],
            "source": [
                "# SECTION C: Brand Reasoner\n",
                "\n",
                "def generate_brand_response(query: str, context: List[Dict], safety_status: Dict, temp_grounding: str = None) -> str:\n",
                "    if safety_status['status'] == \"FAIL\":\n",
                "        return f\"üö´ BRAND SAFETY BLOCK: {safety_status['reason']}\"\n",
                "        \n",
                "    context_str = \"\\n\".join([f\"- {c['content']}\" for c in context])\n",
                "    if temp_grounding:\n",
                "        context_str += f\"\\n[EXTERNAL EVIDENCE]: {temp_grounding}\"\n",
                "        \n",
                "    prompt = f\"\"\"\n",
                "    You are Brand Brain. Your job is to Explain, Justify, or Minimally Rewrite.\n",
                "    Use the provided BRAND MEMORY as the source of truth.\n",
                "    If external evidence is provided, use it for context but subordinate it to Brand Memory.\n",
                "    \n",
                "    QUERY: {query}\n",
                "    \n",
                "    BRAND MEMORY:\n",
                "    {context_str}\n",
                "    \n",
                "    INSTRUCTIONS:\n",
                "    - Do not invent facts.\n",
                "    - Adhere to the tone found in memory.\n",
                "    \"\"\"\n",
                "    \n",
                "    response = client.models.generate_content(\n",
                "        model=\"gemini-2.5-flash\",\n",
                "        contents=prompt\n",
                "    )\n",
                "    return response.text\n",
                "\n",
                "print(\"‚úÖ Section C: Brand Reasoner Ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "427ab1e5",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Section D: Ephemeral Live Fetch Ready\n"
                    ]
                }
            ],
            "source": [
                "# SECTION D: Ephemeral Live Fetch (Type C Memory)\n",
                "\n",
                "def ephemeral_live_fetch(query: str) -> str:\n",
                "    \"\"\"\n",
                "    Fetches live data for Type C memory.\n",
                "    Guaranteed NO persistence.\n",
                "    \"\"\"\n",
                "    print(f\"   üåê Triggering Ephemeral Live Fetch for: '{query}'\")\n",
                "    \n",
                "    prompt = f\"Search Google for: {query}. Summarize the answer in 2 sentences.\"\n",
                "    \n",
                "    response = client.models.generate_content(\n",
                "        model=\"gemini-2.5-flash\",\n",
                "        contents=prompt,\n",
                "        config=types.GenerateContentConfig(\n",
                "            tools=[types.Tool(google_search=types.GoogleSearchRetrieval)]\n",
                "        )\n",
                "    )\n",
                "    \n",
                "    # Extract text from response (ignoring grounding metadata for the summary text)\n",
                "    return response.text\n",
                "\n",
                "print(\"‚úÖ Section D: Ephemeral Live Fetch Ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "baea23a3",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- TEST 1: Grounding-Assisted Ingestion ---\n",
                        "\n",
                        "üåç Starting Grounding-Assisted Ingestion for Westinghouse India...\n",
                        "   ‚úÖ Extracted Grounded Data: ['brand_philosophy', 'design_principles', 'positioning']\n",
                        "   ‚úÖ Successfully stored Type B memory for Westinghouse India\n",
                        "\n",
                        "--- VERIFYING TYPE B ASSETS IN DB ---\n",
                        "‚úÖ Found 4 Type B assets in Postgres.\n",
                        "\n",
                        "--- TEST 3: Live Query with Ephemeral Context ---\n",
                        "\n",
                        "üîé Querying Brand wh_india_001 (UUID: 25ecf8da-150a-506d-aef6-7b2794b4b114) [strategy]: 'What are the latest appliance trends suitable for our brand?'\n",
                        "   [1] Score: 0.6952 | Content: All genders, 25‚Äì45 years (core). Upper-middle to affluent households. Interests: Premium home & kitc...\n",
                        "   [2] Score: 0.6818 | Content: . The brand is committed to delivering solutions that make appliances future-ready, emphasizing exce...\n",
                        "   [3] Score: 0.6783 | Content: . It is perceived as a forward-thinking brand offering durable, elegant, and future-ready technology...\n",
                        "   üåê Triggering Ephemeral Live Fetch for: 'What are the latest appliance trends suitable for our brand?'\n",
                        "\n",
                        "ü§ñ Final Response:\n",
                        "Our brand, known for its commitment to delivering future-ready, technologically advanced, and elegantly styled appliances, is perfectly positioned to leverage several emerging trends that resonate with our target demographic of upper-middle to affluent households (25-45 years) interested in premium home & kitchen solutions and smart living within Tier 1 metros and affluent Tier 2 cities.\n",
                        "\n",
                        "The most suitable appliance trends include:\n",
                        "\n",
                        "1.  **Intuitive Smart Technology & Enhanced Connectivity:** This trend directly aligns with our target audience's interest in \"Smart living\" and our brand's perception as \"forward-thinking\" and dedicated to \"technological advancement.\" Features such as AI-driven learning, optimized performance, and personalized recommendations, along with integration into fully connected home ecosystems, are essential for delivering \"solutions that make appliances future-ready\" and \"transform human experience,\" offering the \"high-performing\" investment our customers seek.\n",
                        "\n",
                        "2.  **Modern Kitchen Aesthetics & Customizable Designs:** Our brand is perceived as offering \"durable, elegant, and future-ready technology\" with an \"elegant style.\" This directly caters to our core audience's interest in \"Modern kitchen aesthetics.\" Customizable designs allow our customers to personalize their spaces, reinforcing the premium and sophisticated image associated with our brand.\n",
                        "\n",
                        "3.  **Multi-functional Solutions:** As a brand focused on \"delivering solutions that make appliances future-ready\" and enhancing the \"human experience,\" multi-functional appliances offer versatile utility that aligns with a smart, streamlined lifestyle. Such solutions contribute to the perception of \"high-performing, long-lasting appliances\" that offer true value.\n",
                        "\n",
                        "4.  **Energy Efficiency & Sustainability:** While not explicitly detailed in our core values, the emphasis on \"future-ready\" solutions and \"investment in high-performing, long-lasting appliances\" implicitly includes efficiency. Affluent households increasingly seek intelligent investments that align with responsible living, and energy-efficient appliances reflect a forward-thinking approach that contributes to both performance and long-term value.\n",
                        "\n",
                        "5.  **Health & Hygiene Features:** Integrating advanced features that promote health and hygiene directly contributes to our brand's mission to \"transform human experience.\" As our customers invest in premium, future-ready appliances, solutions that enhance well-being and simplify daily life reinforce the perception of high-performing, technologically advanced offerings.\n",
                        "\n",
                        "üîí Verifying Type C Non-Persistence...\n",
                        "‚úÖ SUCCESS: Live trend data NOT found in Postgres (ignoring intentional Type A/B).\n"
                    ]
                }
            ],
            "source": [
                "# SECTION E: v1.5 Validation Harness\n",
                "\n",
                "def run_v1_5_validation():\n",
                "    brand_id = \"wh_india_001\"\n",
                "    \n",
                "    # 1. Simulate Type B Ingestion\n",
                "    print(\"\\n--- TEST 1: Grounding-Assisted Ingestion ---\")\n",
                "    grounding_assisted_ingest(westinghouse_json)\n",
                "    \n",
                "    # VERIFICATION OF TYPE B ASSETS\n",
                "    print(\"\\n--- VERIFYING TYPE B ASSETS IN DB ---\")\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    try:\n",
                "        cur.execute(\"SELECT count(*) FROM brand_assets WHERE source LIKE '%grounding_assisted%'\")\n",
                "        count = cur.fetchone()[0]\n",
                "        print(f\"‚úÖ Found {count} Type B assets in Postgres.\")\n",
                "        if count == 0:\n",
                "             print(\"‚ùå ERROR: Type B ingestion failed (no rows affected).\")\n",
                "    finally:\n",
                "        cur.close()\n",
                "        conn.close()\n",
                "        \n",
                "    # 2. Rejection Logic (OMITTED AS REQUESTED)\n",
                "    # print(\"\\n--- TEST 2: Off-Brand Rejection ---\")\n",
                "\n",
                "    # 3. End-to-End Success + Type C\n",
                "    print(\"\\n--- TEST 3: Live Query with Ephemeral Context ---\")\n",
                "    good_query = \"What are the latest appliance trends suitable for our brand?\"\n",
                "    safety_3 = check_brand_safety(good_query, brand_id, \"justify_decision\")\n",
                "    \n",
                "    if safety_3['status'] == \"PASS\":\n",
                "        # Retrieve Memory (Type A/B)\n",
                "        context = retrieve_context(brand_id, good_query, \"strategy\")\n",
                "        \n",
                "        # Trigger Live Fetch (Type C)\n",
                "        type_c_data = ephemeral_live_fetch(good_query)\n",
                "        \n",
                "        # Reason\n",
                "        response = generate_brand_response(good_query, context, safety_3, type_c_data)\n",
                "        print(f\"\\nü§ñ Final Response:\\n{response}\")\n",
                "\n",
                "        # PROOF OF NO PERSISTENCE\n",
                "        print(\"\\nüîí Verifying Type C Non-Persistence...\")\n",
                "        conn = get_db_connection()\n",
                "        cur = conn.cursor()\n",
                "        # Search for 'trends' which comes from live fetch\n",
                "        # but ensure we don't count type B or A if they happened to have it.\n",
                "        # We specifically check for *recent* assets that are NOT type B/A?\n",
                "        # Simple check: search for 'trends' in text, but EXCLUDE source='grounding_assisted_ingestion'\n",
                "        cur.execute(\"SELECT count(*) FROM brand_assets WHERE raw_text ILIKE '%trends%' AND source NOT LIKE '%grounding_assisted%'\")\n",
                "        count = cur.fetchone()[0]\n",
                "        if count == 0:\n",
                "             print(\"‚úÖ SUCCESS: Live trend data NOT found in Postgres (ignoring intentional Type A/B).\")\n",
                "        else:\n",
                "             print(\"‚ö†Ô∏è NOTE: 'trends' keyword found. Verify it is not from ephemeral fetch.\")\n",
                "        cur.close()\n",
                "        conn.close()\n",
                "\n",
                "run_v1_5_validation()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "54cc52c8",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## **Brand Brain v1.6 - Memory Governance Upgrade**\n",
                "\n",
                "The following cells implement **Brand Brain v1.6** extensions, adding human-governed memory control, confidence scoring, and memory review workflows.\n",
                "\n",
                "**Upgrades:**\n",
                "1. **Schema**: Added `confidence` field (inferred/reviewed/approved/deprecated).\n",
                "2. **Retrieval**: Prioritizes approved memory; excludes deprecated memory.\n",
                "3. **Governance**: Added functions to approve, reject, and edit memory."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ [v1.6] Ingestion Logic Updated\n"
                    ]
                }
            ],
            "source": [
                "# [v1.6 UPGRADE] Redefining Ingestion to support Confidence Scoring\n",
                "\n",
                "def ingest_single_asset(asset: Dict, brand_data: Dict):\n",
                "    \"\"\"[v1.6] Helper to ingest a single constructed asset with confidence defaults.\"\"\"\n",
                "    brand_id_str = brand_data['brandId']\n",
                "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
                "    org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
                "    \n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    idx = pc.Index(\"brand-brain-index\")\n",
                "\n",
                "    try:\n",
                "        # Store Asset in Postgres\n",
                "        source_tag = f\"{asset['source_field']} | v1.6 | confidence:inferred\"\n",
                "        \n",
                "        # [MODIFIED v1.6] Explicitly inserting confidence='inferred'\n",
                "        # Note: We rely on the schema update (ADD COLUMN confidence) having been run.\n",
                "        cur.execute(\n",
                "            \"INSERT INTO brand_assets (asset_id, brand_id, asset_type, raw_text, source, confidence) VALUES (%s, %s, %s, %s, %s, %s) ON CONFLICT (asset_id) DO NOTHING\",\n",
                "            (asset['asset_id'], brand_uuid, asset['asset_type'], asset['content'], source_tag, 'inferred')\n",
                "        )\n",
                "\n",
                "        chunks = chunk_text(asset['content'])\n",
                "        for chunk_text_content in chunks:\n",
                "            chunk_id = str(uuid.uuid4())\n",
                "            embedding_id = str(uuid.uuid4())\n",
                "            vector = generate_embedding(chunk_text_content)\n",
                "            \n",
                "            if not vector: continue\n",
                "            \n",
                "            vt = asset.get('vector_type', 'strategy')\n",
                "\n",
                "            cur.execute(\n",
                "                \"INSERT INTO brand_chunks (chunk_id, asset_id, brand_id, vector_type, content, token_count) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
                "                (chunk_id, asset['asset_id'], brand_uuid, vt, chunk_text_content, len(chunk_text_content.split()))\n",
                "            )\n",
                "            \n",
                "            namespace = f\"{org_id}:{brand_uuid}:{vt}\"\n",
                "            \n",
                "            cur.execute(\n",
                "                 \"INSERT INTO embeddings (embedding_id, chunk_id, brand_id, vector_type, namespace, model) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
                "                (embedding_id, chunk_id, brand_uuid, vt, namespace, \"gemini-embedding-001\")\n",
                "            )\n",
                "            \n",
                "            idx.upsert(\n",
                "                vectors=[(chunk_id, vector, {\"source\": source_tag})],\n",
                "                namespace=namespace\n",
                "            )\n",
                "        \n",
                "        conn.commit()\n",
                "        print(f\"   ‚úÖ [v1.6] Successfully stored Type B memory for {brand_data['name']} (Confidence: Inferred)\")\n",
                "    except Exception as e:\n",
                "        conn.rollback()\n",
                "        print(f\"‚ùå Ingestion Error: {e}\")\n",
                "    finally:\n",
                "        cur.close()\n",
                "        conn.close()\n",
                "print(\"‚úÖ [v1.6] Ingestion Logic Updated\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ [v1.6] Retrieval Logic Updated\n"
                    ]
                }
            ],
            "source": [
                "# [v1.6 UPGRADE] Redefining Retrieval to Prioritize Confidence & Filter Deprecated\n",
                "\n",
                "def retrieve_context(brand_name_str: str, query: str, vector_type: str = \"brand_voice\", top_k: int = 3):\n",
                "    if brand_name_str == \"wh_india_001\":\n",
                "        brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_name_str))\n",
                "        org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
                "    else:\n",
                "        brand_uuid = brand_name_str\n",
                "        org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
                "\n",
                "    print(f\"\\nüîé [v1.6] Querying Brand {brand_name_str} (UUID: {brand_uuid}) [{vector_type}]: '{query}'\")\n",
                "    \n",
                "    try:\n",
                "        query_embedding_result = client.models.embed_content(\n",
                "            model=\"gemini-embedding-001\",\n",
                "            contents=query,\n",
                "            config={\n",
                "                'output_dimensionality': 768,\n",
                "                'task_type': 'RETRIEVAL_QUERY'\n",
                "            }\n",
                "        )\n",
                "        query_embedding = query_embedding_result.embeddings[0].values\n",
                "    except Exception as e:\n",
                "        print(f\"Embedding Error during retrieval: {e}\")\n",
                "        return []\n",
                "    \n",
                "    namespace = f\"{org_id}:{brand_uuid}:{vector_type}\"\n",
                "    index_name = \"brand-brain-index\"\n",
                "    idx = pc.Index(index_name)\n",
                "    \n",
                "    # Fetch more candidates to allow for filtering of deprecated items\n",
                "    results = idx.query(\n",
                "        vector=query_embedding,\n",
                "        top_k=top_k * 3,\n",
                "        namespace=namespace,\n",
                "        include_metadata=True\n",
                "    )\n",
                "    \n",
                "    if not results['matches']:\n",
                "        print(\"   ‚ö†Ô∏è No matches found in namespace:\", namespace)\n",
                "        return []\n",
                "        \n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    \n",
                "    retrieved_docs = []\n",
                "    chunk_ids = [m['id'] for m in results['matches']]\n",
                "    \n",
                "    if chunk_ids:\n",
                "        placeholders = ', '.join(['%s'] * len(chunk_ids))\n",
                "        # [MODIFIED v1.6] Join with brand_assets to fetch 'confidence'\n",
                "        query_sql = f\"\"\"\n",
                "            SELECT c.chunk_id, c.content, c.vector_type, a.confidence \n",
                "            FROM brand_chunks c\n",
                "            JOIN brand_assets a ON c.asset_id = a.asset_id\n",
                "            WHERE c.chunk_id IN ({placeholders})\n",
                "        \"\"\"\n",
                "        cur.execute(query_sql, tuple(chunk_ids))\n",
                "        rows = cur.fetchall()\n",
                "        \n",
                "        # Lookup map\n",
                "        db_map = {row[0]: {\"content\": row[1], \"confidence\": row[3]} for row in rows}\n",
                "        \n",
                "        valid_candidates = []\n",
                "        \n",
                "        for match in results['matches']:\n",
                "            c_id = match['id']\n",
                "            score = match['score']\n",
                "            if c_id not in db_map: \n",
                "                continue\n",
                "                \n",
                "            data = db_map[c_id]\n",
                "            confidence = data['confidence'] or 'inferred' # Handle legacy rows where confidence might be NULL\n",
                "            \n",
                "            # [RULE] Exclude Deprecated\n",
                "            if confidence == 'deprecated':\n",
                "                continue\n",
                "                \n",
                "            # [RULE] Prioritize: approved (3) > reviewed (2) > inferred (1)\n",
                "            priority_score = 1\n",
                "            if confidence == 'approved': priority_score = 3\n",
                "            elif confidence == 'reviewed': priority_score = 2\n",
                "            \n",
                "            valid_candidates.append({\n",
                "                \"content\": data['content'],\n",
                "                \"score\": score,\n",
                "                \"confidence\": confidence,\n",
                "                \"priority\": priority_score\n",
                "            })\n",
                "            \n",
                "        # Sort by Priority (desc), then Similarity Score (desc)\n",
                "        valid_candidates.sort(key=lambda x: (x['priority'], x['score']), reverse=True)\n",
                "        \n",
                "        # Return top_k\n",
                "        final_results = valid_candidates[:top_k]\n",
                "        \n",
                "        for i, res in enumerate(final_results):\n",
                "            print(f\"   [{i+1}] [{res['confidence'].upper()}] Score: {res['score']:.4f} | Content: {res['content'][:100]}...\")\n",
                "            retrieved_docs.append(res)\n",
                "            \n",
                "    cur.close()\n",
                "    conn.close()\n",
                "    return retrieved_docs\n",
                "print(\"‚úÖ [v1.6] Retrieval Logic Updated\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ [v1.6] Section C: Functions Ready\n"
                    ]
                }
            ],
            "source": [
                "# SECTION C: Memory Review Functions (v1.6)\n",
                "\n",
                "def list_inferred_assets(brand_id_str: str):\n",
                "    print(f\"\\nüìã Listing Inferred Assets for {brand_id_str}...\")\n",
                "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor(cursor_factory=RealDictCursor)\n",
                "    cur.execute(\"SELECT asset_id, asset_type, raw_text, source, confidence FROM brand_assets WHERE brand_id = %s AND confidence = 'inferred'\", (brand_uuid,))\n",
                "    rows = cur.fetchall()\n",
                "    cur.close()\n",
                "    conn.close()\n",
                "    for r in rows:\n",
                "        print(f\"   [ID: {r['asset_id']}] {r['raw_text'][:50]}... (Source: {r['source']})\")\n",
                "    return rows\n",
                "\n",
                "def approve_asset(asset_id: str, reviewer: str, notes: str):\n",
                "    print(f\"\\n‚úÖ Approving Asset {asset_id}...\")\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    try:\n",
                "        cur.execute(\"SELECT confidence FROM brand_assets WHERE asset_id = %s\", (asset_id,))\n",
                "        res = cur.fetchone()\n",
                "        if not res: return\n",
                "        prev_conf = res[0]\n",
                "        cur.execute(\"UPDATE brand_assets SET confidence = 'approved', reviewed_by = %s, review_notes = %s, reviewed_at = NOW() WHERE asset_id = %s\", (reviewer, notes, asset_id))\n",
                "        cur.execute(\"INSERT INTO memory_reviews (review_id, asset_id, action, previous_confidence, new_confidence, reviewer, notes) VALUES (%s, %s, %s, %s, %s, %s, %s)\", (str(uuid.uuid4()), asset_id, 'approve', prev_conf, 'approved', reviewer, notes))\n",
                "        conn.commit()\n",
                "        print(\"   -> Asset Approved.\")\n",
                "    except Exception as e:\n",
                "        conn.rollback(); print(f\"‚ùå {e}\")\n",
                "    finally:\n",
                "        cur.close(); conn.close()\n",
                "\n",
                "def reject_asset(asset_id: str, reviewer: str, notes: str):\n",
                "    print(f\"\\n‚õî Rejecting Asset {asset_id}...\")\n",
                "    conn = get_db_connection(); cur = conn.cursor()\n",
                "    try:\n",
                "        cur.execute(\"SELECT confidence FROM brand_assets WHERE asset_id = %s\", (asset_id,))\n",
                "        res = cur.fetchone()\n",
                "        if not res: return\n",
                "        prev_conf = res[0]\n",
                "        cur.execute(\"UPDATE brand_assets SET confidence = 'deprecated', reviewed_by = %s, review_notes = %s, reviewed_at = NOW() WHERE asset_id = %s\", (reviewer, notes, asset_id))\n",
                "        cur.execute(\"INSERT INTO memory_reviews (review_id, asset_id, action, previous_confidence, new_confidence, reviewer, notes) VALUES (%s, %s, %s, %s, %s, %s, %s)\", (str(uuid.uuid4()), asset_id, 'deprecate', prev_conf, 'deprecated', reviewer, notes))\n",
                "        conn.commit()\n",
                "        print(\"   -> Asset Deprecated.\")\n",
                "    except Exception as e:\n",
                "        conn.rollback(); print(f\"‚ùå {e}\")\n",
                "    finally:\n",
                "        cur.close(); conn.close()\n",
                "\n",
                "def edit_and_promote_asset(asset_id: str, new_text: str, reviewer: str):\n",
                "    print(f\"\\nüìù Editing & Promoting Asset {asset_id}...\")\n",
                "    conn = get_db_connection(); cur = conn.cursor(cursor_factory=RealDictCursor)\n",
                "    try:\n",
                "        cur.execute(\"SELECT * FROM brand_assets WHERE asset_id = %s\", (asset_id,))\n",
                "        original = cur.fetchone()\n",
                "        if not original: return\n",
                "        # Deprecate Old\n",
                "        cur.execute(\"UPDATE brand_assets SET confidence = 'deprecated', reviewed_by = %s, review_notes = 'Replaced by edit', reviewed_at = NOW() WHERE asset_id = %s\", (reviewer, asset_id))\n",
                "        # Insert New Approved\n",
                "        new_asset_id = str(uuid.uuid4())\n",
                "        cur.execute(\"INSERT INTO brand_assets (asset_id, brand_id, asset_type, raw_text, source, confidence, reviewed_by, reviewed_at, review_notes) VALUES (%s, %s, %s, %s, %s, %s, %s, NOW(), 'Created via Edit')\", (new_asset_id, original['brand_id'], original['asset_type'], new_text, original['source'], 'approved', reviewer))\n",
                "        conn.commit()\n",
                "        print(f\"   -> Old Asset Deprecated. New Asset {new_asset_id} Created.\")\n",
                "        # Chunk & Embed New Asset\n",
                "        chunks = chunk_text(new_text)\n",
                "        idx = pc.Index(\"brand-brain-index\")\n",
                "        org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
                "        # Need vector_type\n",
                "        cur.execute(\"SELECT vector_type FROM brand_chunks WHERE asset_id = %s LIMIT 1\", (asset_id,))\n",
                "        vt = cur.fetchone()['vector_type']\n",
                "        for i, chunk in enumerate(chunks):\n",
                "            chunk_id = str(uuid.uuid4())\n",
                "            vec = generate_embedding(chunk)\n",
                "            cur.execute(\"INSERT INTO brand_chunks (chunk_id, asset_id, brand_id, vector_type, content, token_count) VALUES (%s, %s, %s, %s, %s, %s)\", (chunk_id, new_asset_id, original['brand_id'], vt, chunk, len(chunk.split())))\n",
                "            cur.execute(\"INSERT INTO embeddings (embedding_id, chunk_id, brand_id, vector_type, namespace, model) VALUES (%s, %s, %s, %s, %s, %s)\", (str(uuid.uuid4()), chunk_id, original['brand_id'], vt, f\"{org_id}:{original['brand_id']}:{vt}\", \"gemini-embedding-001\"))\n",
                "            idx.upsert(vectors=[(chunk_id, vec, {\"source\": original['source']})], namespace=f\"{org_id}:{original['brand_id']}:{vt}\")\n",
                "        conn.commit()\n",
                "        print(\"   -> New/Edited Asset Embeddings Generated.\")\n",
                "    except Exception as e:\n",
                "        conn.rollback(); print(f\"‚ùå Edit Failed: {e}\")\n",
                "    finally:\n",
                "        cur.close(); conn.close()\n",
                "print(\"‚úÖ [v1.6] Section C: Functions Ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "--- üß™ TEST 1: Ingestion starts as 'inferred' ---\n",
                        "‚úÖ Found 12 'inferred' assets\n",
                        "\n",
                        "--- üß™ TEST 2: Retrieval Priority (Approved > Inferred) [brand_voice] ---\n",
                        "\n",
                        "üìã Listing Inferred Assets for wh_india_001...\n",
                        "   [ID: 7bc146d0-7068-486b-bc28-4da657e10966] Morphy Richards (Strong British Heritage, Wide Por... (Source: competitors)\n",
                        "   [ID: d70f75c2-a5be-485f-864a-a7c5842a48bf] Morphy Richards... (Source: inspiration)\n",
                        "   [ID: 93215377-316d-4130-b009-4fb6136c437d] https://www.westinghousehomeware.in/... (Source: website)\n",
                        "   [ID: 870e34f5-8969-42d0-90ab-b07309685a65] To enrich everyday living with reliable, thoughtfu... (Source: mission)\n",
                        "   [ID: cc087901-bafe-4b2e-baff-3775407863b9] All genders, 25‚Äì45 years (core). Upper-middle to a... (Source: audience)\n",
                        "   [ID: 5f50d7d9-d4f0-4eb7-aa94-4bab4ce2a09b] Morphy Richards (Strong British Heritage, Wide Por... (Source: competitors)\n",
                        "   [ID: 0044f9e9-e6f4-4ec3-90ed-b93155d759be] Morphy Richards... (Source: inspiration)\n",
                        "   [ID: aae3ebaa-70d4-43fd-ba63-c278bffa4ffd] https://www.westinghousehomeware.in/... (Source: website)\n",
                        "   [ID: 514cdb81-822d-4fc9-b961-e634fe77e07e] Philosophy: Westinghouse's philosophy is to power ... (Source: grounding_assisted_ingestion | v1.5 | confidence:inferred)\n",
                        "   [ID: 6d446544-6ba4-45c9-9370-b011901f556d] Philosophy: At Westinghouse, the mission is to pow... (Source: grounding_assisted_ingestion | v1.5 | confidence:inferred)\n",
                        "   [ID: 9087537c-4800-41ae-9596-ea161900216a] Philosophy: Westinghouse's mission is to power mea... (Source: grounding_assisted_ingestion | v1.5 | confidence:inferred)\n",
                        "   [ID: e58d9a92-da98-44f2-863b-b2549b9a2ddd] Philosophy: Westinghouse is driven by a mission to... (Source: grounding_assisted_ingestion | v1.5 | confidence:inferred)\n",
                        "‚ùå No inferred brand_voice asset found to test.\n",
                        "\n",
                        "--- üß™ TEST 3: Deprecation (Exclude from Retrieval) ---\n",
                        "‚ö†Ô∏è Skipping TEST 3: No approved asset available.\n",
                        "\n",
                        "--- üß™ TEST 4: Audit Trail ---\n",
                        "   - Action: approve | Old: inferred -> New: approved\n",
                        "   - Action: approve | Old: inferred -> New: approved\n",
                        "   - Action: deprecate | Old: approved -> New: deprecated\n",
                        "   - Action: approve | Old: inferred -> New: approved\n",
                        "   - Action: deprecate | Old: approved -> New: deprecated\n",
                        "\n",
                        "\n",
                        "--- üß™ TEST 1: Ingestion starts as 'inferred' ---\n",
                        "‚úÖ Found 12 'inferred' assets\n",
                        "\n",
                        "--- üß™ TEST 2: Retrieval Priority (Approved > Inferred) [brand_voice] ---\n",
                        "‚ö†Ô∏è No inferred brand_voice asset available. TEST 2 skipped (expected if already curated).\n",
                        "\n",
                        "--- üß™ TEST 3: Deprecation (Exclude from Retrieval) ---\n",
                        "‚ö†Ô∏è Skipping TEST 3: No approved asset available.\n",
                        "\n",
                        "--- üß™ TEST 4: Audit Trail ---\n",
                        "   - Action: approve | Old: inferred -> New: approved\n",
                        "   - Action: approve | Old: inferred -> New: approved\n",
                        "   - Action: deprecate | Old: approved -> New: deprecated\n",
                        "   - Action: approve | Old: inferred -> New: approved\n",
                        "   - Action: deprecate | Old: approved -> New: deprecated\n"
                    ]
                }
            ],
            "source": [
                "# SECTION D: Validation Tests (v1.6)\n",
                "\n",
                "def run_v1_6_validation():\n",
                "    brand_id_str = \"wh_india_001\"\n",
                "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
                "\n",
                "    approved_asset_id = None\n",
                "    approved_asset_text = None\n",
                "\n",
                "    print(\"\\n\\n--- üß™ TEST 1: Ingestion starts as 'inferred' ---\")\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    cur.execute(\n",
                "        \"SELECT count(*) FROM brand_assets WHERE brand_id = %s AND confidence = 'inferred'\",\n",
                "        (brand_uuid,)\n",
                "    )\n",
                "    count = cur.fetchone()[0]\n",
                "    cur.close()\n",
                "    conn.close()\n",
                "    print(f\"‚úÖ Found {count} 'inferred' assets\")\n",
                "\n",
                "    # -------------------------------------------------\n",
                "\n",
                "    print(\"\\n--- üß™ TEST 2: Retrieval Priority (Approved > Inferred) [brand_voice] ---\")\n",
                "\n",
                "    # 1Ô∏è‚É£ List inferred assets\n",
                "    inferred = list_inferred_assets(brand_id_str)\n",
                "\n",
                "    # 2Ô∏è‚É£ Select an inferred BRAND_VOICE asset explicitly\n",
                "    brand_voice_target = None\n",
                "    for asset in inferred:\n",
                "        if asset[\"source\"] in [\"brandVoice\", \"visualStyle\"]:\n",
                "            brand_voice_target = asset\n",
                "            break\n",
                "\n",
                "    if not brand_voice_target:\n",
                "        print(\"‚ùå No inferred brand_voice asset found to test.\")\n",
                "    else:\n",
                "        approved_asset_id = brand_voice_target[\"asset_id\"]\n",
                "        approved_asset_text = brand_voice_target[\"raw_text\"]\n",
                "\n",
                "        print(\n",
                "            f\"   üéØ Targeting Brand Voice Asset: \"\n",
                "            f\"{approved_asset_text[:40]}...\"\n",
                "        )\n",
                "\n",
                "        # 3Ô∏è‚É£ Approve the brand_voice asset\n",
                "        approve_asset(\n",
                "            approved_asset_id,\n",
                "            reviewer=\"Admin\",\n",
                "            notes=\"Approved brand voice memory\"\n",
                "        )\n",
                "\n",
                "        # 4Ô∏è‚É£ Query SAME semantic space + namespace\n",
                "        res = retrieve_context(\n",
                "            brand_id_str,\n",
                "            \"design philosophy\",\n",
                "            \"brand_voice\"\n",
                "        )\n",
                "\n",
                "        # 5Ô∏è‚É£ Assert approved asset is prioritized\n",
                "        if res and res[0][\"confidence\"] == \"approved\":\n",
                "            print(\"‚úÖ SUCCESS: Approved brand_voice asset correctly prioritized.\")\n",
                "        else:\n",
                "            print(\n",
                "                f\"‚ùå FAILURE: Expected approved asset first, got \"\n",
                "                f\"{res[0]['confidence'] if res else 'None'}\"\n",
                "            )\n",
                "\n",
                "    # -------------------------------------------------\n",
                "\n",
                "    print(\"\\n--- üß™ TEST 3: Deprecation (Exclude from Retrieval) ---\")\n",
                "\n",
                "    if approved_asset_id:\n",
                "        reject_asset(\n",
                "            approved_asset_id,\n",
                "            reviewer=\"Admin\",\n",
                "            notes=\"Deprecating for validation test\"\n",
                "        )\n",
                "\n",
                "        res = retrieve_context(\n",
                "            brand_id_str,\n",
                "            \"design philosophy\",\n",
                "            \"brand_voice\"\n",
                "        )\n",
                "\n",
                "        found = any(\n",
                "            d[\"content\"] == approved_asset_text\n",
                "            for d in res\n",
                "        )\n",
                "\n",
                "        if not found:\n",
                "            print(\"‚úÖ Deprecated asset successfully EXCLUDED.\")\n",
                "        else:\n",
                "            print(\"‚ùå FAILURE: Deprecated asset still retrieved!\")\n",
                "\n",
                "    else:\n",
                "        print(\"‚ö†Ô∏è Skipping TEST 3: No approved asset available.\")\n",
                "\n",
                "    # -------------------------------------------------\n",
                "\n",
                "    print(\"\\n--- üß™ TEST 4: Audit Trail ---\")\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    cur.execute(\n",
                "        \"SELECT action, previous_confidence, new_confidence \"\n",
                "        \"FROM memory_reviews ORDER BY created_at DESC LIMIT 5\"\n",
                "    )\n",
                "    rows = cur.fetchall()\n",
                "    cur.close()\n",
                "    conn.close()\n",
                "\n",
                "    for r in rows:\n",
                "        print(f\"   - Action: {r[0]} | Old: {r[1]} -> New: {r[2]}\")\n",
                "\n",
                "# Run validation\n",
                "run_v1_6_validation()# SECTION D: Validation Tests (v1.6)\n",
                "\n",
                "def run_v1_6_validation():\n",
                "    brand_id_str = \"wh_india_001\"\n",
                "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
                "\n",
                "    approved_asset_id = None\n",
                "    approved_asset_text = None\n",
                "\n",
                "    print(\"\\n\\n--- üß™ TEST 1: Ingestion starts as 'inferred' ---\")\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    cur.execute(\n",
                "        \"SELECT count(*) FROM brand_assets WHERE brand_id = %s AND confidence = 'inferred'\",\n",
                "        (brand_uuid,)\n",
                "    )\n",
                "    count = cur.fetchone()[0]\n",
                "    cur.close()\n",
                "    conn.close()\n",
                "    print(f\"‚úÖ Found {count} 'inferred' assets\")\n",
                "\n",
                "    # -------------------------------------------------\n",
                "\n",
                "    print(\"\\n--- üß™ TEST 2: Retrieval Priority (Approved > Inferred) [brand_voice] ---\")\n",
                "\n",
                "    # üîé Find an inferred BRAND_VOICE asset via DB (robust)\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    cur.execute(\"\"\"\n",
                "        SELECT a.asset_id, a.raw_text\n",
                "        FROM brand_assets a\n",
                "        JOIN brand_chunks c ON a.asset_id = c.asset_id\n",
                "        WHERE a.brand_id = %s\n",
                "          AND a.confidence = 'inferred'\n",
                "          AND c.vector_type = 'brand_voice'\n",
                "        LIMIT 1\n",
                "    \"\"\", (brand_uuid,))\n",
                "    row = cur.fetchone()\n",
                "    cur.close()\n",
                "    conn.close()\n",
                "\n",
                "    if not row:\n",
                "        print(\"‚ö†Ô∏è No inferred brand_voice asset available. TEST 2 skipped (expected if already curated).\")\n",
                "    else:\n",
                "        approved_asset_id, approved_asset_text = row\n",
                "\n",
                "        print(f\"   üéØ Targeting Brand Voice Asset: {approved_asset_text[:40]}...\")\n",
                "\n",
                "        approve_asset(\n",
                "            approved_asset_id,\n",
                "            reviewer=\"Admin\",\n",
                "            notes=\"Approved brand voice memory (v1.6 validation)\"\n",
                "        )\n",
                "\n",
                "        res = retrieve_context(\n",
                "            brand_id_str,\n",
                "            \"design philosophy\",\n",
                "            \"brand_voice\"\n",
                "        )\n",
                "\n",
                "        if res and res[0][\"confidence\"] == \"approved\":\n",
                "            print(\"‚úÖ SUCCESS: Approved brand_voice asset correctly prioritized.\")\n",
                "        else:\n",
                "            print(\n",
                "                f\"‚ùå FAILURE: Expected approved asset first, got \"\n",
                "                f\"{res[0]['confidence'] if res else 'None'}\"\n",
                "            )\n",
                "\n",
                "    # -------------------------------------------------\n",
                "\n",
                "    print(\"\\n--- üß™ TEST 3: Deprecation (Exclude from Retrieval) ---\")\n",
                "\n",
                "    if approved_asset_id:\n",
                "        reject_asset(\n",
                "            approved_asset_id,\n",
                "            reviewer=\"Admin\",\n",
                "            notes=\"Deprecating for validation test\"\n",
                "        )\n",
                "\n",
                "        res = retrieve_context(\n",
                "            brand_id_str,\n",
                "            \"design philosophy\",\n",
                "            \"brand_voice\"\n",
                "        )\n",
                "\n",
                "        found = any(\n",
                "            d[\"content\"] == approved_asset_text\n",
                "            for d in res\n",
                "        )\n",
                "\n",
                "        if not found:\n",
                "            print(\"‚úÖ Deprecated asset successfully EXCLUDED.\")\n",
                "        else:\n",
                "            print(\"‚ùå FAILURE: Deprecated asset still retrieved!\")\n",
                "    else:\n",
                "        print(\"‚ö†Ô∏è Skipping TEST 3: No approved asset available.\")\n",
                "\n",
                "    # -------------------------------------------------\n",
                "\n",
                "    print(\"\\n--- üß™ TEST 4: Audit Trail ---\")\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    cur.execute(\"\"\"\n",
                "        SELECT action, previous_confidence, new_confidence\n",
                "        FROM memory_reviews\n",
                "        ORDER BY created_at DESC\n",
                "        LIMIT 5\n",
                "    \"\"\")\n",
                "    rows = cur.fetchall()\n",
                "    cur.close()\n",
                "    conn.close()\n",
                "\n",
                "    for r in rows:\n",
                "        print(f\"   - Action: {r[0]} | Old: {r[1]} -> New: {r[2]}\")\n",
                "\n",
                "# Run validation\n",
                "run_v1_6_validation()\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "babf71fa",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "94505d3c",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.3"
        },
        "nbformat": 4,
        "nbformat_minor": 2
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
