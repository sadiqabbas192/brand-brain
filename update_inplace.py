
import json
import os
import uuid

# Load v1.5
notebook_path = 'brand_brain_v1.5.ipynb'
with open(notebook_path, 'r', encoding='utf-8') as f:
    nb = json.load(f)

# Define New Cells
new_cells = []

# Header for v1.6
new_cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "## **Brand Brain v1.6 - Memory Governance Upgrade**\n",
        "\n",
        "The following cells implement **Brand Brain v1.6** extensions, adding human-governed memory control, confidence scoring, and memory review workflows.\n",
        "\n",
        "**Upgrades:**\n",
        "1. **Schema**: Added `confidence` field (inferred/reviewed/approved/deprecated).\n",
        "2. **Retrieval**: Prioritizes approved memory; excludes deprecated memory.\n",
        "3. **Governance**: Added functions to approve, reject, and edit memory."
    ]
})

# Redefined Ingestion (Section A)
ingest_code = [
    "# [v1.6 UPGRADE] Redefining Ingestion to support Confidence Scoring\n",
    "\n",
    "def ingest_single_asset(asset: Dict, brand_data: Dict):\n",
    "    \"\"\"[v1.6] Helper to ingest a single constructed asset with confidence defaults.\"\"\"\n",
    "    brand_id_str = brand_data['brandId']\n",
    "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
    "    org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
    "    \n",
    "    conn = get_db_connection()\n",
    "    cur = conn.cursor()\n",
    "    idx = pc.Index(\"brand-brain-index\")\n",
    "\n",
    "    try:\n",
    "        # Store Asset in Postgres\n",
    "        source_tag = f\"{asset['source_field']} | v1.6 | confidence:inferred\"\n",
    "        \n",
    "        # [MODIFIED v1.6] Explicitly inserting confidence='inferred'\n",
    "        # Note: We rely on the schema update (ADD COLUMN confidence) having been run.\n",
    "        cur.execute(\n",
    "            \"INSERT INTO brand_assets (asset_id, brand_id, asset_type, raw_text, source, confidence) VALUES (%s, %s, %s, %s, %s, %s) ON CONFLICT (asset_id) DO NOTHING\",\n",
    "            (asset['asset_id'], brand_uuid, asset['asset_type'], asset['content'], source_tag, 'inferred')\n",
    "        )\n",
    "\n",
    "        chunks = chunk_text(asset['content'])\n",
    "        for chunk_text_content in chunks:\n",
    "            chunk_id = str(uuid.uuid4())\n",
    "            embedding_id = str(uuid.uuid4())\n",
    "            vector = generate_embedding(chunk_text_content)\n",
    "            \n",
    "            if not vector: continue\n",
    "            \n",
    "            vt = asset.get('vector_type', 'strategy')\n",
    "\n",
    "            cur.execute(\n",
    "                \"INSERT INTO brand_chunks (chunk_id, asset_id, brand_id, vector_type, content, token_count) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
    "                (chunk_id, asset['asset_id'], brand_uuid, vt, chunk_text_content, len(chunk_text_content.split()))\n",
    "            )\n",
    "            \n",
    "            namespace = f\"{org_id}:{brand_uuid}:{vt}\"\n",
    "            \n",
    "            cur.execute(\n",
    "                 \"INSERT INTO embeddings (embedding_id, chunk_id, brand_id, vector_type, namespace, model) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
    "                (embedding_id, chunk_id, brand_uuid, vt, namespace, \"gemini-embedding-001\")\n",
    "            )\n",
    "            \n",
    "            idx.upsert(\n",
    "                vectors=[(chunk_id, vector, {\"source\": source_tag})],\n",
    "                namespace=namespace\n",
    "            )\n",
    "        \n",
    "        conn.commit()\n",
    "        print(f\"   âœ… [v1.6] Successfully stored Type B memory for {brand_data['name']} (Confidence: Inferred)\")\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"âŒ Ingestion Error: {e}\")\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "print(\"âœ… [v1.6] Ingestion Logic Updated\")"
]
new_cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "source": ingest_code
})

# Redefined Retrieval (Section B)
retrieve_code = [
    "# [v1.6 UPGRADE] Redefining Retrieval to Prioritize Confidence & Filter Deprecated\n",
    "\n",
    "def retrieve_context(brand_name_str: str, query: str, vector_type: str = \"brand_voice\", top_k: int = 3):\n",
    "    if brand_name_str == \"wh_india_001\":\n",
    "        brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_name_str))\n",
    "        org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
    "    else:\n",
    "        brand_uuid = brand_name_str\n",
    "        org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
    "\n",
    "    print(f\"\\nðŸ”Ž [v1.6] Querying Brand {brand_name_str} (UUID: {brand_uuid}) [{vector_type}]: '{query}'\")\n",
    "    \n",
    "    try:\n",
    "        query_embedding_result = client.models.embed_content(\n",
    "            model=\"gemini-embedding-001\",\n",
    "            contents=query,\n",
    "            config={\n",
    "                'output_dimensionality': 768,\n",
    "                'task_type': 'RETRIEVAL_QUERY'\n",
    "            }\n",
    "        )\n",
    "        query_embedding = query_embedding_result.embeddings[0].values\n",
    "    except Exception as e:\n",
    "        print(f\"Embedding Error during retrieval: {e}\")\n",
    "        return []\n",
    "    \n",
    "    namespace = f\"{org_id}:{brand_uuid}:{vector_type}\"\n",
    "    index_name = \"brand-brain-index\"\n",
    "    idx = pc.Index(index_name)\n",
    "    \n",
    "    # Fetch more candidates to allow for filtering of deprecated items\n",
    "    results = idx.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=top_k * 3,\n",
    "        namespace=namespace,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    \n",
    "    if not results['matches']:\n",
    "        print(\"   âš ï¸ No matches found in namespace:\", namespace)\n",
    "        return []\n",
    "        \n",
    "    conn = get_db_connection()\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    retrieved_docs = []\n",
    "    chunk_ids = [m['id'] for m in results['matches']]\n",
    "    \n",
    "    if chunk_ids:\n",
    "        placeholders = ', '.join(['%s'] * len(chunk_ids))\n",
    "        # [MODIFIED v1.6] Join with brand_assets to fetch 'confidence'\n",
    "        query_sql = f\"\"\"\n",
    "            SELECT c.chunk_id, c.content, c.vector_type, a.confidence \n",
    "            FROM brand_chunks c\n",
    "            JOIN brand_assets a ON c.asset_id = a.asset_id\n",
    "            WHERE c.chunk_id IN ({placeholders})\n",
    "        \"\"\"\n",
    "        cur.execute(query_sql, tuple(chunk_ids))\n",
    "        rows = cur.fetchall()\n",
    "        \n",
    "        # Lookup map\n",
    "        db_map = {row[0]: {\"content\": row[1], \"confidence\": row[3]} for row in rows}\n",
    "        \n",
    "        valid_candidates = []\n",
    "        \n",
    "        for match in results['matches']:\n",
    "            c_id = match['id']\n",
    "            score = match['score']\n",
    "            if c_id not in db_map: \n",
    "                continue\n",
    "                \n",
    "            data = db_map[c_id]\n",
    "            confidence = data['confidence'] or 'inferred' # Handle legacy rows where confidence might be NULL\n",
    "            \n",
    "            # [RULE] Exclude Deprecated\n",
    "            if confidence == 'deprecated':\n",
    "                continue\n",
    "                \n",
    "            # [RULE] Prioritize: approved (3) > reviewed (2) > inferred (1)\n",
    "            priority_score = 1\n",
    "            if confidence == 'approved': priority_score = 3\n",
    "            elif confidence == 'reviewed': priority_score = 2\n",
    "            \n",
    "            valid_candidates.append({\n",
    "                \"content\": data['content'],\n",
    "                \"score\": score,\n",
    "                \"confidence\": confidence,\n",
    "                \"priority\": priority_score\n",
    "            })\n",
    "            \n",
    "        # Sort by Priority (desc), then Similarity Score (desc)\n",
    "        valid_candidates.sort(key=lambda x: (x['priority'], x['score']), reverse=True)\n",
    "        \n",
    "        # Return top_k\n",
    "        final_results = valid_candidates[:top_k]\n",
    "        \n",
    "        for i, res in enumerate(final_results):\n",
    "            print(f\"   [{i+1}] [{res['confidence'].upper()}] Score: {res['score']:.4f} | Content: {res['content'][:100]}...\")\n",
    "            retrieved_docs.append(res)\n",
    "            \n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return retrieved_docs\n",
    "print(\"âœ… [v1.6] Retrieval Logic Updated\")"
]
new_cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "source": retrieve_code
})

# Section C
review_funcs = [
    "# SECTION C: Memory Review Functions (v1.6)\n",
    "\n",
    "def list_inferred_assets(brand_id_str: str):\n",
    "    print(f\"\\nðŸ“‹ Listing Inferred Assets for {brand_id_str}...\")\n",
    "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
    "    conn = get_db_connection()\n",
    "    cur = conn.cursor(cursor_factory=RealDictCursor)\n",
    "    cur.execute(\"SELECT asset_id, asset_type, raw_text, source, confidence FROM brand_assets WHERE brand_id = %s AND confidence = 'inferred'\", (brand_uuid,))\n",
    "    rows = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    for r in rows:\n",
    "        print(f\"   [ID: {r['asset_id']}] {r['raw_text'][:50]}... (Source: {r['source']})\")\n",
    "    return rows\n",
    "\n",
    "def approve_asset(asset_id: str, reviewer: str, notes: str):\n",
    "    print(f\"\\nâœ… Approving Asset {asset_id}...\")\n",
    "    conn = get_db_connection()\n",
    "    cur = conn.cursor()\n",
    "    try:\n",
    "        cur.execute(\"SELECT confidence FROM brand_assets WHERE asset_id = %s\", (asset_id,))\n",
    "        res = cur.fetchone()\n",
    "        if not res: return\n",
    "        prev_conf = res[0]\n",
    "        cur.execute(\"UPDATE brand_assets SET confidence = 'approved', reviewed_by = %s, review_notes = %s, reviewed_at = NOW() WHERE asset_id = %s\", (reviewer, notes, asset_id))\n",
    "        cur.execute(\"INSERT INTO memory_reviews (review_id, asset_id, action, previous_confidence, new_confidence, reviewer, notes) VALUES (%s, %s, %s, %s, %s, %s, %s)\", (str(uuid.uuid4()), asset_id, 'approve', prev_conf, 'approved', reviewer, notes))\n",
    "        conn.commit()\n",
    "        print(\"   -> Asset Approved.\")\n",
    "    except Exception as e:\n",
    "        conn.rollback(); print(f\"âŒ {e}\")\n",
    "    finally:\n",
    "        cur.close(); conn.close()\n",
    "\n",
    "def reject_asset(asset_id: str, reviewer: str, notes: str):\n",
    "    print(f\"\\nâ›” Rejecting Asset {asset_id}...\")\n",
    "    conn = get_db_connection(); cur = conn.cursor()\n",
    "    try:\n",
    "        cur.execute(\"SELECT confidence FROM brand_assets WHERE asset_id = %s\", (asset_id,))\n",
    "        res = cur.fetchone()\n",
    "        if not res: return\n",
    "        prev_conf = res[0]\n",
    "        cur.execute(\"UPDATE brand_assets SET confidence = 'deprecated', reviewed_by = %s, review_notes = %s, reviewed_at = NOW() WHERE asset_id = %s\", (reviewer, notes, asset_id))\n",
    "        cur.execute(\"INSERT INTO memory_reviews (review_id, asset_id, action, previous_confidence, new_confidence, reviewer, notes) VALUES (%s, %s, %s, %s, %s, %s, %s)\", (str(uuid.uuid4()), asset_id, 'deprecate', prev_conf, 'deprecated', reviewer, notes))\n",
    "        conn.commit()\n",
    "        print(\"   -> Asset Deprecated.\")\n",
    "    except Exception as e:\n",
    "        conn.rollback(); print(f\"âŒ {e}\")\n",
    "    finally:\n",
    "        cur.close(); conn.close()\n",
    "\n",
    "def edit_and_promote_asset(asset_id: str, new_text: str, reviewer: str):\n",
    "    print(f\"\\nðŸ“ Editing & Promoting Asset {asset_id}...\")\n",
    "    conn = get_db_connection(); cur = conn.cursor(cursor_factory=RealDictCursor)\n",
    "    try:\n",
    "        cur.execute(\"SELECT * FROM brand_assets WHERE asset_id = %s\", (asset_id,))\n",
    "        original = cur.fetchone()\n",
    "        if not original: return\n",
    "        # Deprecate Old\n",
    "        cur.execute(\"UPDATE brand_assets SET confidence = 'deprecated', reviewed_by = %s, review_notes = 'Replaced by edit', reviewed_at = NOW() WHERE asset_id = %s\", (reviewer, asset_id))\n",
    "        # Insert New Approved\n",
    "        new_asset_id = str(uuid.uuid4())\n",
    "        cur.execute(\"INSERT INTO brand_assets (asset_id, brand_id, asset_type, raw_text, source, confidence, reviewed_by, reviewed_at, review_notes) VALUES (%s, %s, %s, %s, %s, %s, %s, NOW(), 'Created via Edit')\", (new_asset_id, original['brand_id'], original['asset_type'], new_text, original['source'], 'approved', reviewer))\n",
    "        conn.commit()\n",
    "        print(f\"   -> Old Asset Deprecated. New Asset {new_asset_id} Created.\")\n",
    "        # Chunk & Embed New Asset\n",
    "        chunks = chunk_text(new_text)\n",
    "        idx = pc.Index(\"brand-brain-index\")\n",
    "        org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
    "        # Need vector_type\n",
    "        cur.execute(\"SELECT vector_type FROM brand_chunks WHERE asset_id = %s LIMIT 1\", (asset_id,))\n",
    "        vt = cur.fetchone()['vector_type']\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            chunk_id = str(uuid.uuid4())\n",
    "            vec = generate_embedding(chunk)\n",
    "            cur.execute(\"INSERT INTO brand_chunks (chunk_id, asset_id, brand_id, vector_type, content, token_count) VALUES (%s, %s, %s, %s, %s, %s)\", (chunk_id, new_asset_id, original['brand_id'], vt, chunk, len(chunk.split())))\n",
    "            cur.execute(\"INSERT INTO embeddings (embedding_id, chunk_id, brand_id, vector_type, namespace, model) VALUES (%s, %s, %s, %s, %s, %s)\", (str(uuid.uuid4()), chunk_id, original['brand_id'], vt, f\"{org_id}:{original['brand_id']}:{vt}\", \"gemini-embedding-001\"))\n",
    "            idx.upsert(vectors=[(chunk_id, vec, {\"source\": original['source']})], namespace=f\"{org_id}:{original['brand_id']}:{vt}\")\n",
    "        conn.commit()\n",
    "        print(\"   -> New/Edited Asset Embeddings Generated.\")\n",
    "    except Exception as e:\n",
    "        conn.rollback(); print(f\"âŒ Edit Failed: {e}\")\n",
    "    finally:\n",
    "        cur.close(); conn.close()\n",
    "print(\"âœ… [v1.6] Section C: Functions Ready\")"
]
new_cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "source": review_funcs
})

# Section D (Validation)
validation_code = [
    "# SECTION D: Validation Tests (v1.6)\n",
    "\n",
    "def run_v1_6_validation():\n",
    "    brand_id_str = \"wh_india_001\"\n",
    "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
    "    \n",
    "    print(\"\\n\\n--- ðŸ§ª TEST 1: Ingestion starts as 'inferred' ---\")\n",
    "    conn = get_db_connection()\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT count(*) FROM brand_assets WHERE brand_id = %s AND confidence = 'inferred'\", (brand_uuid,))\n",
    "    count = cur.fetchone()[0]\n",
    "    cur.close(); conn.close()\n",
    "    print(f\"âœ… Found {count} 'inferred' assets\")\n",
    "    \n",
    "    print(\"\\n--- ðŸ§ª TEST 2: Retrieval Priority (Approved > Inferred) ---\")\n",
    "    inferred = list_inferred_assets(brand_id_str)\n",
    "    if inferred:\n",
    "        target = inferred[0]\n",
    "        print(f\"   Targeting: {target['raw_text'][:20]}...\")\n",
    "        approve_asset(target['asset_id'], \"Admin\", \"Accurate\")\n",
    "        res = retrieve_context(brand_id_str, \"brand philosophy\", \"strategy\")\n",
    "        # Fallback query if strategy doesn't hit\n",
    "        if not res: res = retrieve_context(brand_id_str, target['raw_text'][:50], \"strategy\")\n",
    "\n",
    "        if res and res[0]['confidence'] == 'approved':\n",
    "             print(\"âœ… Approved asset prioritized.\")\n",
    "        else:\n",
    "             print(f\"âš ï¸ Result confidence: {res[0]['confidence'] if res else 'None'}\")\n",
    "\n",
    "    print(\"\\n--- ðŸ§ª TEST 3: Deprecation (Exclude from Retrieval) ---\")\n",
    "    if inferred:\n",
    "        reject_asset(target['asset_id'], \"Admin\", \"Deprecating\")\n",
    "        res = retrieve_context(brand_id_str, \"brand philosophy\", \"strategy\")\n",
    "        # Fallback\n",
    "        if not res: res = retrieve_context(brand_id_str, target['raw_text'][:50], \"strategy\")\n",
    "        \n",
    "        found = any(d['content'] == target['raw_text'] for d in res)\n",
    "        if not found:\n",
    "            print(\"âœ… Deprecated asset successfully EXCLUDED.\")\n",
    "        else:\n",
    "            print(\"âŒ FAILURE: Deprecated asset still retrieved!\")\n",
    "\n",
    "    print(\"\\n--- ðŸ§ª TEST 4: Audit Trail ---\")\n",
    "    conn = get_db_connection()\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT * FROM memory_reviews ORDER BY created_at DESC LIMIT 5\")\n",
    "    for r in cur.fetchall():\n",
    "        print(f\"   - Action: {r[3]} | Old: {r[4]} -> New: {r[5]}\")\n",
    "    cur.close(); conn.close()\n",
    "\n",
    "run_v1_6_validation()"
]
new_cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "source": validation_code
})

# Append new cells
nb['cells'].extend(new_cells)

# Save Back
with open('brand_brain_v1.5.ipynb', 'w', encoding='utf-8') as f:
    json.dump(nb, f, indent=4)
print("Updated brand_brain_v1.5.ipynb with v1.6 extensions.")
