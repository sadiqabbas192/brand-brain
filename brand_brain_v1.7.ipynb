{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# **Brand Brain v1 - Development & Validation Harness**\n",
                "\n",
                "This notebook implements and validates the Brand Brain v1 architecture end-to-end. \n",
                "It covers data ingestion, semantic asset extraction, chunking, embedding, storage (Postgres + Pinecone), and brand-scoped retrieval.\n",
                "\n",
                "## **Architecture Recap**\n",
                "\n",
                "1.  **Input**: Brand JSON (simulating DynamoDB export)\n",
                "2.  **Ingestion**: \n",
                "    *   Extract Semantic Assets\n",
                "    *   Chunking (200-350 tokens)\n",
                "    *   Embedding (Gemini `gemini-embedding-001` @ 768 dims)\n",
                "3.  **Storage**:\n",
                "    *   **Postgres**: Structured memory (Assets, Chunks)\n",
                "    *   **Pinecone**: Semantic vectors (Namespace: `org:brand:type`)\n",
                "4.  **Retrieval**: Brand-scoped semantic search\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "35b8dff5",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Configuration Loaded & Clients Initialized\n"
                    ]
                }
            ],
            "source": [
                "# 1. Setup & Configuration\n",
                "import os\n",
                "import json\n",
                "import uuid\n",
                "import time\n",
                "from typing import List, Dict, Any, Optional\n",
                "import pandas as pd\n",
                "import psycopg2\n",
                "from psycopg2.extras import RealDictCursor, Json\n",
                "from pinecone import Pinecone, ServerlessSpec\n",
                "from google import genai\n",
                "from dotenv import load_dotenv\n",
                "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
                "\n",
                "\n",
                "DEBUG_MODE = False  # True = developer logs, False = clean UX\n",
                "def print_debug(*args, **kwargs):\n",
                "    if DEBUG_MODE:\n",
                "        print(*args, **kwargs)\n",
                "\n",
                "# Load environment variables\n",
                "load_dotenv(override=True) # Ensure we reload if .env changed\n",
                "\n",
                "NEON_DB_URL = os.getenv(\"NEON_DB_URL\")\n",
                "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
                "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY4\")\n",
                "\n",
                "if not all([NEON_DB_URL, PINECONE_API_KEY, GEMINI_API_KEY]):\n",
                "    raise ValueError(\"Missing required environment variables. Please check your .env file.\")\n",
                "\n",
                "# Initialize Clients\n",
                "client = genai.Client(api_key=GEMINI_API_KEY)\n",
                "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
                "\n",
                "# Database Connection Helper\n",
                "def get_db_connection():\n",
                "    return psycopg2.connect(NEON_DB_URL)\n",
                "\n",
                "print(\"‚úÖ Configuration Loaded & Clients Initialized\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "84d3c0d2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Connected to Neon DB. Tables exist.\n"
                    ]
                }
            ],
            "source": [
                "# 2. Database Pre-checks (No Table Creation)\n",
                "def check_connection():\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    try:\n",
                "        cur.execute(\"SELECT count(*) FROM information_schema.tables WHERE table_name = 'brand_assets'\")\n",
                "        if cur.fetchone()[0] == 0:\n",
                "            print(\"‚ùå ERROR: Tables not found! Please run tables.sql in Neon console.\")\n",
                "        else:\n",
                "            print(\"‚úÖ Connected to Neon DB. Tables exist.\")\n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Connection Failed: {e}\")\n",
                "    finally:\n",
                "        cur.close()\n",
                "        conn.close()\n",
                "\n",
                "check_connection()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "6d901e3b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Input Brand Data\n",
                "\n",
                "# Parsed from Westinghouse India.txt\n",
                "westinghouse_json = {\n",
                "    \"brandId\": \"wh_india_001\",\n",
                "    \"name\": \"Westinghouse India\",\n",
                "    \"industry\": \"FMEG\",\n",
                "    \"mission\": \"To enrich everyday living with reliable, thoughtfully engineered appliances that combine global heritage, modern innovation, and timeless design‚Äîdelivering confidence, comfort, and consistency to Indian homes.\",\n",
                "    \"brandVoice\": \"Confident & Reassuring. Premium yet Approachable. Clear & Functional. Trust-First. Design-Conscious.\",\n",
                "    \"visualStyle\": \"Design-forward minimalism. Product as hero. Lifestyle-led context. Retro-modern blend. Premium finishes. Colors: Orange, Red, White, Green, Blue, Black.\",\n",
                "    \"audience\": \"All genders, 25‚Äì45 years (core). Upper-middle to affluent households. Interests: Premium home & kitchen appliances, Modern kitchen aesthetics, Smart living. Focus: Tier 1 metros (Mumbai, Delhi NCR...) and affluent Tier 2.\",\n",
                "    \"competitors\": \"Morphy Richards (Strong British Heritage, Wide Portfolio). Weaknesses: Inconsistent Visual Identity, Limited Design Differentiation.\",\n",
                "    \"inspiration\": \"Morphy Richards\",\n",
                "    \"website\": \"https://www.westinghousehomeware.in/\"\n",
                "}\n",
                "\n",
                "brands_to_ingest = [westinghouse_json]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "a8808592",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Asset Extraction Logic Defined\n"
                    ]
                }
            ],
            "source": [
                "# 4. Semantic Asset Extraction Logic\n",
                "\n",
                "def extract_assets(brand_data: Dict) -> List[Dict]:\n",
                "    assets = []\n",
                "    brand_id = brand_data.get(\"brandId\")\n",
                "    \n",
                "    # Extraction Rules Mapping\n",
                "    # Source Field -> (Asset Type [copy/guideline/website], Vector Type [brand_voice/strategy/performance])\n",
                "    mapping = {\n",
                "        \"mission\": (\"guideline\", \"strategy\"),\n",
                "        \"brandVoice\": (\"guideline\", \"brand_voice\"),\n",
                "        \"visualStyle\": (\"guideline\", \"brand_voice\"),\n",
                "        \"audience\": (\"guideline\", \"strategy\"),\n",
                "        \"competitors\": (\"guideline\", \"strategy\"),\n",
                "        \"inspiration\": (\"guideline\", \"strategy\"),\n",
                "        \"website\": (\"website\", \"strategy\")\n",
                "    }\n",
                "    \n",
                "    for field, (asset_type, vector_type) in mapping.items():\n",
                "        content = brand_data.get(field)\n",
                "        if content:\n",
                "            assets.append({\n",
                "                \"asset_id\": str(uuid.uuid4()),\n",
                "                \"brand_id\": brand_id,\n",
                "                \"asset_type\": asset_type,\n",
                "                \"vector_type\": vector_type,\n",
                "                \"source_field\": field,\n",
                "                \"content\": content\n",
                "            })\n",
                "            \n",
                "    return assets\n",
                "\n",
                "print(\"‚úÖ Asset Extraction Logic Defined\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "bfd9409f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Chunking & Embedding Functions Defined (New SDK - 768 dims)\n"
                    ]
                }
            ],
            "source": [
                "# 5. Chunking & Embedding Logic\n",
                "\n",
                "text_splitter = RecursiveCharacterTextSplitter(\n",
                "    chunk_size=350,\n",
                "    chunk_overlap=50,\n",
                "    length_function=len,\n",
                "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
                ")\n",
                "\n",
                "def chunk_text(text: str) -> List[str]:\n",
                "    return text_splitter.split_text(text)\n",
                "\n",
                "def generate_embedding(text: str) -> List[float]:\n",
                "    # Using gemini-embedding-001 with truncation to 768 dimensions\n",
                "    try:\n",
                "        result = client.models.embed_content(\n",
                "            model=\"gemini-embedding-001\",\n",
                "            contents=text,\n",
                "            config={\n",
                "                'output_dimensionality': 768,\n",
                "                'task_type': 'RETRIEVAL_DOCUMENT',\n",
                "                'title': 'Brand Asset'\n",
                "            }\n",
                "        )\n",
                "        return result.embeddings[0].values\n",
                "    except Exception as e:\n",
                "        print(f\"Embedding Error: {e}\")\n",
                "        return []\n",
                "\n",
                "print(\"‚úÖ Chunking & Embedding Functions Defined (New SDK - 768 dims)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "82d0d35e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. Ingestion Pipeline (Production Schema)\n",
                "\n",
                "def ingest_brand(brand_data: Dict):\n",
                "    brand_id_str = brand_data['brandId']\n",
                "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
                "    \n",
                "    brand_name = brand_data.get('name', 'Unknown')\n",
                "    org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org')) # Placeholder Org\n",
                "\n",
                "    print(f\"\\nüß† Ingesting Brand: {brand_name} (UUID: {brand_uuid}) ...\")\n",
                "    \n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    \n",
                "    try:\n",
                "        # 1. Ensure Organization Exists\n",
                "        cur.execute(\n",
                "            \"INSERT INTO organizations (org_id, name) VALUES (%s, %s) ON CONFLICT (org_id) DO NOTHING\",\n",
                "            (org_id, \"Test Org\")\n",
                "        )\n",
                "\n",
                "        # 2. Ensure Brand Exists\n",
                "        cur.execute(\n",
                "            \"INSERT INTO brands (brand_id, org_id, name, industry) VALUES (%s, %s, %s, %s) ON CONFLICT (brand_id) DO NOTHING\",\n",
                "            (brand_uuid, org_id, brand_name, brand_data.get('industry', 'Unknown'))\n",
                "        )\n",
                "\n",
                "        # 3. Extract Assets\n",
                "        assets = extract_assets(brand_data)\n",
                "        print(f\"   -> Extracted {len(assets)} semantic assets\")\n",
                "\n",
                "        # Prepare Pinecone\n",
                "        index_name = \"brand-brain-index\"\n",
                "        \n",
                "        # DEBUG: Check what key is actually being used\n",
                "        masked = PINECONE_API_KEY[:5] + \"...\" if PINECONE_API_KEY else \"None\"\n",
                "        print(f\"   [DEBUG] Checking Pinecone Index with Key: {masked}\")\n",
                "        \n",
                "        # Create index if not exists\n",
                "        if index_name not in pc.list_indexes().names():\n",
                "             pc.create_index(\n",
                "                name=index_name,\n",
                "                dimension=768,\n",
                "                metric=\"cosine\",\n",
                "                spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
                "            )\n",
                "        idx = pc.Index(index_name)\n",
                "\n",
                "        total_chunks = 0\n",
                "        \n",
                "        for asset in assets:\n",
                "            # Insert Asset Metadata\n",
                "            cur.execute(\n",
                "                \"INSERT INTO brand_assets (asset_id, brand_id, asset_type, raw_text, source) VALUES (%s, %s, %s, %s, %s) ON CONFLICT (asset_id) DO NOTHING\",\n",
                "                (asset['asset_id'], brand_uuid, asset['asset_type'], asset['content'], asset['source_field'])\n",
                "            )\n",
                "            \n",
                "            chunks = chunk_text(asset['content'])\n",
                "            \n",
                "            for i, chunk_text_content in enumerate(chunks):\n",
                "                chunk_id = str(uuid.uuid4())\n",
                "                embedding_id = str(uuid.uuid4())\n",
                "                vector = generate_embedding(chunk_text_content)\n",
                "                \n",
                "                if not vector:\n",
                "                    print(f\"Skipping chunk due to embedding failure\")\n",
                "                    continue\n",
                "\n",
                "                cur.execute(\n",
                "                    \"INSERT INTO brand_chunks (chunk_id, asset_id, brand_id, vector_type, content, token_count) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
                "                    (chunk_id, asset['asset_id'], brand_uuid, asset['vector_type'], chunk_text_content, len(chunk_text_content.split()))\n",
                "                )\n",
                "                \n",
                "                namespace = f\"{org_id}:{brand_uuid}:{asset['vector_type']}\"\n",
                "                cur.execute(\n",
                "                    \"INSERT INTO embeddings (embedding_id, chunk_id, brand_id, vector_type, namespace, model) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
                "                    (embedding_id, chunk_id, brand_uuid, asset['vector_type'], namespace, \"gemini-embedding-001\")\n",
                "                )\n",
                "\n",
                "                idx.upsert(\n",
                "                    vectors=[(chunk_id, vector, {\"source\": asset['source_field']})],\n",
                "                    namespace=namespace\n",
                "                )\n",
                "                total_chunks += 1\n",
                "        \n",
                "        conn.commit()\n",
                "        print(f\"‚úÖ Successfully ingested {total_chunks} chunks for {brand_name}.\")\n",
                "        \n",
                "    except Exception as e:\n",
                "        conn.rollback()\n",
                "        print(f\"‚ùå Ingestion Failed: {e}\")\n",
                "    finally:\n",
                "        cur.close()\n",
                "        conn.close()\n",
                "\n",
                "# # Run Ingestion\n",
                "# for brand in brands_to_ingest:\n",
                "#     ingest_brand(brand)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "79c995b1",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 7. Retrieval & Validation Logic\n",
                "\n",
                "def retrieve_context(brand_name_str: str, query: str, vector_type: str = \"brand_voice\", top_k: int = 3):\n",
                "    if brand_name_str == \"wh_india_001\":\n",
                "        brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_name_str))\n",
                "        org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
                "    else:\n",
                "        brand_uuid = brand_name_str\n",
                "        org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
                "\n",
                "    print(f\"\\nüîé Querying Brand {brand_name_str} (UUID: {brand_uuid}) [{vector_type}]: '{query}'\")\n",
                "    \n",
                "    # New SDK for Query Embedding\n",
                "    try:\n",
                "        query_embedding_result = client.models.embed_content(\n",
                "            model=\"gemini-embedding-001\",\n",
                "            contents=query,\n",
                "            config={\n",
                "                'output_dimensionality': 768,\n",
                "                'task_type': 'RETRIEVAL_QUERY'\n",
                "            }\n",
                "        )\n",
                "        query_embedding = query_embedding_result.embeddings[0].values\n",
                "    except Exception as e:\n",
                "        print(f\"Embedding Error during retrieval: {e}\")\n",
                "        return []\n",
                "    \n",
                "    namespace = f\"{org_id}:{brand_uuid}:{vector_type}\"\n",
                "    index_name = \"brand-brain-index\"\n",
                "    idx = pc.Index(index_name)\n",
                "    \n",
                "    results = idx.query(\n",
                "        vector=query_embedding,\n",
                "        top_k=top_k,\n",
                "        namespace=namespace,\n",
                "        include_metadata=True\n",
                "    )\n",
                "    \n",
                "    if not results['matches']:\n",
                "        print(\"   ‚ö†Ô∏è No matches found in namespace:\", namespace)\n",
                "        return []\n",
                "        \n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    \n",
                "    retrieved_docs = []\n",
                "    chunk_ids = [m['id'] for m in results['matches']]\n",
                "    \n",
                "    if chunk_ids:\n",
                "        placeholders = ', '.join(['%s'] * len(chunk_ids))\n",
                "        query_sql = f\"SELECT content, vector_type FROM brand_chunks WHERE chunk_id IN ({placeholders})\"\n",
                "        cur.execute(query_sql, tuple(chunk_ids))\n",
                "        rows = cur.fetchall()\n",
                "        \n",
                "        for i, row in enumerate(rows):\n",
                "            score = results['matches'][i]['score']\n",
                "            print(f\"   [{i+1}] Score: {score:.4f} | Content: {row[0][:100]}...\")\n",
                "            retrieved_docs.append({\"content\": row[0], \"score\": score})\n",
                "            \n",
                "    cur.close()\n",
                "    conn.close()\n",
                "    return retrieved_docs\n",
                "\n",
                "# 8. Run Validation Tests\n",
                "def run_validation():\n",
                "    # Test 1: Westinghouse Brand Voice\n",
                "    print(\"\\n--- TEST 1: Westinghouse Brand Voice ---\")\n",
                "    retrieve_context(\"wh_india_001\", \"Describe our design philosophy.\", vector_type=\"brand_voice\")\n",
                "    \n",
                "    # Test 2: Westinghouse Competitor Context\n",
                "    print(\"\\n--- TEST 2: Westinghouse Strategy ---\")\n",
                "    retrieve_context(\"wh_india_001\", \"Who are we fighting against?\", vector_type=\"strategy\")\n",
                "    \n",
                "    # Test 3: Off-Brand check\n",
                "    print(\"\\n--- TEST 3: Isolation / Irrelevant Query ---\")\n",
                "    retrieve_context(\"wh_india_001\", \"How to be cheap and loud?\", vector_type=\"brand_voice\")\n",
                "\n",
                "#run_validation()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "80900523",
            "metadata": {},
            "source": [
                "## **Brand Brain v1.5 - Grounded Cognition Extensions**\n",
                "\n",
                "The following sections implement **Brand Brain v1.5** with strict adherence to:\n",
                "1. **Type A/B/C Memory separation**\n",
                "2. **Evidence-based Grounding**\n",
                "3. **Deterministic Safety Rules**\n",
                "4. **No implicit memory growth**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "347a5efd",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ v1.5 Libraries Loaded\n"
                    ]
                }
            ],
            "source": [
                "# v1.5 Imports\n",
                "import numpy as np\n",
                "from google.genai import types\n",
                "import statistics\n",
                "\n",
                "print(\"‚úÖ v1.5 Libraries Loaded\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "300959cb",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Section A: Grounding-Assisted Ingestion Implementation Ready\n"
                    ]
                }
            ],
            "source": [
                "# SECTION A: Grounding-Assisted Ingestion (Type B Memory)\n",
                "\n",
                "def grounding_assisted_ingest(brand_data: Dict, target_vector_type=\"strategy\"):\n",
                "    \"\"\"\n",
                "    Uses Gemini Google Search tools to extract ONLY evergreen brand philosophy.\n",
                "    Enforces strict prompt filters.\n",
                "    Stores as Type B memory with version tags.\n",
                "    \"\"\"\n",
                "    brand_name = brand_data['name']\n",
                "    website = brand_data.get('website', '')\n",
                "    \n",
                "    print(f\"\\nüåç Starting Grounding-Assisted Ingestion for {brand_name}...\")\n",
                "\n",
                "    # 1. Define Prompt with HARD FILTERS\n",
                "    prompt = f\"\"\"\n",
                "    You are a Brand Identity Expert.\n",
                "    SEARCH for \"{brand_name} brand philosophy design principles manifesto\".\n",
                "    Also check the provided website: {website}\n",
                "\n",
                "    EXTRACT ONLY evergreen, high-level brand identity content.\n",
                "    \n",
                "    ‚ùå STRICTLY IGNORE:\n",
                "    - pricing, offers, discounts\n",
                "    - launches, new arrivals\n",
                "    - comparisons, awards\n",
                "    - timelines, history dates\n",
                "    - \"latest\", \"new\", \"recent\", \"2024\", \"2025\"\n",
                "\n",
                "    ‚úÖ EXTRACT ONLY:\n",
                "    - philosophy & mission\n",
                "    - design principles\n",
                "    - core values\n",
                "    - identity statements\n",
                "    \n",
                "    RETURN JSON in this format:\n",
                "    {{\n",
                "      \"brand_philosophy\": \"string\",\n",
                "      \"design_principles\": \"string\",\n",
                "      \"positioning\": \"string\"\n",
                "    }}\n",
                "    \"\"\"\n",
                "\n",
                "    try:\n",
                "        # 2. Call Gemini with Search Tool\n",
                "        # [FIX] Removed response_mime_type to allow Tools to work correctly\n",
                "        response = client.models.generate_content(\n",
                "            model=\"gemini-2.5-flash-preview-09-2025\", # Using Flash for speed/tools\n",
                "            contents=prompt,\n",
                "            config=types.GenerateContentConfig(\n",
                "                tools=[types.Tool(google_search=types.GoogleSearchRetrieval)]\n",
                "            )\n",
                "        )\n",
                "        \n",
                "        # 3. Robust JSON Parsing (Manual)\n",
                "        text = response.text.strip()\n",
                "        if text.startswith(\"```json\"):\n",
                "            text = text[7:]\n",
                "        elif text.startswith(\"```\"):\n",
                "            text = text[3:]\n",
                "        if text.endswith(\"```\"):\n",
                "            text = text[:-3]\n",
                "            \n",
                "        extracted_data = json.loads(text.strip())\n",
                "        print(f\"   ‚úÖ Extracted Grounded Data: {list(extracted_data.keys())}\")\n",
                "\n",
                "        # 3. Format as Assets (Type B)\n",
                "        # Merging into a single text block for embedding is usually better for 'strategy'\n",
                "        combined_text = f\"Philosophy: {extracted_data.get('brand_philosophy', '')}\\n\"\n",
                "        combined_text += f\"Design Principles: {extracted_data.get('design_principles', '')}\\n\"\n",
                "        combined_text += f\"Positioning: {extracted_data.get('positioning', '')}\"\n",
                "\n",
                "        grounded_asset = {\n",
                "            \"asset_id\": str(uuid.uuid4()),\n",
                "            \"brand_id\": brand_data['brandId'],\n",
                "            \"asset_type\": \"guideline\", # Fixed: Must be one of 'copy', 'guideline', 'website'\n",
                "            \"vector_type\": target_vector_type,\n",
                "            \"source_field\": \"grounding_assisted_ingestion\",\n",
                "            \"content\": combined_text\n",
                "        }\n",
                "\n",
                "        # 4. Store & Embed (Reusing ingestion logic pattern)\n",
                "        ingest_single_asset(grounded_asset, brand_data) # Helper to be defined below\n",
                "\n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Grounding Ingestion Failed: {e}\")\n",
                "\n",
                "\n",
                "def ingest_single_asset(asset: Dict, brand_data: Dict):\n",
                "    \"\"\"Helper to ingest a single constructed asset.\"\"\"\n",
                "    brand_id_str = brand_data['brandId']\n",
                "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
                "    org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
                "    \n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    idx = pc.Index(\"brand-brain-index\")\n",
                "\n",
                "    try:\n",
                "        # Store Asset in Postgres\n",
                "        # Note: metadata like source_version is stored in source or handled via separate columns in prod\n",
                "        # Here we pack it into 'source' string or similar for v1 demo\n",
                "        source_tag = f\"{asset['source_field']} | v1.5 | confidence:inferred\"\n",
                "        \n",
                "        cur.execute(\n",
                "            \"INSERT INTO brand_assets (asset_id, brand_id, asset_type, raw_text, source) VALUES (%s, %s, %s, %s, %s) ON CONFLICT (asset_id) DO NOTHING\",\n",
                "            (asset['asset_id'], brand_uuid, asset['asset_type'], asset['content'], source_tag)\n",
                "        )\n",
                "\n",
                "        chunks = chunk_text(asset['content'])\n",
                "        for chunk_text_content in chunks:\n",
                "            chunk_id = str(uuid.uuid4())\n",
                "            embedding_id = str(uuid.uuid4())\n",
                "            vector = generate_embedding(chunk_text_content)\n",
                "            \n",
                "            if not vector: continue\n",
                "\n",
                "            cur.execute(\n",
                "                \"INSERT INTO brand_chunks (chunk_id, asset_id, brand_id, vector_type, content, token_count) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
                "                (chunk_id, asset['asset_id'], brand_uuid, asset['vector_type'], chunk_text_content, len(chunk_text_content.split()))\n",
                "            )\n",
                "            \n",
                "            namespace = f\"{org_id}:{brand_uuid}:{asset['vector_type']}\"\n",
                "            \n",
                "            cur.execute(\n",
                "                 \"INSERT INTO embeddings (embedding_id, chunk_id, brand_id, vector_type, namespace, model) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
                "                (embedding_id, chunk_id, brand_uuid, asset['vector_type'], namespace, \"gemini-embedding-001\")\n",
                "            )\n",
                "            \n",
                "            idx.upsert(\n",
                "                vectors=[(chunk_id, vector, {\"source\": source_tag})],\n",
                "                namespace=namespace\n",
                "            )\n",
                "        \n",
                "        conn.commit()\n",
                "        print(f\"   ‚úÖ Successfully stored Type B memory for {brand_data['name']}\")\n",
                "    finally:\n",
                "        cur.close()\n",
                "        conn.close()\n",
                "\n",
                "print(\"‚úÖ Section A: Grounding-Assisted Ingestion Implementation Ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "a7312ee2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Section B: Off-Brand Rule Engine Ready (Soft Safety Enabled)\n"
                    ]
                }
            ],
            "source": [
                "# SECTION B: Off-Brand Rule Engine (Deterministic)\n",
                "\n",
                "# [v1.7 Update] Allow generic intents or IntentType\n",
                "from typing import Any\n",
                "\n",
                "ALLOWED_INTENTS = {\"explain_brand\", \"validate_copy\", \"justify_decision\", \"minimal_rewrite\"}\n",
                "FORBIDDEN_KEYWORDS = {\"cheap\", \"free\", \"lowest price\", \"clearance\", \"sale\", \"loud\", \"discount\", \"discounting\"} \n",
                "\n",
                "def calculate_brand_centroid(brand_id: str, org_id: str, top_n=5) -> List[float]:\n",
                "    \"\"\"\n",
                "    Calculates deterministic centroid from top-N 'brand_voice' chunks.\n",
                "    In a real system, this is pre-computed. Here we fetch via a 'neutral' query.\n",
                "    \"\"\"\n",
                "    idx = pc.Index(\"brand-brain-index\")\n",
                "    namespace = f\"{org_id}:{brand_id}:brand_voice\"\n",
                "    \n",
                "    # Deterministic query to fetch representative chunks\n",
                "    # We use a static string that represents the ideal voice to find core chunks\n",
                "    query_vec = generate_embedding(\"brand voice tone philosophy identity\")\n",
                "    \n",
                "    results = idx.query(\n",
                "        vector=query_vec,\n",
                "        top_k=top_n,\n",
                "        namespace=namespace,\n",
                "        include_values=True\n",
                "    )\n",
                "    \n",
                "    vectors = []\n",
                "    if results['matches']:\n",
                "         for m in results['matches']:\n",
                "             if m.get('values'):\n",
                "                 vectors.append(m['values'])\n",
                "             \n",
                "    if not vectors:\n",
                "        return []\n",
                "    \n",
                "    return np.mean(vectors, axis=0).tolist()\n",
                "\n",
                "def check_brand_safety(user_query: str, brand_id_str: str, intent: Any) -> Dict:\n",
                "    # 1. Intent Check\n",
                "    # [v1.7 Update] Allow IntentType enums or legacy strings\n",
                "    intent_val = intent.value if hasattr(intent, 'value') else intent\n",
                "    \n",
                "    # 2. Keyword Check\n",
                "    query_lower = user_query.lower()\n",
                "    violated_keywords = [kw for kw in FORBIDDEN_KEYWORDS if kw in query_lower]\n",
                "    \n",
                "    if violated_keywords:\n",
                "        # [v1.7 SOFT SAFETY]\n",
                "        # If intent is REASONING (or legacy 'justify_decision'), we Warn instead of Fail\n",
                "        if intent_val in [\"reasoning\", \"justify_decision\"] or (hasattr(IntentType, 'REASONING') and intent_val == IntentType.REASONING.value):\n",
                "             return {\n",
                "                 \"status\": \"PASS_WITH_WARNING\", \n",
                "                 \"warning_type\": \"brand_positioning_conflict\",\n",
                "                 \"reason\": f\"This idea conflicts with the brand‚Äôs premium positioning (Keywords: {violated_keywords}).\"\n",
                "             }\n",
                "        else:\n",
                "             # Creative or Knowledge requests with forbidden words still fail\n",
                "             return {\"status\": \"FAIL\", \"reason\": f\"Forbidden keywords detected: {violated_keywords}\"}\n",
                "    \n",
                "    # 3. Semantic Drift Check\n",
                "    # Setup IDs\n",
                "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
                "    org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
                "    \n",
                "    centroid = calculate_brand_centroid(brand_uuid, org_id)\n",
                "    if not centroid:\n",
                "        return {\"status\": \"PASS\", \"reason\": \"No brand memory to validate against (Cold Start)\"}\n",
                "        \n",
                "    query_vec = generate_embedding(user_query)\n",
                "    similarity = np.dot(query_vec, centroid) / (np.linalg.norm(query_vec) * np.linalg.norm(centroid))\n",
                "    \n",
                "    if similarity < 0.4: \n",
                "         return {\"status\": \"FAIL\", \"reason\": f\"Semantic drift detected (Score: {similarity:.2f}). Query not aligned with Brand Voice.\"}\n",
                "\n",
                "    return {\"status\": \"PASS\", \"reason\": \"All checks passed\"}\n",
                "\n",
                "print(\"‚úÖ Section B: Off-Brand Rule Engine Ready (Soft Safety Enabled)\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1679150f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Section C: Brand Reasoner Ready\n"
                    ]
                }
            ],
            "source": [
                "# SECTION C: Brand Reasoner\n",
                "\n",
                "def generate_brand_response(query: str, context: List[Dict], safety_status: Dict, temp_grounding: str = None) -> str:\n",
                "    if safety_status['status'] == \"FAIL\":\n",
                "        return f\"üö´ BRAND SAFETY BLOCK: {safety_status['reason']}\"\n",
                "        \n",
                "    context_str = \"\\n\".join([f\"- {c['content']}\" for c in context])\n",
                "    if temp_grounding:\n",
                "        context_str += f\"\\n[EXTERNAL EVIDENCE]: {temp_grounding}\"\n",
                "        \n",
                "    prompt = f\"\"\"\n",
                "    You are Brand Brain. Your job is to Explain, Justify, or Minimally Rewrite.\n",
                "    Use the provided BRAND MEMORY as the source of truth.\n",
                "    If external evidence is provided, use it for context but subordinate it to Brand Memory.\n",
                "    \n",
                "    QUERY: {query}\n",
                "    \n",
                "    BRAND MEMORY:\n",
                "    {context_str}\n",
                "    \n",
                "    INSTRUCTIONS:\n",
                "    - Do not invent facts.\n",
                "    - Adhere to the tone found in memory.\n",
                "    \"\"\"\n",
                "    \n",
                "    response = client.models.generate_content(\n",
                "        model=\"gemini-2.5-flash-preview-09-2025\",\n",
                "        contents=prompt\n",
                "    )\n",
                "    return response.text\n",
                "\n",
                "print(\"‚úÖ Section C: Brand Reasoner Ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "427ab1e5",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Section D: Ephemeral Live Fetch Ready\n"
                    ]
                }
            ],
            "source": [
                "# SECTION D: Ephemeral Live Fetch (Type C Memory)\n",
                "\n",
                "def ephemeral_live_fetch(query: str) -> str:\n",
                "    \"\"\"\n",
                "    Fetches live data for Type C memory.\n",
                "    Guaranteed NO persistence.\n",
                "    \"\"\"\n",
                "    print(f\"   üåê Triggering Ephemeral Live Fetch for: '{query}'\")\n",
                "    \n",
                "    prompt = f\"Search Google for: {query}. Summarize the answer in 2 sentences.\"\n",
                "    \n",
                "    response = client.models.generate_content(\n",
                "        model=\"gemini-2.5-flash-preview-09-2025\",\n",
                "        contents=prompt,\n",
                "        config=types.GenerateContentConfig(\n",
                "            tools=[types.Tool(google_search=types.GoogleSearchRetrieval)]\n",
                "        )\n",
                "    )\n",
                "    \n",
                "    # Extract text from response (ignoring grounding metadata for the summary text)\n",
                "    return response.text\n",
                "\n",
                "print(\"‚úÖ Section D: Ephemeral Live Fetch Ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "baea23a3",
            "metadata": {},
            "outputs": [],
            "source": [
                "# SECTION E: v1.5 Validation Harness\n",
                "\n",
                "def run_v1_5_validation():\n",
                "    brand_id = \"wh_india_001\"\n",
                "    \n",
                "    # 1. Simulate Type B Ingestion\n",
                "    print(\"\\n--- TEST 1: Grounding-Assisted Ingestion ---\")\n",
                "    grounding_assisted_ingest(westinghouse_json)\n",
                "    \n",
                "    # VERIFICATION OF TYPE B ASSETS\n",
                "    print(\"\\n--- VERIFYING TYPE B ASSETS IN DB ---\")\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    try:\n",
                "        cur.execute(\"SELECT count(*) FROM brand_assets WHERE source LIKE '%grounding_assisted%'\")\n",
                "        count = cur.fetchone()[0]\n",
                "        print(f\"‚úÖ Found {count} Type B assets in Postgres.\")\n",
                "        if count == 0:\n",
                "             print(\"‚ùå ERROR: Type B ingestion failed (no rows affected).\")\n",
                "    finally:\n",
                "        cur.close()\n",
                "        conn.close()\n",
                "        \n",
                "    # 2. Rejection Logic (OMITTED AS REQUESTED)\n",
                "    # print(\"\\n--- TEST 2: Off-Brand Rejection ---\")\n",
                "\n",
                "    # 3. End-to-End Success + Type C\n",
                "    print(\"\\n--- TEST 3: Live Query with Ephemeral Context ---\")\n",
                "    good_query = \"What are the latest appliance trends suitable for our brand?\"\n",
                "    safety_3 = check_brand_safety(good_query, brand_id, \"justify_decision\")\n",
                "    \n",
                "    if safety_3['status'] == \"PASS\":\n",
                "        # Retrieve Memory (Type A/B)\n",
                "        context = retrieve_context(brand_id, good_query, \"strategy\")\n",
                "        \n",
                "        # Trigger Live Fetch (Type C)\n",
                "        type_c_data = ephemeral_live_fetch(good_query)\n",
                "        \n",
                "        # Reason\n",
                "        response = generate_brand_response(good_query, context, safety_3, type_c_data)\n",
                "        print(f\"\\nü§ñ Final Response:\\n{response}\")\n",
                "\n",
                "        # PROOF OF NO PERSISTENCE\n",
                "        print(\"\\nüîí Verifying Type C Non-Persistence...\")\n",
                "        conn = get_db_connection()\n",
                "        cur = conn.cursor()\n",
                "        # Search for 'trends' which comes from live fetch\n",
                "        # but ensure we don't count type B or A if they happened to have it.\n",
                "        # We specifically check for *recent* assets that are NOT type B/A?\n",
                "        # Simple check: search for 'trends' in text, but EXCLUDE source='grounding_assisted_ingestion'\n",
                "        cur.execute(\"SELECT count(*) FROM brand_assets WHERE raw_text ILIKE '%trends%' AND source NOT LIKE '%grounding_assisted%'\")\n",
                "        count = cur.fetchone()[0]\n",
                "        if count == 0:\n",
                "             print(\"‚úÖ SUCCESS: Live trend data NOT found in Postgres (ignoring intentional Type A/B).\")\n",
                "        else:\n",
                "             print(\"‚ö†Ô∏è NOTE: 'trends' keyword found. Verify it is not from ephemeral fetch.\")\n",
                "        cur.close()\n",
                "        conn.close()\n",
                "\n",
                "#run_v1_5_validation()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "54cc52c8",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "id": "0de370d3",
            "metadata": {},
            "source": [
                "## **Brand Brain v1.6 - Memory Governance Upgrade**\n",
                "\n",
                "The following cells implement **Brand Brain v1.6** extensions, adding human-governed memory control, confidence scoring, and memory review workflows.\n",
                "\n",
                "**Upgrades:**\n",
                "1. **Schema**: Added `confidence` field (inferred/reviewed/approved/deprecated).\n",
                "2. **Retrieval**: Prioritizes approved memory; excludes deprecated memory.\n",
                "3. **Governance**: Added functions to approve, reject, and edit memory."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "63fd6317",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ [v1.6] Ingestion Logic Updated\n"
                    ]
                }
            ],
            "source": [
                "# [v1.6 UPGRADE] Redefining Ingestion to support Confidence Scoring\n",
                "\n",
                "def ingest_single_asset(asset: Dict, brand_data: Dict):\n",
                "    \"\"\"[v1.6] Helper to ingest a single constructed asset with confidence defaults.\"\"\"\n",
                "    brand_id_str = brand_data['brandId']\n",
                "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
                "    org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
                "    \n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    idx = pc.Index(\"brand-brain-index\")\n",
                "\n",
                "    try:\n",
                "        # Store Asset in Postgres\n",
                "        source_tag = f\"{asset['source_field']} | v1.6 | confidence:inferred\"\n",
                "        \n",
                "        # [MODIFIED v1.6] Explicitly inserting confidence='inferred'\n",
                "        # Note: We rely on the schema update (ADD COLUMN confidence) having been run.\n",
                "        cur.execute(\n",
                "            \"INSERT INTO brand_assets (asset_id, brand_id, asset_type, raw_text, source, confidence) VALUES (%s, %s, %s, %s, %s, %s) ON CONFLICT (asset_id) DO NOTHING\",\n",
                "            (asset['asset_id'], brand_uuid, asset['asset_type'], asset['content'], source_tag, 'inferred')\n",
                "        )\n",
                "\n",
                "        chunks = chunk_text(asset['content'])\n",
                "        for chunk_text_content in chunks:\n",
                "            chunk_id = str(uuid.uuid4())\n",
                "            embedding_id = str(uuid.uuid4())\n",
                "            vector = generate_embedding(chunk_text_content)\n",
                "            \n",
                "            if not vector: continue\n",
                "            \n",
                "            vt = asset.get('vector_type', 'strategy')\n",
                "\n",
                "            cur.execute(\n",
                "                \"INSERT INTO brand_chunks (chunk_id, asset_id, brand_id, vector_type, content, token_count) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
                "                (chunk_id, asset['asset_id'], brand_uuid, vt, chunk_text_content, len(chunk_text_content.split()))\n",
                "            )\n",
                "            \n",
                "            namespace = f\"{org_id}:{brand_uuid}:{vt}\"\n",
                "            \n",
                "            cur.execute(\n",
                "                 \"INSERT INTO embeddings (embedding_id, chunk_id, brand_id, vector_type, namespace, model) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
                "                (embedding_id, chunk_id, brand_uuid, vt, namespace, \"gemini-embedding-001\")\n",
                "            )\n",
                "            \n",
                "            idx.upsert(\n",
                "                vectors=[(chunk_id, vector, {\"source\": source_tag})],\n",
                "                namespace=namespace\n",
                "            )\n",
                "        \n",
                "        conn.commit()\n",
                "        print(f\"   ‚úÖ [v1.6] Successfully stored Type B memory for {brand_data['name']} (Confidence: Inferred)\")\n",
                "    except Exception as e:\n",
                "        conn.rollback()\n",
                "        print(f\"‚ùå Ingestion Error: {e}\")\n",
                "    finally:\n",
                "        cur.close()\n",
                "        conn.close()\n",
                "print(\"‚úÖ [v1.6] Ingestion Logic Updated\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "b4dfc0de",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ [v1.6] Retrieval Logic Updated\n"
                    ]
                }
            ],
            "source": [
                "# [v1.6 UPGRADE] Redefining Retrieval to Prioritize Confidence & Filter Deprecated\n",
                "\n",
                "def retrieve_context(brand_name_str: str, query: str, vector_type: str = \"brand_voice\", top_k: int = 3):\n",
                "    if brand_name_str == \"wh_india_001\":\n",
                "        brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_name_str))\n",
                "        org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
                "    else:\n",
                "        brand_uuid = brand_name_str\n",
                "        org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
                "\n",
                "    print_debug(f\"\\nüîé [v1.6] Querying Brand {brand_name_str} (UUID: {brand_uuid}) [{vector_type}]: '{query}'\")\n",
                "    \n",
                "    try:\n",
                "        query_embedding_result = client.models.embed_content(\n",
                "            model=\"gemini-embedding-001\",\n",
                "            contents=query,\n",
                "            config={\n",
                "                'output_dimensionality': 768,\n",
                "                'task_type': 'RETRIEVAL_QUERY'\n",
                "            }\n",
                "        )\n",
                "        query_embedding = query_embedding_result.embeddings[0].values\n",
                "    except Exception as e:\n",
                "        print_debug(f\"Embedding Error during retrieval: {e}\")\n",
                "        return []\n",
                "    \n",
                "    namespace = f\"{org_id}:{brand_uuid}:{vector_type}\"\n",
                "    index_name = \"brand-brain-index\"\n",
                "    idx = pc.Index(index_name)\n",
                "    \n",
                "    # Fetch more candidates to allow for filtering of deprecated items\n",
                "    results = idx.query(\n",
                "        vector=query_embedding,\n",
                "        top_k=top_k * 3,\n",
                "        namespace=namespace,\n",
                "        include_metadata=True\n",
                "    )\n",
                "    \n",
                "    if not results['matches']:\n",
                "        print_debug(\"   ‚ö†Ô∏è No matches found in namespace:\", namespace)\n",
                "        return []\n",
                "        \n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    \n",
                "    retrieved_docs = []\n",
                "    chunk_ids = [m['id'] for m in results['matches']]\n",
                "    \n",
                "    if chunk_ids:\n",
                "        placeholders = ', '.join(['%s'] * len(chunk_ids))\n",
                "        # [MODIFIED v1.6] Join with brand_assets to fetch 'confidence'\n",
                "        query_sql = f\"\"\"\n",
                "            SELECT c.chunk_id, c.content, c.vector_type, a.confidence \n",
                "            FROM brand_chunks c\n",
                "            JOIN brand_assets a ON c.asset_id = a.asset_id\n",
                "            WHERE c.chunk_id IN ({placeholders})\n",
                "        \"\"\"\n",
                "        cur.execute(query_sql, tuple(chunk_ids))\n",
                "        rows = cur.fetchall()\n",
                "        \n",
                "        # Lookup map\n",
                "        db_map = {row[0]: {\"content\": row[1], \"confidence\": row[3]} for row in rows}\n",
                "        \n",
                "        valid_candidates = []\n",
                "        \n",
                "        for match in results['matches']:\n",
                "            c_id = match['id']\n",
                "            score = match['score']\n",
                "            if c_id not in db_map: \n",
                "                continue\n",
                "                \n",
                "            data = db_map[c_id]\n",
                "            confidence = data['confidence'] or 'inferred' # Handle legacy rows where confidence might be NULL\n",
                "            \n",
                "            # [RULE] Exclude Deprecated\n",
                "            if confidence == 'deprecated':\n",
                "                continue\n",
                "                \n",
                "            # [RULE] Prioritize: approved (3) > reviewed (2) > inferred (1)\n",
                "            priority_score = 1\n",
                "            if confidence == 'approved': priority_score = 3\n",
                "            elif confidence == 'reviewed': priority_score = 2\n",
                "            \n",
                "            valid_candidates.append({\n",
                "                \"content\": data['content'],\n",
                "                \"score\": score,\n",
                "                \"confidence\": confidence,\n",
                "                \"priority\": priority_score\n",
                "            })\n",
                "            \n",
                "        # Sort by Priority (desc), then Similarity Score (desc)\n",
                "        valid_candidates.sort(key=lambda x: (x['priority'], x['score']), reverse=True)\n",
                "        \n",
                "        # Return top_k\n",
                "        final_results = valid_candidates[:top_k]\n",
                "        \n",
                "        for i, res in enumerate(final_results):\n",
                "            print_debug(f\"   [{i+1}] [{res['confidence'].upper()}] Score: {res['score']:.4f} | Content: {res['content'][:100]}...\")\n",
                "            retrieved_docs.append(res)\n",
                "            \n",
                "    cur.close()\n",
                "    conn.close()\n",
                "    return retrieved_docs\n",
                "print(\"‚úÖ [v1.6] Retrieval Logic Updated\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "0b46084f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ [v1.6] Section C: Functions Ready\n"
                    ]
                }
            ],
            "source": [
                "# SECTION C: Memory Review Functions (v1.6)\n",
                "\n",
                "def list_inferred_assets(brand_id_str: str):\n",
                "    print(f\"\\nüìã Listing Inferred Assets for {brand_id_str}...\")\n",
                "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor(cursor_factory=RealDictCursor)\n",
                "    cur.execute(\"SELECT asset_id, asset_type, raw_text, source, confidence FROM brand_assets WHERE brand_id = %s AND confidence = 'inferred'\", (brand_uuid,))\n",
                "    rows = cur.fetchall()\n",
                "    cur.close()\n",
                "    conn.close()\n",
                "    for r in rows:\n",
                "        print(f\"   [ID: {r['asset_id']}] {r['raw_text'][:50]}... (Source: {r['source']})\")\n",
                "    return rows\n",
                "\n",
                "def approve_asset(asset_id: str, reviewer: str, notes: str):\n",
                "    print(f\"\\n‚úÖ Approving Asset {asset_id}...\")\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    try:\n",
                "        cur.execute(\"SELECT confidence FROM brand_assets WHERE asset_id = %s\", (asset_id,))\n",
                "        res = cur.fetchone()\n",
                "        if not res: return\n",
                "        prev_conf = res[0]\n",
                "        cur.execute(\"UPDATE brand_assets SET confidence = 'approved', reviewed_by = %s, review_notes = %s, reviewed_at = NOW() WHERE asset_id = %s\", (reviewer, notes, asset_id))\n",
                "        cur.execute(\"INSERT INTO memory_reviews (review_id, asset_id, action, previous_confidence, new_confidence, reviewer, notes) VALUES (%s, %s, %s, %s, %s, %s, %s)\", (str(uuid.uuid4()), asset_id, 'approve', prev_conf, 'approved', reviewer, notes))\n",
                "        conn.commit()\n",
                "        print(\"   -> Asset Approved.\")\n",
                "    except Exception as e:\n",
                "        conn.rollback(); print(f\"‚ùå {e}\")\n",
                "    finally:\n",
                "        cur.close(); conn.close()\n",
                "\n",
                "def reject_asset(asset_id: str, reviewer: str, notes: str):\n",
                "    print(f\"\\n‚õî Rejecting Asset {asset_id}...\")\n",
                "    conn = get_db_connection(); cur = conn.cursor()\n",
                "    try:\n",
                "        cur.execute(\"SELECT confidence FROM brand_assets WHERE asset_id = %s\", (asset_id,))\n",
                "        res = cur.fetchone()\n",
                "        if not res: return\n",
                "        prev_conf = res[0]\n",
                "        cur.execute(\"UPDATE brand_assets SET confidence = 'deprecated', reviewed_by = %s, review_notes = %s, reviewed_at = NOW() WHERE asset_id = %s\", (reviewer, notes, asset_id))\n",
                "        cur.execute(\"INSERT INTO memory_reviews (review_id, asset_id, action, previous_confidence, new_confidence, reviewer, notes) VALUES (%s, %s, %s, %s, %s, %s, %s)\", (str(uuid.uuid4()), asset_id, 'deprecate', prev_conf, 'deprecated', reviewer, notes))\n",
                "        conn.commit()\n",
                "        print(\"   -> Asset Deprecated.\")\n",
                "    except Exception as e:\n",
                "        conn.rollback(); print(f\"‚ùå {e}\")\n",
                "    finally:\n",
                "        cur.close(); conn.close()\n",
                "\n",
                "def edit_and_promote_asset(asset_id: str, new_text: str, reviewer: str):\n",
                "    print(f\"\\nüìù Editing & Promoting Asset {asset_id}...\")\n",
                "    conn = get_db_connection(); cur = conn.cursor(cursor_factory=RealDictCursor)\n",
                "    try:\n",
                "        cur.execute(\"SELECT * FROM brand_assets WHERE asset_id = %s\", (asset_id,))\n",
                "        original = cur.fetchone()\n",
                "        if not original: return\n",
                "        # Deprecate Old\n",
                "        cur.execute(\"UPDATE brand_assets SET confidence = 'deprecated', reviewed_by = %s, review_notes = 'Replaced by edit', reviewed_at = NOW() WHERE asset_id = %s\", (reviewer, asset_id))\n",
                "        # Insert New Approved\n",
                "        new_asset_id = str(uuid.uuid4())\n",
                "        cur.execute(\"INSERT INTO brand_assets (asset_id, brand_id, asset_type, raw_text, source, confidence, reviewed_by, reviewed_at, review_notes) VALUES (%s, %s, %s, %s, %s, %s, %s, NOW(), 'Created via Edit')\", (new_asset_id, original['brand_id'], original['asset_type'], new_text, original['source'], 'approved', reviewer))\n",
                "        conn.commit()\n",
                "        print(f\"   -> Old Asset Deprecated. New Asset {new_asset_id} Created.\")\n",
                "        # Chunk & Embed New Asset\n",
                "        chunks = chunk_text(new_text)\n",
                "        idx = pc.Index(\"brand-brain-index\")\n",
                "        org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
                "        # Need vector_type\n",
                "        cur.execute(\"SELECT vector_type FROM brand_chunks WHERE asset_id = %s LIMIT 1\", (asset_id,))\n",
                "        vt = cur.fetchone()['vector_type']\n",
                "        for i, chunk in enumerate(chunks):\n",
                "            chunk_id = str(uuid.uuid4())\n",
                "            vec = generate_embedding(chunk)\n",
                "            cur.execute(\"INSERT INTO brand_chunks (chunk_id, asset_id, brand_id, vector_type, content, token_count) VALUES (%s, %s, %s, %s, %s, %s)\", (chunk_id, new_asset_id, original['brand_id'], vt, chunk, len(chunk.split())))\n",
                "            cur.execute(\"INSERT INTO embeddings (embedding_id, chunk_id, brand_id, vector_type, namespace, model) VALUES (%s, %s, %s, %s, %s, %s)\", (str(uuid.uuid4()), chunk_id, original['brand_id'], vt, f\"{org_id}:{original['brand_id']}:{vt}\", \"gemini-embedding-001\"))\n",
                "            idx.upsert(vectors=[(chunk_id, vec, {\"source\": original['source']})], namespace=f\"{org_id}:{original['brand_id']}:{vt}\")\n",
                "        conn.commit()\n",
                "        print(\"   -> New/Edited Asset Embeddings Generated.\")\n",
                "    except Exception as e:\n",
                "        conn.rollback(); print(f\"‚ùå Edit Failed: {e}\")\n",
                "    finally:\n",
                "        cur.close(); conn.close()\n",
                "print(\"‚úÖ [v1.6] Section C: Functions Ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "a073cddb",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "--- üß™ TEST 1: Ingestion starts as 'inferred' ---\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Found 62 'inferred' assets\n",
                        "\n",
                        "--- üß™ TEST 2: Retrieval Priority (Approved > Inferred) [brand_voice] ---\n",
                        "\n",
                        "üìã Listing Inferred Assets for wh_india_001...\n",
                        "   [ID: 7bc146d0-7068-486b-bc28-4da657e10966] Morphy Richards (Strong British Heritage, Wide Por... (Source: competitors)\n",
                        "   [ID: d70f75c2-a5be-485f-864a-a7c5842a48bf] Morphy Richards... (Source: inspiration)\n",
                        "   [ID: 93215377-316d-4130-b009-4fb6136c437d] https://www.westinghousehomeware.in/... (Source: website)\n",
                        "   [ID: 870e34f5-8969-42d0-90ab-b07309685a65] To enrich everyday living with reliable, thoughtfu... (Source: mission)\n",
                        "   [ID: cc087901-bafe-4b2e-baff-3775407863b9] All genders, 25‚Äì45 years (core). Upper-middle to a... (Source: audience)\n",
                        "   [ID: 5f50d7d9-d4f0-4eb7-aa94-4bab4ce2a09b] Morphy Richards (Strong British Heritage, Wide Por... (Source: competitors)\n",
                        "   [ID: 0044f9e9-e6f4-4ec3-90ed-b93155d759be] Morphy Richards... (Source: inspiration)\n",
                        "   [ID: aae3ebaa-70d4-43fd-ba63-c278bffa4ffd] https://www.westinghousehomeware.in/... (Source: website)\n",
                        "   [ID: 514cdb81-822d-4fc9-b961-e634fe77e07e] Philosophy: Westinghouse's philosophy is to power ... (Source: grounding_assisted_ingestion | v1.5 | confidence:inferred)\n",
                        "   [ID: 6d446544-6ba4-45c9-9370-b011901f556d] Philosophy: At Westinghouse, the mission is to pow... (Source: grounding_assisted_ingestion | v1.5 | confidence:inferred)\n",
                        "   [ID: 064582f5-963e-414f-8617-e5e53beaa461] To enrich everyday living with reliable, thoughtfu... (Source: mission)\n",
                        "   [ID: ceb6f034-aee3-40fd-92ee-2ec8dfe97e11] All genders, 25‚Äì45 years (core). Upper-middle to a... (Source: audience)\n",
                        "   [ID: 1555bd51-e86a-43d0-8403-0949f1940027] Morphy Richards (Strong British Heritage, Wide Por... (Source: competitors)\n",
                        "   [ID: 14054072-05ac-4d84-87e6-0c2e748e6097] Morphy Richards... (Source: inspiration)\n",
                        "   [ID: 9087537c-4800-41ae-9596-ea161900216a] Philosophy: Westinghouse's mission is to power mea... (Source: grounding_assisted_ingestion | v1.5 | confidence:inferred)\n",
                        "   [ID: e58d9a92-da98-44f2-863b-b2549b9a2ddd] Philosophy: Westinghouse is driven by a mission to... (Source: grounding_assisted_ingestion | v1.5 | confidence:inferred)\n",
                        "   [ID: 5a6bb33f-6c61-4e0d-901c-00de50271be6] To enrich everyday living with reliable, thoughtfu... (Source: mission)\n",
                        "   [ID: 4eeddc99-6d35-46c7-a8a3-3adf981bbd85] All genders, 25‚Äì45 years (core). Upper-middle to a... (Source: audience)\n",
                        "   [ID: 58779a7c-62a6-4f8e-9926-46e4c3232bd5] Morphy Richards (Strong British Heritage, Wide Por... (Source: competitors)\n",
                        "   [ID: 97c09bb2-c1c3-4890-8049-27ec066b320c] Morphy Richards... (Source: inspiration)\n",
                        "   [ID: 668a3420-b15e-4f20-8bc1-f5f2c0ad9ede] https://www.westinghousehomeware.in/... (Source: website)\n",
                        "   [ID: e730b6a9-c703-4f5b-9e26-e666e72c61a2] To enrich everyday living with reliable, thoughtfu... (Source: mission)\n",
                        "   [ID: be71e2bf-6d7d-4e5c-8622-a6d9e1147133] All genders, 25‚Äì45 years (core). Upper-middle to a... (Source: audience)\n",
                        "   [ID: ebfb5718-361a-4d80-b67d-8b53048dbecc] Morphy Richards (Strong British Heritage, Wide Por... (Source: competitors)\n",
                        "   [ID: 7fb9b1cb-0e94-44f8-9f5d-264358f33e44] Morphy Richards... (Source: inspiration)\n",
                        "   [ID: 1da8392a-f784-4a6d-93a7-660bb4cb8966] https://www.westinghousehomeware.in/... (Source: website)\n",
                        "   [ID: 3568fcd2-cb8a-4211-9ebd-ab0510472bec] All genders, 25‚Äì45 years (core). Upper-middle to a... (Source: audience)\n",
                        "   [ID: 96496fd5-285f-411c-aa9f-d37dccce72ec] https://www.westinghousehomeware.in/... (Source: website)\n",
                        "   [ID: d7813bda-8629-46fc-b2f0-fb21307e510d] Morphy Richards (Strong British Heritage, Wide Por... (Source: competitors)\n",
                        "   [ID: 0c1f4693-a463-4af8-8c7a-c5b074a81048] Morphy Richards... (Source: inspiration)\n",
                        "   [ID: 6410a66e-8a07-4377-970e-3e00ebb49081] https://www.westinghousehomeware.in/... (Source: website)\n",
                        "   [ID: 8aca5285-86b1-447c-b729-635cfd6357a0] Philosophy: Westinghouse Homeware's mission is to ... (Source: grounding_assisted_ingestion | v1.5 | confidence:inferred)\n",
                        "   [ID: e1ab1962-c757-4f77-82f6-e754ed4bc250] Philosophy: Westinghouse's philosophy is rooted in... (Source: grounding_assisted_ingestion | v1.5 | confidence:inferred)\n",
                        "   [ID: 983898c7-e78c-4ffc-bdf3-0618c618ad78] Philosophy: Westinghouse's mission is to power mea... (Source: grounding_assisted_ingestion | v1.5 | confidence:inferred)\n",
                        "   [ID: ceb22e98-6615-48e3-9c99-cf1e950b1603] Philosophy: Westinghouse aims to power meaningful ... (Source: grounding_assisted_ingestion | v1.5 | confidence:inferred)\n",
                        "   [ID: 98c20129-6835-4184-ae39-c2c0d1093c37] To enrich everyday living with reliable, thoughtfu... (Source: mission)\n",
                        "   [ID: 5ab86961-1427-4b66-aebe-135ad1acf6ed] All genders, 25‚Äì45 years (core). Upper-middle to a... (Source: audience)\n",
                        "   [ID: e1847f12-f504-4604-8e25-3316fae54d5b] Morphy Richards (Strong British Heritage, Wide Por... (Source: competitors)\n",
                        "   [ID: 0be47462-88c6-495f-b7bc-00cf68400a91] Morphy Richards... (Source: inspiration)\n",
                        "   [ID: 532ff13e-0632-428c-9fa9-e75db35235c2] https://www.westinghousehomeware.in/... (Source: website)\n",
                        "   [ID: 441fbf28-fc43-464a-9b1c-4fa55b85a99d] Philosophy: Westinghouse's mission is to power mea... (Source: grounding_assisted_ingestion | v1.5 | confidence:inferred)\n",
                        "   [ID: a4ca1b05-040e-499c-be00-8b57ec583680] To enrich everyday living with reliable, thoughtfu... (Source: mission)\n",
                        "   [ID: c49de44e-ade1-4822-b8df-41afc4fb4e0b] All genders, 25‚Äì45 years (core). Upper-middle to a... (Source: audience)\n",
                        "   [ID: 19e46cd9-f49d-49b7-829c-e679ab73897c] Morphy Richards (Strong British Heritage, Wide Por... (Source: competitors)\n",
                        "   [ID: f54bea62-03e0-4125-8da0-640da6d79b5b] Morphy Richards... (Source: inspiration)\n",
                        "   [ID: 9a45a1cd-1a89-40e5-9b92-8291066b7183] https://www.westinghousehomeware.in/... (Source: website)\n",
                        "   [ID: 379d8777-60d7-4a13-9423-18062a30fcc8] To enrich everyday living with reliable, thoughtfu... (Source: mission)\n",
                        "   [ID: 0c0bbd45-32b8-43dd-ab99-6050a7747590] All genders, 25‚Äì45 years (core). Upper-middle to a... (Source: audience)\n",
                        "   [ID: 3e520fc3-0322-4ecc-b585-023a162b1ac0] Morphy Richards (Strong British Heritage, Wide Por... (Source: competitors)\n",
                        "   [ID: 81ed1e4a-3588-4a75-abf5-df5a8f31e3e1] Morphy Richards... (Source: inspiration)\n",
                        "   [ID: fce386c4-61ec-4182-88b0-6d8ae2bc7bc7] https://www.westinghousehomeware.in/... (Source: website)\n",
                        "   [ID: c759e8ce-3fac-4b0c-b0b6-83004647e89d] To enrich everyday living with reliable, thoughtfu... (Source: mission)\n",
                        "   [ID: d0dc8315-7801-41c1-81f2-0f48b27204aa] Confident & Reassuring. Premium yet Approachable. ... (Source: brandVoice)\n",
                        "   [ID: ec47e3cf-9ef2-4a96-afa7-34aaaaa76b66] Design-forward minimalism. Product as hero. Lifest... (Source: visualStyle)\n",
                        "   [ID: 2606fa05-b22d-4637-b023-148b1184f82d] All genders, 25‚Äì45 years (core). Upper-middle to a... (Source: audience)\n",
                        "   [ID: b78d2a92-0e28-4a12-b061-638ed8bb963f] Morphy Richards (Strong British Heritage, Wide Por... (Source: competitors)\n",
                        "   [ID: 5aa5d82c-fb29-43a0-a8b3-383fbabba921] Morphy Richards... (Source: inspiration)\n",
                        "   [ID: 0204a3b1-6e2b-45c2-b53d-7fd99e67e5f0] https://www.westinghousehomeware.in/... (Source: website)\n",
                        "   [ID: a8ca8bf5-cb64-45e5-a753-cfae8019bdcc] To enrich everyday living with reliable, thoughtfu... (Source: mission)\n",
                        "   [ID: 8df9c30f-2b71-4bac-aa8f-1aa9f92ae146] Confident & Reassuring. Premium yet Approachable. ... (Source: brandVoice)\n",
                        "   [ID: 55a6b862-1536-4eba-92d3-638d7a7d20b9] Design-forward minimalism. Product as hero. Lifest... (Source: visualStyle)\n",
                        "   [ID: d51dc3a0-0780-45e2-8369-ffcdea396ac6] Philosophy: At Westinghouse, the mission is to pow... (Source: grounding_assisted_ingestion | v1.5 | confidence:inferred)\n",
                        "   üéØ Targeting Brand Voice Asset: Confident & Reassuring. Premium yet Appr...\n",
                        "\n",
                        "‚úÖ Approving Asset d0dc8315-7801-41c1-81f2-0f48b27204aa...\n",
                        "   -> Asset Approved.\n",
                        "‚úÖ SUCCESS: Approved brand_voice asset correctly prioritized.\n",
                        "\n",
                        "--- üß™ TEST 3: Deprecation (Exclude from Retrieval) ---\n",
                        "\n",
                        "‚õî Rejecting Asset d0dc8315-7801-41c1-81f2-0f48b27204aa...\n",
                        "   -> Asset Deprecated.\n",
                        "‚ùå FAILURE: Deprecated asset still retrieved!\n",
                        "\n",
                        "--- üß™ TEST 4: Audit Trail ---\n",
                        "   - Action: deprecate | Old: approved -> New: deprecated\n",
                        "   - Action: approve | Old: inferred -> New: approved\n",
                        "   - Action: deprecate | Old: approved -> New: deprecated\n",
                        "   - Action: approve | Old: inferred -> New: approved\n",
                        "   - Action: deprecate | Old: approved -> New: deprecated\n"
                    ]
                }
            ],
            "source": [
                "# SECTION D: Validation Tests (v1.6)\n",
                "\n",
                "def run_v1_6_validation():\n",
                "    brand_id_str = \"wh_india_001\"\n",
                "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
                "\n",
                "    approved_asset_id = None\n",
                "    approved_asset_text = None\n",
                "\n",
                "    print(\"\\n\\n--- üß™ TEST 1: Ingestion starts as 'inferred' ---\")\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    cur.execute(\n",
                "        \"SELECT count(*) FROM brand_assets WHERE brand_id = %s AND confidence = 'inferred'\",\n",
                "        (brand_uuid,)\n",
                "    )\n",
                "    count = cur.fetchone()[0]\n",
                "    cur.close()\n",
                "    conn.close()\n",
                "    print(f\"‚úÖ Found {count} 'inferred' assets\")\n",
                "\n",
                "    # -------------------------------------------------\n",
                "\n",
                "    print(\"\\n--- üß™ TEST 2: Retrieval Priority (Approved > Inferred) [brand_voice] ---\")\n",
                "\n",
                "    # 1Ô∏è‚É£ List inferred assets\n",
                "    inferred = list_inferred_assets(brand_id_str)\n",
                "\n",
                "    # 2Ô∏è‚É£ Select an inferred BRAND_VOICE asset explicitly\n",
                "    brand_voice_target = None\n",
                "    for asset in inferred:\n",
                "        if asset[\"source\"] in [\"brandVoice\", \"visualStyle\"]:\n",
                "            brand_voice_target = asset\n",
                "            break\n",
                "\n",
                "    if not brand_voice_target:\n",
                "        print(\"‚ùå No inferred brand_voice asset found to test.\")\n",
                "    else:\n",
                "        approved_asset_id = brand_voice_target[\"asset_id\"]\n",
                "        approved_asset_text = brand_voice_target[\"raw_text\"]\n",
                "\n",
                "        print(\n",
                "            f\"   üéØ Targeting Brand Voice Asset: \"\n",
                "            f\"{approved_asset_text[:40]}...\"\n",
                "        )\n",
                "\n",
                "        # 3Ô∏è‚É£ Approve the brand_voice asset\n",
                "        approve_asset(\n",
                "            approved_asset_id,\n",
                "            reviewer=\"Admin\",\n",
                "            notes=\"Approved brand voice memory\"\n",
                "        )\n",
                "\n",
                "        # 4Ô∏è‚É£ Query SAME semantic space + namespace\n",
                "        res = retrieve_context(\n",
                "            brand_id_str,\n",
                "            \"design philosophy\",\n",
                "            \"brand_voice\"\n",
                "        )\n",
                "\n",
                "        # 5Ô∏è‚É£ Assert approved asset is prioritized\n",
                "        if res and res[0][\"confidence\"] == \"approved\":\n",
                "            print(\"‚úÖ SUCCESS: Approved brand_voice asset correctly prioritized.\")\n",
                "        else:\n",
                "            print(\n",
                "                f\"‚ùå FAILURE: Expected approved asset first, got \"\n",
                "                f\"{res[0]['confidence'] if res else 'None'}\"\n",
                "            )\n",
                "\n",
                "    # -------------------------------------------------\n",
                "\n",
                "    print(\"\\n--- üß™ TEST 3: Deprecation (Exclude from Retrieval) ---\")\n",
                "\n",
                "    if approved_asset_id:\n",
                "        reject_asset(\n",
                "            approved_asset_id,\n",
                "            reviewer=\"Admin\",\n",
                "            notes=\"Deprecating for validation test\"\n",
                "        )\n",
                "\n",
                "        res = retrieve_context(\n",
                "            brand_id_str,\n",
                "            \"design philosophy\",\n",
                "            \"brand_voice\"\n",
                "        )\n",
                "\n",
                "        found = any(\n",
                "            d[\"content\"] == approved_asset_text\n",
                "            for d in res\n",
                "        )\n",
                "\n",
                "        if not found:\n",
                "            print(\"‚úÖ Deprecated asset successfully EXCLUDED.\")\n",
                "        else:\n",
                "            print(\"‚ùå FAILURE: Deprecated asset still retrieved!\")\n",
                "\n",
                "    else:\n",
                "        print(\"‚ö†Ô∏è Skipping TEST 3: No approved asset available.\")\n",
                "\n",
                "    # -------------------------------------------------\n",
                "\n",
                "    print(\"\\n--- üß™ TEST 4: Audit Trail ---\")\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    cur.execute(\n",
                "        \"SELECT action, previous_confidence, new_confidence \"\n",
                "        \"FROM memory_reviews ORDER BY created_at DESC LIMIT 5\"\n",
                "    )\n",
                "    rows = cur.fetchall()\n",
                "    cur.close()\n",
                "    conn.close()\n",
                "\n",
                "    for r in rows:\n",
                "        print(f\"   - Action: {r[0]} | Old: {r[1]} -> New: {r[2]}\")\n",
                "\n",
                "# Run validation\n",
                "run_v1_6_validation()# SECTION D: Validation Tests (v1.6)\n",
                "\n",
                "def run_v1_6_validation():\n",
                "    brand_id_str = \"wh_india_001\"\n",
                "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
                "\n",
                "    approved_asset_id = None\n",
                "    approved_asset_text = None\n",
                "\n",
                "    print(\"\\n\\n--- üß™ TEST 1: Ingestion starts as 'inferred' ---\")\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    cur.execute(\n",
                "        \"SELECT count(*) FROM brand_assets WHERE brand_id = %s AND confidence = 'inferred'\",\n",
                "        (brand_uuid,)\n",
                "    )\n",
                "    count = cur.fetchone()[0]\n",
                "    cur.close()\n",
                "    conn.close()\n",
                "    print(f\"‚úÖ Found {count} 'inferred' assets\")\n",
                "\n",
                "    # -------------------------------------------------\n",
                "\n",
                "    print(\"\\n--- üß™ TEST 2: Retrieval Priority (Approved > Inferred) [brand_voice] ---\")\n",
                "\n",
                "    # üîé Find an inferred BRAND_VOICE asset via DB (robust)\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    cur.execute(\"\"\"\n",
                "        SELECT a.asset_id, a.raw_text\n",
                "        FROM brand_assets a\n",
                "        JOIN brand_chunks c ON a.asset_id = c.asset_id\n",
                "        WHERE a.brand_id = %s\n",
                "          AND a.confidence = 'inferred'\n",
                "          AND c.vector_type = 'brand_voice'\n",
                "        LIMIT 1\n",
                "    \"\"\", (brand_uuid,))\n",
                "    row = cur.fetchone()\n",
                "    cur.close()\n",
                "    conn.close()\n",
                "\n",
                "    if not row:\n",
                "        print(\"‚ö†Ô∏è No inferred brand_voice asset available. TEST 2 skipped (expected if already curated).\")\n",
                "    else:\n",
                "        approved_asset_id, approved_asset_text = row\n",
                "\n",
                "        print(f\"   üéØ Targeting Brand Voice Asset: {approved_asset_text[:40]}...\")\n",
                "\n",
                "        approve_asset(\n",
                "            approved_asset_id,\n",
                "            reviewer=\"Admin\",\n",
                "            notes=\"Approved brand voice memory (v1.6 validation)\"\n",
                "        )\n",
                "\n",
                "        res = retrieve_context(\n",
                "            brand_id_str,\n",
                "            \"design philosophy\",\n",
                "            \"brand_voice\"\n",
                "        )\n",
                "\n",
                "        if res and res[0][\"confidence\"] == \"approved\":\n",
                "            print(\"‚úÖ SUCCESS: Approved brand_voice asset correctly prioritized.\")\n",
                "        else:\n",
                "            print(\n",
                "                f\"‚ùå FAILURE: Expected approved asset first, got \"\n",
                "                f\"{res[0]['confidence'] if res else 'None'}\"\n",
                "            )\n",
                "\n",
                "    # -------------------------------------------------\n",
                "\n",
                "    print(\"\\n--- üß™ TEST 3: Deprecation (Exclude from Retrieval) ---\")\n",
                "\n",
                "    if approved_asset_id:\n",
                "        reject_asset(\n",
                "            approved_asset_id,\n",
                "            reviewer=\"Admin\",\n",
                "            notes=\"Deprecating for validation test\"\n",
                "        )\n",
                "\n",
                "        res = retrieve_context(\n",
                "            brand_id_str,\n",
                "            \"design philosophy\",\n",
                "            \"brand_voice\"\n",
                "        )\n",
                "\n",
                "        found = any(\n",
                "            d[\"content\"] == approved_asset_text\n",
                "            for d in res\n",
                "        )\n",
                "\n",
                "        if not found:\n",
                "            print(\"‚úÖ Deprecated asset successfully EXCLUDED.\")\n",
                "        else:\n",
                "            print(\"‚ùå FAILURE: Deprecated asset still retrieved!\")\n",
                "    else:\n",
                "        print(\"‚ö†Ô∏è Skipping TEST 3: No approved asset available.\")\n",
                "\n",
                "    # -------------------------------------------------\n",
                "\n",
                "    print(\"\\n--- üß™ TEST 4: Audit Trail ---\")\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    cur.execute(\"\"\"\n",
                "        SELECT action, previous_confidence, new_confidence\n",
                "        FROM memory_reviews\n",
                "        ORDER BY created_at DESC\n",
                "        LIMIT 5\n",
                "    \"\"\")\n",
                "    rows = cur.fetchall()\n",
                "    cur.close()\n",
                "    conn.close()\n",
                "\n",
                "    for r in rows:\n",
                "        print(f\"   - Action: {r[0]} | Old: {r[1]} -> New: {r[2]}\")\n",
                "\n",
                "# Run validation\n",
                "#run_v1_6_validation()\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "babf71fa",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "94505d3c",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "id": "712529f2",
            "metadata": {},
            "source": [
                "## **Section F: Brand Brain v1.7 - Read-Only Chat & Explainability**\n",
                "\n",
                "This section implements the **Read-Only Chat Playground** with **Explainability**.\n",
                "It focuses on safe, natural interaction without persistent memory mutation.\n",
                "\n",
                "**Core Features:**\n",
                "1.  **Hybrid Intent Classification** (Rules + Gemini)\n",
                "2.  **Brand Reasoner** (Gemini-2.5-Flash with Strict System Prompt)\n",
                "3.  **Chat Pipeline** (Intent -> Retrieval -> Safety -> Reasoner)\n",
                "4.  **Zero-Mutation Guarantee**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "2c5995ba",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from itertools import cycle\n",
                "from google import genai\n",
                "from google.genai import types\n",
                "from IPython.display import display, Markdown\n",
                "\n",
                "# Load environment variables\n",
                "load_dotenv(override=True) # Ensure we reload if .env changed\n",
                "\n",
                "# Load API keys from environment\n",
                "GEMINI_KEYS = [\n",
                "    os.getenv(\"GEMINI_API_KEY1\"),\n",
                "    os.getenv(\"GEMINI_API_KEY2\"),\n",
                "    os.getenv(\"GEMINI_API_KEY3\"),\n",
                "    os.getenv(\"GEMINI_API_KEY4\"),\n",
                "    os.getenv(\"GEMINI_API_KEY5\"),\n",
                "    os.getenv(\"GEMINI_API_KEY6\"),\n",
                "    os.getenv(\"GEMINI_API\")\n",
                "\n",
                "]\n",
                "\n",
                "# Filter out missing keys\n",
                "GEMINI_KEYS = [k for k in GEMINI_KEYS if k]\n",
                "\n",
                "if not GEMINI_KEYS:\n",
                "    raise RuntimeError(\"‚ùå No Gemini API keys found in environment variables.\")\n",
                "\n",
                "# Create a rotating iterator\n",
                "_gemini_key_cycle = cycle(GEMINI_KEYS)\n",
                "\n",
                "def get_gemini_client():\n",
                "    \"\"\"\n",
                "    Returns a Gemini client using the next available API key.\n",
                "    \"\"\"\n",
                "    api_key = next(_gemini_key_cycle)\n",
                "    return genai.Client(api_key=api_key)\n",
                "\n",
                "# Safe Gemini Call Wrapper (Auto-Retry)\n",
                "def safe_generate_content(model: str, contents, config=None, max_retries=4):\n",
                "    \"\"\"\n",
                "    Safely call Gemini with automatic API key rotation on failure.\n",
                "    \"\"\"\n",
                "    last_error = None\n",
                "\n",
                "    for attempt in range(max_retries):\n",
                "        try:\n",
                "            client = get_gemini_client()\n",
                "            return client.models.generate_content(\n",
                "                model=model,\n",
                "                contents=contents,\n",
                "                config=config\n",
                "            )\n",
                "        except Exception as e:\n",
                "            last_error = e\n",
                "            print(f\"‚ö†Ô∏è Gemini call failed (attempt {attempt+1}/{max_retries}): {e}\")\n",
                "    \n",
                "    raise RuntimeError(f\"‚ùå All Gemini API keys exhausted. Last error: {last_error}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "59ba77bf",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Hybrid Intent Classifier Ready\n"
                    ]
                }
            ],
            "source": [
                "# 1. Hybrid Intent Classification\n",
                "\n",
                "import re\n",
                "from enum import Enum\n",
                "import json\n",
                "\n",
                "class IntentType(Enum):\n",
                "    KNOWLEDGE = \"knowledge\"    # Allow\n",
                "    REASONING = \"reasoning\"    # Allow\n",
                "    CREATIVE = \"creative\"      # Block\n",
                "\n",
                "# Regex for Obvious Creative Intents (Rule-Based First)\n",
                "CREATIVE_PATTERNS = [\n",
                "    r\"create\", r\"write\", r\"generate\", r\"design\", r\"make me a\", r\"draft\", \n",
                "    r\"slogan\", r\"logo\", r\"ad copy\", r\"campaign\"\n",
                "]\n",
                "\n",
                "def classify_intent_hybrid(query: str) -> IntentType:\n",
                "    # 1. Rule-Based Check\n",
                "    query_lower = query.lower()\n",
                "    for pattern in CREATIVE_PATTERNS:\n",
                "        if re.search(pattern, query_lower):\n",
                "            print(f\"   üõ°Ô∏è Rule-Based Intent Detection: CREATIVE (Blocked pattern: '{pattern}')\")\n",
                "            return IntentType.CREATIVE\n",
                "            \n",
                "    # 2. Gemini Fallback for Ambiguity\n",
                "    prompt = f\"\"\"\n",
                "    Classify the following query into one of 3 categories:\n",
                "    1. KNOWLEDGE (Questions about facts, brand voice, mission, identity)\n",
                "    2. REASONING (Questions asking for validation, 'is this on-brand?', 'why?')\n",
                "    3. CREATIVE (Requests to create, write, generate, design new assets)\n",
                "    \n",
                "    QUERY: {query}\n",
                "    \n",
                "    RETURN ONLY ONE WORD: KNOWLEDGE, REASONING, or CREATIVE.\n",
                "    \"\"\"\n",
                "    \n",
                "    try:\n",
                "        response = safe_generate_content(\n",
                "            model=\"gemini-2.5-flash-preview-09-2025\",\n",
                "            contents=prompt\n",
                "        )\n",
                "        result = response.text.strip().upper()\n",
                "        if \"CREATIVE\" in result: return IntentType.CREATIVE\n",
                "        if \"REASONING\" in result: return IntentType.REASONING\n",
                "        return IntentType.KNOWLEDGE\n",
                "    except Exception as e:\n",
                "        print(f\"   ‚ö†Ô∏è Intent Classification Failed: {e}. Defaulting to KNOWLEDGE.\")\n",
                "        return IntentType.KNOWLEDGE\n",
                "\n",
                "print(\"‚úÖ Hybrid Intent Classifier Ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7db42a03",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Brand Reasoner Ready (Soft Safety Enabled)\n"
                    ]
                }
            ],
            "source": [
                "# 2. Brand Reasoner & Explainability\n",
                "\n",
                "SYSTEM_PROMPT = \"\"\"\n",
                "You are Brand Brain, a read-only brand intelligence system.\n",
                "\n",
                "Your role is to explain, summarize, and reason about a brand using only the context provided to you.\n",
                "\n",
                "You must strictly follow these rules:\n",
                "‚Ä¢ You do **not** invent facts\n",
                "‚Ä¢ You do **not** create new brand assets\n",
                "‚Ä¢ You do **not** generate creative content\n",
                "‚Ä¢ You do **not** speculate beyond provided or grounded information\n",
                "\n",
                "You may:\n",
                "‚Ä¢ Explain brand identity, voice, values, and positioning\n",
                "‚Ä¢ Answer factual questions about the brand\n",
                "‚Ä¢ Justify whether ideas or messaging align with the brand\n",
                "‚Ä¢ Politely refuse creative or unsafe requests\n",
                "\n",
                "If a request asks you to create campaigns, copy, slogans, or visuals:\n",
                "‚Ä¢ Respond with a polite refusal\n",
                "‚Ä¢ Explain that you can evaluate or explain brand guidelines instead\n",
                "\n",
                "If information is uncertain:\n",
                "‚Ä¢ State the uncertainty clearly\n",
                "‚Ä¢ Do not guess\n",
                "\n",
                "Your tone must be:\n",
                "‚Ä¢ Clear\n",
                "‚Ä¢ Calm\n",
                "‚Ä¢ Professional\n",
                "‚Ä¢ Brand-aligned\n",
                "\n",
                "You exist to **protect and explain the brand**, not to create on its behalf.\n",
                "\"\"\"\n",
                "\n",
                "def generate_explained_response(query: str, context: List[Dict], safety_status: Dict, intent: IntentType) -> Dict:\n",
                "    # Build System Context\n",
                "    context_str = \"\\n\".join([f\"- {c['content']} (Confidence: {c.get('confidence', 'inferred')})\" for c in context])\n",
                "    \n",
                "    # [v1.7 SOFT SAFETY INJECTION]\n",
                "    safety_instruction = \"\"\n",
                "    if safety_status.get('status') == 'PASS_WITH_WARNING':\n",
                "        safety_instruction = f\"\"\"\n",
                "        ‚ö†Ô∏è IMPORTANT: The user's idea conflicts with brand positioning: {safety_status['reason']}\n",
                "        \n",
                "        YOUR TASK:\n",
                "        1. Explain WHY this idea conflicts with the brand (using the Context below).\n",
                "        2. Suggest a principle-based alternative that aligns with the brand.\n",
                "        3. Maintain a helpful, educational tone. Do NOT scold.\n",
                "        4. DO NOT generate the requested content/slogan/copy. Just explain the misalignment.\n",
                "        \"\"\"\n",
                "    \n",
                "    full_prompt = f\"\"\"\n",
                "    {SYSTEM_PROMPT}\n",
                "    \n",
                "    CONTEXT (Brand Memory):\n",
                "    {context_str}\n",
                "    \n",
                "    {safety_instruction}\n",
                "    \n",
                "    USER QUERY: {query}\n",
                "    \n",
                "    Explain your answer based *only* on the context above.\n",
                "    \"\"\"\n",
                "    \n",
                "    try:\n",
                "        response = safe_generate_content(\n",
                "            model=\"gemini-2.5-flash-preview-09-2025\",\n",
                "            contents=full_prompt,\n",
                "            config=types.GenerateContentConfig(\n",
                "                temperature=0.3 # Low temp for strict adherence\n",
                "            )\n",
                "        )\n",
                "        answer_text = response.text\n",
                "    except Exception as e:\n",
                "        answer_text = f\"Error generating response: {e}\"\n",
                "\n",
                "    # Construct Explainability Object\n",
                "    return {\n",
                "        \"answer\": answer_text,\n",
                "        \"confidence_level\": \"high\" if context else \"medium\", \n",
                "        \"brand_elements_used\": list(set([c.get('source_field', 'General') for c in context])) if isinstance(context, list) else [],\n",
                "        \"memory_sources\": list(set([c.get('confidence', 'inferred') for c in context])),\n",
                "        \"live_context_used\": False,\n",
                "        \"safety_status\": safety_status['status']\n",
                "    }\n",
                "\n",
                "print(\"‚úÖ Brand Reasoner Ready (Soft Safety Enabled)\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "id": "b349b481",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Chat Pipeline Ready (Soft Safety Enabled)\n"
                    ]
                }
            ],
            "source": [
                "# 3. Chat Pipeline (Strict Ordering)\n",
                "\n",
                "def chat_session(user_query: str, brand_id: str = \"wh_india_001\"):\n",
                "    print(f\"\\nüí¨ User: {user_query}\")\n",
                "    \n",
                "    # 1. Intent Classification (Hybrid)\n",
                "    intent = classify_intent_hybrid(user_query)\n",
                "    print(f\"   üß† Intent: {intent.value}\")\n",
                "    \n",
                "    # 2. Creative Block (Pre-computation)\n",
                "    if intent == IntentType.CREATIVE:\n",
                "        # Double check: if it was rule-based, we already blocked. \n",
                "        # But if Gemini classified it as creative and we didn't catch usage of forbidden words yet...\n",
                "        # We'll block here. \n",
                "        print_debug(\"   üö´ Creative Request Blocked.\")\n",
                "        return {\n",
                "            \"answer\": \"I can explain brand guidelines and evaluate ideas, but I don‚Äôt generate creative assets yet.\",\n",
                "            \"safety_status\": \"BLOCKED_CREATIVE\"\n",
                "        }\n",
                "\n",
                "    # 3. Retrieval\n",
                "    # Using v1.6 retrieval (prioritizes approved)\n",
                "    context = retrieve_context(brand_id, user_query, vector_type=\"brand_voice\" if intent == IntentType.REASONING else \"strategy\")\n",
                "    \n",
                "    # 4. Safety Check (Off-Brand Rules) - BEFORE Reasoner\n",
                "    # [v1.7] Pass actual intent (IntentType) to safety check\n",
                "    safety = check_brand_safety(user_query, brand_id, intent)\n",
                "    \n",
                "    if safety['status'] == 'FAIL':\n",
                "        print_debug(f\"   üõ°Ô∏è Safety Block: {safety['reason']}\")\n",
                "        return {\n",
                "            \"answer\": f\"I cannot answer that. {safety['reason']}\",\n",
                "            \"safety_status\": \"BLOCKED_SAFETY\"\n",
                "        }\n",
                "    elif safety['status'] == 'PASS_WITH_WARNING':\n",
                "        print_debug(f\"   ‚ö†Ô∏è Soft Safety Warning: {safety['reason']}\")\n",
                "        # Proceed to Reasoner, passing the warning\n",
                "        \n",
                "    # 5. Brand Reasoner\n",
                "    response_obj = generate_explained_response(user_query, context, safety, intent)\n",
                "\n",
                "    response_obj[\"intent\"] = intent.value\n",
                "\n",
                "    print_debug(f\"   ü§ñ Brand Brain: {response_obj['answer'][:100]}...\")\n",
                "    return response_obj\n",
                "\n",
                "print(\"‚úÖ Chat Pipeline Ready (Soft Safety Enabled)\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "c5834bd0",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. v1.7 Validation Harness & DB Snapshot\n",
                "\n",
                "def get_db_counts():\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    cur.execute(\"SELECT count(*) FROM brand_assets\")\n",
                "    assets = cur.fetchone()[0]\n",
                "    cur.execute(\"SELECT count(*) FROM brand_chunks\")\n",
                "    chunks = cur.fetchone()[0]\n",
                "    cur.close()\n",
                "    conn.close()\n",
                "    return assets, chunks\n",
                "\n",
                "def run_v1_7_validation():\n",
                "    print(\"\\n\\n--- üß™ v1.7 Validation Suite (Soft Safety) ---\")\n",
                "    \n",
                "    # 1. Snapshot DB\n",
                "    assets_before, chunks_before = get_db_counts()\n",
                "    print(f\"üìä DB Before: Assets={assets_before}, Chunks={chunks_before}\")\n",
                "        \n",
                "    # 2. Test Cases\n",
                "    queries = [\n",
                "        (\"What are our brand colors?\", \"KNOWLEDGE\"),\n",
                "        (\"Is aggressive discounting on-brand?\", \"REASONING\"), # Should trigger Soft Safety (PASS_WITH_WARNING)\n",
                "        (\"Write a Diwali campaign\", \"CREATIVE\") # Should be blocked\n",
                "    ]\n",
                "    \n",
                "    for q, expected in queries:\n",
                "        print(f\"\\n--- Testing: '{q}' (Expected Intent/Flow: {expected}) ---\")\n",
                "        res = chat_session(q)\n",
                "        print(f\"   üìÑ Result: {json.dumps(res, indent=2)}\")\n",
                "\n",
                "    # 3. Verify Mutation\n",
                "    assets_after, chunks_after = get_db_counts()\n",
                "    print(f\"\\nüìä DB After: Assets={assets_after}, Chunks={chunks_after}\")\n",
                "    \n",
                "    if assets_before == assets_after and chunks_before == chunks_after:\n",
                "        print(\"‚úÖ SUCCESS: Zero DB Mutation Confirmed.\")\n",
                "    else:\n",
                "        print(\"‚ùå FAILURE: DB Mutation Detected!\")\n",
                "\n",
                "#run_v1_7_validation()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2fd484d3",
            "metadata": {},
            "source": [
                "## **Brand Brain Interactive Chat (v1.7)**\n",
                "\n",
                "This section enables a **read-only, user-friendly chat interface** for Brand Brain.\n",
                "\n",
                "### Features\n",
                "- Natural language interaction\n",
                "- Automatic Gemini API key rotation on quota errors\n",
                "- Explainable, brand-safe responses\n",
                "- Zero database mutation (read-only guarantee)\n",
                "\n",
                "### Usage\n",
                "Run `ask_brand_brain()` and start chatting.\n",
                "Type `exit` to stop the session.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "id": "8056966f",
            "metadata": {},
            "outputs": [],
            "source": [
                "# def render_brand_brain_response(response: dict):\n",
                "#     \"\"\"\n",
                "#     Human-friendly rendering of Brand Brain output.\n",
                "#     \"\"\"\n",
                "\n",
                "#     display(Markdown(\"### ü§ñ Brand Brain\"))\n",
                "#     display(Markdown(response.get(\"answer\", \"_No response generated._\")))\n",
                "\n",
                "#     confidence = response.get(\"confidence_level\", \"unknown\")\n",
                "#     confidence_badge = {\n",
                "#         \"high\": \"üü¢ **High confidence** (Approved brand memory)\",\n",
                "#         \"medium\": \"üü° **Medium confidence** (Inferred brand memory)\",\n",
                "#         \"live\": \"üîµ **Live context used**\"\n",
                "#     }.get(confidence, \"‚ö™ Confidence unknown\")\n",
                "\n",
                "#     display(Markdown(f\"**Confidence:** {confidence_badge}\"))\n",
                "\n",
                "#     display(Markdown(\"---\"))\n",
                "#     display(Markdown(\"#### üîç Explainability\"))\n",
                "\n",
                "#     display(Markdown(f\"- **Brand elements used:** {', '.join(response.get('brand_elements_used', [])) or 'N/A'}\"))\n",
                "#     display(Markdown(f\"- **Memory sources:** {', '.join(response.get('memory_sources', [])) or 'N/A'}\"))\n",
                "    \n",
                "#     safety_status = response.get('safety_status', 'UNKNOWN')\n",
                "#     if safety_status == 'PASS_WITH_WARNING':\n",
                "#         safety_display = \"‚ö†Ô∏è **Soft Safety Warning** (Brand Conflict Explained)\"\n",
                "#     else:\n",
                "#         safety_display = f\"`{safety_status}`\"\n",
                "    \n",
                "#     display(Markdown(f\"- **Safety status:** {safety_display}\"))\n",
                "\n",
                "# def ask_brand_brain():\n",
                "#     \"\"\"\n",
                "#     Interactive Brand Brain chat (read-only).\n",
                "#     \"\"\"\n",
                "#     print(\"\\nüí¨ Ask Brand Brain (type 'exit' to stop)\\n\")\n",
                "\n",
                "#     while True:\n",
                "#         user_query = input(\"You: \").strip()\n",
                "\n",
                "#         if user_query.lower() in [\"exit\", \"quit\"]:\n",
                "#             print(\"üëã Exiting Brand Brain chat.\")\n",
                "#             break\n",
                "\n",
                "#         if not user_query:\n",
                "#             print(\"‚ö†Ô∏è Please enter a question.\")\n",
                "#             continue\n",
                "\n",
                "#         try:\n",
                "#             response = chat_session(user_query)\n",
                "#             render_brand_brain_response(response)\n",
                "#         except Exception as e:\n",
                "#             print(f\"‚ùå Error: {e}\")\n",
                "\n",
                "#         print(\"\\n\" + \"=\" * 60 + \"\\n\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "ad966794",
            "metadata": {},
            "outputs": [],
            "source": [
                "#ask_brand_brain()\n",
                "# What is our mission and vision?\n",
                "# What colors and fonts define our brand?\n",
                "# Is aggressive discounting on-brand?\n",
                "# How should we sound on LinkedIn?\n",
                "# Write a Diwali campaign"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3a4538ab",
            "metadata": {},
            "source": [
                "## **Brand Brain Interactive Chat (v1.7) UX**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "id": "af3b141d",
            "metadata": {},
            "outputs": [],
            "source": [
                "from IPython.display import display, Markdown\n",
                "\n",
                "def render_brand_brain_response_clean(response: dict, intent: str):\n",
                "    \"\"\"\n",
                "    Non-tech friendly Brand Brain response renderer.\n",
                "    \"\"\"\n",
                "\n",
                "    # Intent (Human-friendly)\n",
                "    intent_map = {\n",
                "        \"knowledge\": \"üìò Brand Knowledge\",\n",
                "        \"reasoning\": \"üß† Brand Reasoning\",\n",
                "        \"creative\": \"üé® Creative (Not Available)\"\n",
                "    }\n",
                "\n",
                "    display(Markdown(f\"### {intent_map.get(intent, 'üí¨ Brand Brain')}\"))\n",
                "\n",
                "    # Main Answer\n",
                "    display(Markdown(response.get(\"answer\", \"_No response generated._\")))\n",
                "\n",
                "    # Confidence (Human-friendly)\n",
                "    confidence = response.get(\"confidence_level\", \"unknown\")\n",
                "    confidence_map = {\n",
                "        \"high\": \"üü¢ Based on core brand guidelines\",\n",
                "        \"medium\": \"üü° Based on brand understanding\",\n",
                "        \"live\": \"üîµ Based on public information\"\n",
                "    }\n",
                "\n",
                "    display(Markdown(f\"**Confidence:** {confidence_map.get(confidence, '‚ö™ Confidence unavailable')}\"))\n",
                "\n",
                "    # Explainability\n",
                "    display(Markdown(\"---\"))\n",
                "    display(Markdown(\"#### üîç Why this answer\"))\n",
                "\n",
                "    explain_lines = []\n",
                "\n",
                "    if response.get(\"brand_elements_used\"):\n",
                "        explain_lines.append(\"‚Ä¢ Based on brand identity, voice, and positioning\")\n",
                "\n",
                "    if response.get(\"memory_sources\"):\n",
                "        explain_lines.append(\"‚Ä¢ Uses existing brand knowledge (no external learning)\")\n",
                "\n",
                "    if response.get(\"safety_status\", \"\").startswith(\"‚ö†Ô∏è\"):\n",
                "        explain_lines.append(\"‚Ä¢ This topic was evaluated carefully to protect brand positioning\")\n",
                "\n",
                "    if not explain_lines:\n",
                "        explain_lines.append(\"‚Ä¢ Answered using available brand guidelines\")\n",
                "\n",
                "    for line in explain_lines:\n",
                "        display(Markdown(line))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c550bc45",
            "metadata": {},
            "outputs": [],
            "source": [
                "def ask_brand_brain_clean():\n",
                "    print(\"\\nüëã Welcome to Brand Brain\\n\")\n",
                "    print(\"Type 'exit' to stop.\\n\")\n",
                "\n",
                "    while True:\n",
                "        user_query = input(\"You: \").strip()\n",
                "\n",
                "        if user_query.lower() in [\"exit\", \"quit\"]:\n",
                "            print(\"üëã Exiting Brand Brain chat.\")\n",
                "            break\n",
                "\n",
                "        if not user_query:\n",
                "            print(\"‚ö†Ô∏è Please enter a question.\")\n",
                "            continue\n",
                "\n",
                "        response = chat_session(user_query)\n",
                "\n",
                "        # Extract intent safely\n",
                "        intent = response.get(\"intent\", \"knowledge\")\n",
                "\n",
                "        # Render clean UX\n",
                "        render_brand_brain_response_clean(response, intent)\n",
                "\n",
                "        print(\"\\n\" + \"=\" * 60 + \"\\n\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "id": "cf92e692",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "üëã Welcome to Brand Brain\n",
                        "\n",
                        "You can ask about:\n",
                        "‚Ä¢ Mission, vision, values\n",
                        "‚Ä¢ Brand tone and positioning\n",
                        "‚Ä¢ Target audience and markets\n",
                        "‚Ä¢ Whether an idea is on-brand\n",
                        "\n",
                        "Type 'exit' to stop.\n",
                        "\n",
                        "‚ö†Ô∏è Gemini call failed (attempt 1/4): 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n"
                    ]
                },
                {
                    "data": {
                        "text/markdown": [
                            "### üìò Brand Knowledge"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "Based on the provided context, the brand's mission and vision can be understood as:\n",
                            "\n",
                            "To enrich everyday living with reliable, thoughtfully engineered appliances that combine global heritage, modern innovation, and timeless design‚Äîdelivering confidence, comfort, and consistency to Indian homes.\n",
                            "\n",
                            "The context also notes that \"Confidence\" is an inferred aspect of this mission/vision."
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "**Confidence:** üü¢ Based on core brand guidelines"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "---"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "#### üîç Why this answer"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "‚Ä¢ Based on brand identity, voice, and positioning"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "‚Ä¢ Uses existing brand knowledge (no external learning)"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "============================================================\n",
                        "\n",
                        "‚ö†Ô∏è Gemini call failed (attempt 1/4): 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
                        "‚ö†Ô∏è Gemini call failed (attempt 2/4): 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n"
                    ]
                },
                {
                    "data": {
                        "text/markdown": [
                            "### üìò Brand Knowledge"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "Based on the provided context, the colors and fonts that define the brand are:\n",
                            "\n",
                            "**Colors:**\n",
                            "*   Westinghouse blue\n",
                            "*   White\n",
                            "*   Black\n",
                            "\n",
                            "These are the only acceptable colors for logos and identity elements.\n",
                            "\n",
                            "**Fonts:**\n",
                            "*   Westinghouse Sans (a custom font developed with characters inspired by the original logo)\n",
                            "*   Westinghouse Gothic Typeface"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "**Confidence:** üü¢ Based on core brand guidelines"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "---"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "#### üîç Why this answer"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "‚Ä¢ Based on brand identity, voice, and positioning"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "‚Ä¢ Uses existing brand knowledge (no external learning)"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "============================================================\n",
                        "\n",
                        "‚ö†Ô∏è Gemini call failed (attempt 1/4): 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n"
                    ]
                },
                {
                    "data": {
                        "text/markdown": [
                            "### üß† Brand Reasoning"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "Aggressive discounting is not aligned with the brand's established positioning.\n",
                            "\n",
                            "The brand is defined as \"Premium yet Approachable.\" Aggressive discounting can conflict with a premium positioning by shifting the focus from inherent value, quality, and design to price reduction, which may undermine the perception of a high-quality, premium offering.\n",
                            "\n",
                            "Instead of aggressive discounting, strategies that reinforce the brand's premium nature while maintaining approachability would be more aligned. This could involve emphasizing the inherent value, quality, design, and long-term benefits of the offering, or focusing on building trust and confidence through superior product/service experience and clear, functional communication."
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "**Confidence:** üü¢ Based on core brand guidelines"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "---"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "#### üîç Why this answer"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "‚Ä¢ Based on brand identity, voice, and positioning"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "‚Ä¢ Uses existing brand knowledge (no external learning)"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "============================================================\n",
                        "\n",
                        "‚ö†Ô∏è Gemini call failed (attempt 1/4): 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
                        "‚ö†Ô∏è Gemini call failed (attempt 2/4): 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
                        "‚ö†Ô∏è Gemini call failed (attempt 3/4): 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n"
                    ]
                },
                {
                    "data": {
                        "text/markdown": [
                            "### üìò Brand Knowledge"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "Based on the provided context, the brand's sound on LinkedIn should reflect its core identity and aspirations. It should be:\n",
                            "\n",
                            "*   **Forward-thinking and Visionary:** Emphasizing its role in \"pioneering the future of power\" and delivering \"future-ready\" solutions.\n",
                            "*   **Trustworthy and Authoritative:** Highlighting its \"legacy of quality\" and commitment to \"trustworthy innovation.\"\n",
                            "*   **Human-centric and Impactful:** Focusing on \"improving everyday life,\" \"bringing people together for the moments that matter,\" and \"transforming the human experience with technology.\"\n",
                            "*   **Committed to Sustainability and Performance:** Showcasing its efforts in \"defining enjoyable and sustainable living\" through \"reliable and high-performing home solutions and clean energy.\"\n",
                            "*   **Proactive and Leadership-oriented:** Positioning itself as a \"driving force\" in its field.\n",
                            "\n",
                            "In summary, the tone should be professional, confident, visionary, and grounded in its commitment to quality, human well-being, and a sustainable future."
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "**Confidence:** üü¢ Based on core brand guidelines"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "---"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "#### üîç Why this answer"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "‚Ä¢ Based on brand identity, voice, and positioning"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "‚Ä¢ Uses existing brand knowledge (no external learning)"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "============================================================\n",
                        "\n",
                        "üëã Exiting Brand Brain chat.\n"
                    ]
                }
            ],
            "source": [
                "ask_brand_brain_clean()\n",
                "# What is our mission and vision?\n",
                "# What colors and fonts define our brand?\n",
                "# Is aggressive discounting on-brand?\n",
                "# How should we sound on LinkedIn?\n",
                "# Write a Diwali campaign"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1c636fd6",
            "metadata": {},
            "outputs": [],
            "source": [
                "ask_brand_brain_clean()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "44f7755a",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.3"
        },
        "nbformat": 4,
        "nbformat_minor": 2
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
