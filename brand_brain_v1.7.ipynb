{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# **Brand Brain v1 - Development & Validation Harness**\n",
                "\n",
                "This notebook implements and validates the Brand Brain v1 architecture end-to-end. \n",
                "It covers data ingestion, semantic asset extraction, chunking, embedding, storage (Postgres + Pinecone), and brand-scoped retrieval.\n",
                "\n",
                "## **Architecture Recap**\n",
                "\n",
                "1.  **Input**: Brand JSON (simulating DynamoDB export)\n",
                "2.  **Ingestion**: \n",
                "    *   Extract Semantic Assets\n",
                "    *   Chunking (200-350 tokens)\n",
                "    *   Embedding (Gemini `gemini-embedding-001` @ 768 dims)\n",
                "3.  **Storage**:\n",
                "    *   **Postgres**: Structured memory (Assets, Chunks)\n",
                "    *   **Pinecone**: Semantic vectors (Namespace: `org:brand:type`)\n",
                "4.  **Retrieval**: Brand-scoped semantic search\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Configuration Loaded & Clients Initialized\n"
                    ]
                }
            ],
            "source": [
                "# 1. Setup & Configuration\n",
                "import os\n",
                "import json\n",
                "import uuid\n",
                "import time\n",
                "from typing import List, Dict, Any, Optional\n",
                "import pandas as pd\n",
                "import psycopg2\n",
                "from psycopg2.extras import RealDictCursor, Json\n",
                "from pinecone import Pinecone, ServerlessSpec\n",
                "from google import genai\n",
                "from dotenv import load_dotenv\n",
                "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
                "\n",
                "# Load environment variables\n",
                "load_dotenv(override=True) # Ensure we reload if .env changed\n",
                "\n",
                "NEON_DB_URL = os.getenv(\"NEON_DB_URL\")\n",
                "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
                "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY4\")\n",
                "\n",
                "if not all([NEON_DB_URL, PINECONE_API_KEY, GEMINI_API_KEY]):\n",
                "    raise ValueError(\"Missing required environment variables. Please check your .env file.\")\n",
                "\n",
                "# Initialize Clients\n",
                "client = genai.Client(api_key=GEMINI_API_KEY)\n",
                "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
                "\n",
                "# Database Connection Helper\n",
                "def get_db_connection():\n",
                "    return psycopg2.connect(NEON_DB_URL)\n",
                "\n",
                "print(\"‚úÖ Configuration Loaded & Clients Initialized\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Connected to Neon DB. Tables exist.\n"
                    ]
                }
            ],
            "source": [
                "# 2. Database Pre-checks (No Table Creation)\n",
                "def check_connection():\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    try:\n",
                "        cur.execute(\"SELECT count(*) FROM information_schema.tables WHERE table_name = 'brand_assets'\")\n",
                "        if cur.fetchone()[0] == 0:\n",
                "            print(\"‚ùå ERROR: Tables not found! Please run tables.sql in Neon console.\")\n",
                "        else:\n",
                "            print(\"‚úÖ Connected to Neon DB. Tables exist.\")\n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Connection Failed: {e}\")\n",
                "    finally:\n",
                "        cur.close()\n",
                "        conn.close()\n",
                "\n",
                "check_connection()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Input Brand Data\n",
                "\n",
                "# Parsed from Westinghouse India.txt\n",
                "westinghouse_json = {\n",
                "    \"brandId\": \"wh_india_001\",\n",
                "    \"name\": \"Westinghouse India\",\n",
                "    \"industry\": \"FMEG\",\n",
                "    \"mission\": \"To enrich everyday living with reliable, thoughtfully engineered appliances that combine global heritage, modern innovation, and timeless design‚Äîdelivering confidence, comfort, and consistency to Indian homes.\",\n",
                "    \"brandVoice\": \"Confident & Reassuring. Premium yet Approachable. Clear & Functional. Trust-First. Design-Conscious.\",\n",
                "    \"visualStyle\": \"Design-forward minimalism. Product as hero. Lifestyle-led context. Retro-modern blend. Premium finishes. Colors: Orange, Red, White, Green, Blue, Black.\",\n",
                "    \"audience\": \"All genders, 25‚Äì45 years (core). Upper-middle to affluent households. Interests: Premium home & kitchen appliances, Modern kitchen aesthetics, Smart living. Focus: Tier 1 metros (Mumbai, Delhi NCR...) and affluent Tier 2.\",\n",
                "    \"competitors\": \"Morphy Richards (Strong British Heritage, Wide Portfolio). Weaknesses: Inconsistent Visual Identity, Limited Design Differentiation.\",\n",
                "    \"inspiration\": \"Morphy Richards\",\n",
                "    \"website\": \"https://www.westinghousehomeware.in/\"\n",
                "}\n",
                "\n",
                "brands_to_ingest = [westinghouse_json]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Asset Extraction Logic Defined\n"
                    ]
                }
            ],
            "source": [
                "# 4. Semantic Asset Extraction Logic\n",
                "\n",
                "def extract_assets(brand_data: Dict) -> List[Dict]:\n",
                "    assets = []\n",
                "    brand_id = brand_data.get(\"brandId\")\n",
                "    \n",
                "    # Extraction Rules Mapping\n",
                "    # Source Field -> (Asset Type [copy/guideline/website], Vector Type [brand_voice/strategy/performance])\n",
                "    mapping = {\n",
                "        \"mission\": (\"guideline\", \"strategy\"),\n",
                "        \"brandVoice\": (\"guideline\", \"brand_voice\"),\n",
                "        \"visualStyle\": (\"guideline\", \"brand_voice\"),\n",
                "        \"audience\": (\"guideline\", \"strategy\"),\n",
                "        \"competitors\": (\"guideline\", \"strategy\"),\n",
                "        \"inspiration\": (\"guideline\", \"strategy\"),\n",
                "        \"website\": (\"website\", \"strategy\")\n",
                "    }\n",
                "    \n",
                "    for field, (asset_type, vector_type) in mapping.items():\n",
                "        content = brand_data.get(field)\n",
                "        if content:\n",
                "            assets.append({\n",
                "                \"asset_id\": str(uuid.uuid4()),\n",
                "                \"brand_id\": brand_id,\n",
                "                \"asset_type\": asset_type,\n",
                "                \"vector_type\": vector_type,\n",
                "                \"source_field\": field,\n",
                "                \"content\": content\n",
                "            })\n",
                "            \n",
                "    return assets\n",
                "\n",
                "print(\"‚úÖ Asset Extraction Logic Defined\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Chunking & Embedding Functions Defined (New SDK - 768 dims)\n"
                    ]
                }
            ],
            "source": [
                "# 5. Chunking & Embedding Logic\n",
                "\n",
                "text_splitter = RecursiveCharacterTextSplitter(\n",
                "    chunk_size=350,\n",
                "    chunk_overlap=50,\n",
                "    length_function=len,\n",
                "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
                ")\n",
                "\n",
                "def chunk_text(text: str) -> List[str]:\n",
                "    return text_splitter.split_text(text)\n",
                "\n",
                "def generate_embedding(text: str) -> List[float]:\n",
                "    # Using gemini-embedding-001 with truncation to 768 dimensions\n",
                "    try:\n",
                "        result = client.models.embed_content(\n",
                "            model=\"gemini-embedding-001\",\n",
                "            contents=text,\n",
                "            config={\n",
                "                'output_dimensionality': 768,\n",
                "                'task_type': 'RETRIEVAL_DOCUMENT',\n",
                "                'title': 'Brand Asset'\n",
                "            }\n",
                "        )\n",
                "        return result.embeddings[0].values\n",
                "    except Exception as e:\n",
                "        print(f\"Embedding Error: {e}\")\n",
                "        return []\n",
                "\n",
                "print(\"‚úÖ Chunking & Embedding Functions Defined (New SDK - 768 dims)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. Ingestion Pipeline (Production Schema)\n",
                "\n",
                "def ingest_brand(brand_data: Dict):\n",
                "    brand_id_str = brand_data['brandId']\n",
                "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
                "    \n",
                "    brand_name = brand_data.get('name', 'Unknown')\n",
                "    org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org')) # Placeholder Org\n",
                "\n",
                "    print(f\"\\nüß† Ingesting Brand: {brand_name} (UUID: {brand_uuid}) ...\")\n",
                "    \n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    \n",
                "    try:\n",
                "        # 1. Ensure Organization Exists\n",
                "        cur.execute(\n",
                "            \"INSERT INTO organizations (org_id, name) VALUES (%s, %s) ON CONFLICT (org_id) DO NOTHING\",\n",
                "            (org_id, \"Test Org\")\n",
                "        )\n",
                "\n",
                "        # 2. Ensure Brand Exists\n",
                "        cur.execute(\n",
                "            \"INSERT INTO brands (brand_id, org_id, name, industry) VALUES (%s, %s, %s, %s) ON CONFLICT (brand_id) DO NOTHING\",\n",
                "            (brand_uuid, org_id, brand_name, brand_data.get('industry', 'Unknown'))\n",
                "        )\n",
                "\n",
                "        # 3. Extract Assets\n",
                "        assets = extract_assets(brand_data)\n",
                "        print(f\"   -> Extracted {len(assets)} semantic assets\")\n",
                "\n",
                "        # Prepare Pinecone\n",
                "        index_name = \"brand-brain-index\"\n",
                "        \n",
                "        # DEBUG: Check what key is actually being used\n",
                "        masked = PINECONE_API_KEY[:5] + \"...\" if PINECONE_API_KEY else \"None\"\n",
                "        print(f\"   [DEBUG] Checking Pinecone Index with Key: {masked}\")\n",
                "        \n",
                "        # Create index if not exists\n",
                "        if index_name not in pc.list_indexes().names():\n",
                "             pc.create_index(\n",
                "                name=index_name,\n",
                "                dimension=768,\n",
                "                metric=\"cosine\",\n",
                "                spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
                "            )\n",
                "        idx = pc.Index(index_name)\n",
                "\n",
                "        total_chunks = 0\n",
                "        \n",
                "        for asset in assets:\n",
                "            # Insert Asset Metadata\n",
                "            cur.execute(\n",
                "                \"INSERT INTO brand_assets (asset_id, brand_id, asset_type, raw_text, source) VALUES (%s, %s, %s, %s, %s) ON CONFLICT (asset_id) DO NOTHING\",\n",
                "                (asset['asset_id'], brand_uuid, asset['asset_type'], asset['content'], asset['source_field'])\n",
                "            )\n",
                "            \n",
                "            chunks = chunk_text(asset['content'])\n",
                "            \n",
                "            for i, chunk_text_content in enumerate(chunks):\n",
                "                chunk_id = str(uuid.uuid4())\n",
                "                embedding_id = str(uuid.uuid4())\n",
                "                vector = generate_embedding(chunk_text_content)\n",
                "                \n",
                "                if not vector:\n",
                "                    print(f\"Skipping chunk due to embedding failure\")\n",
                "                    continue\n",
                "\n",
                "                cur.execute(\n",
                "                    \"INSERT INTO brand_chunks (chunk_id, asset_id, brand_id, vector_type, content, token_count) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
                "                    (chunk_id, asset['asset_id'], brand_uuid, asset['vector_type'], chunk_text_content, len(chunk_text_content.split()))\n",
                "                )\n",
                "                \n",
                "                namespace = f\"{org_id}:{brand_uuid}:{asset['vector_type']}\"\n",
                "                cur.execute(\n",
                "                    \"INSERT INTO embeddings (embedding_id, chunk_id, brand_id, vector_type, namespace, model) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
                "                    (embedding_id, chunk_id, brand_uuid, asset['vector_type'], namespace, \"gemini-embedding-001\")\n",
                "                )\n",
                "\n",
                "                idx.upsert(\n",
                "                    vectors=[(chunk_id, vector, {\"source\": asset['source_field']})],\n",
                "                    namespace=namespace\n",
                "                )\n",
                "                total_chunks += 1\n",
                "        \n",
                "        conn.commit()\n",
                "        print(f\"‚úÖ Successfully ingested {total_chunks} chunks for {brand_name}.\")\n",
                "        \n",
                "    except Exception as e:\n",
                "        conn.rollback()\n",
                "        print(f\"‚ùå Ingestion Failed: {e}\")\n",
                "    finally:\n",
                "        cur.close()\n",
                "        conn.close()\n",
                "\n",
                "# Run Ingestion\n",
                "for brand in brands_to_ingest:\n",
                "    ingest_brand(brand)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- TEST 1: Westinghouse Brand Voice ---\n",
                        "\n",
                        "üîé Querying Brand wh_india_001 (UUID: 25ecf8da-150a-506d-aef6-7b2794b4b114) [brand_voice]: 'Describe our design philosophy.'\n",
                        "   [1] Score: 0.6904 | Content: Confident & Reassuring. Premium yet Approachable. Clear & Functional. Trust-First. Design-Conscious....\n",
                        "   [2] Score: 0.6904 | Content: Confident & Reassuring. Premium yet Approachable. Clear & Functional. Trust-First. Design-Conscious....\n",
                        "   [3] Score: 0.6904 | Content: Confident & Reassuring. Premium yet Approachable. Clear & Functional. Trust-First. Design-Conscious....\n",
                        "\n",
                        "--- TEST 2: Westinghouse Strategy ---\n",
                        "\n",
                        "üîé Querying Brand wh_india_001 (UUID: 25ecf8da-150a-506d-aef6-7b2794b4b114) [strategy]: 'Who are we fighting against?'\n",
                        "   [1] Score: 0.5286 | Content: To enrich everyday living with reliable, thoughtfully engineered appliances that combine global heri...\n",
                        "   [2] Score: 0.5286 | Content: To enrich everyday living with reliable, thoughtfully engineered appliances that combine global heri...\n",
                        "   [3] Score: 0.5286 | Content: To enrich everyday living with reliable, thoughtfully engineered appliances that combine global heri...\n",
                        "\n",
                        "--- TEST 3: Isolation / Irrelevant Query ---\n",
                        "\n",
                        "üîé Querying Brand wh_india_001 (UUID: 25ecf8da-150a-506d-aef6-7b2794b4b114) [brand_voice]: 'How to be cheap and loud?'\n",
                        "   [1] Score: 0.5464 | Content: Design-forward minimalism. Product as hero. Lifestyle-led context. Retro-modern blend. Premium finis...\n",
                        "   [2] Score: 0.5464 | Content: Design-forward minimalism. Product as hero. Lifestyle-led context. Retro-modern blend. Premium finis...\n",
                        "   [3] Score: 0.5464 | Content: Design-forward minimalism. Product as hero. Lifestyle-led context. Retro-modern blend. Premium finis...\n"
                    ]
                }
            ],
            "source": [
                "# 7. Retrieval & Validation Logic\n",
                "\n",
                "def retrieve_context(brand_name_str: str, query: str, vector_type: str = \"brand_voice\", top_k: int = 3):\n",
                "    if brand_name_str == \"wh_india_001\":\n",
                "        brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_name_str))\n",
                "        org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
                "    else:\n",
                "        brand_uuid = brand_name_str\n",
                "        org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
                "\n",
                "    print(f\"\\nüîé Querying Brand {brand_name_str} (UUID: {brand_uuid}) [{vector_type}]: '{query}'\")\n",
                "    \n",
                "    # New SDK for Query Embedding\n",
                "    try:\n",
                "        query_embedding_result = client.models.embed_content(\n",
                "            model=\"gemini-embedding-001\",\n",
                "            contents=query,\n",
                "            config={\n",
                "                'output_dimensionality': 768,\n",
                "                'task_type': 'RETRIEVAL_QUERY'\n",
                "            }\n",
                "        )\n",
                "        query_embedding = query_embedding_result.embeddings[0].values\n",
                "    except Exception as e:\n",
                "        print(f\"Embedding Error during retrieval: {e}\")\n",
                "        return []\n",
                "    \n",
                "    namespace = f\"{org_id}:{brand_uuid}:{vector_type}\"\n",
                "    index_name = \"brand-brain-index\"\n",
                "    idx = pc.Index(index_name)\n",
                "    \n",
                "    results = idx.query(\n",
                "        vector=query_embedding,\n",
                "        top_k=top_k,\n",
                "        namespace=namespace,\n",
                "        include_metadata=True\n",
                "    )\n",
                "    \n",
                "    if not results['matches']:\n",
                "        print(\"   ‚ö†Ô∏è No matches found in namespace:\", namespace)\n",
                "        return []\n",
                "        \n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    \n",
                "    retrieved_docs = []\n",
                "    chunk_ids = [m['id'] for m in results['matches']]\n",
                "    \n",
                "    if chunk_ids:\n",
                "        placeholders = ', '.join(['%s'] * len(chunk_ids))\n",
                "        query_sql = f\"SELECT content, vector_type FROM brand_chunks WHERE chunk_id IN ({placeholders})\"\n",
                "        cur.execute(query_sql, tuple(chunk_ids))\n",
                "        rows = cur.fetchall()\n",
                "        \n",
                "        for i, row in enumerate(rows):\n",
                "            score = results['matches'][i]['score']\n",
                "            print(f\"   [{i+1}] Score: {score:.4f} | Content: {row[0][:100]}...\")\n",
                "            retrieved_docs.append({\"content\": row[0], \"score\": score})\n",
                "            \n",
                "    cur.close()\n",
                "    conn.close()\n",
                "    return retrieved_docs\n",
                "\n",
                "# 8. Run Validation Tests\n",
                "def run_validation():\n",
                "    # Test 1: Westinghouse Brand Voice\n",
                "    print(\"\\n--- TEST 1: Westinghouse Brand Voice ---\")\n",
                "    retrieve_context(\"wh_india_001\", \"Describe our design philosophy.\", vector_type=\"brand_voice\")\n",
                "    \n",
                "    # Test 2: Westinghouse Competitor Context\n",
                "    print(\"\\n--- TEST 2: Westinghouse Strategy ---\")\n",
                "    retrieve_context(\"wh_india_001\", \"Who are we fighting against?\", vector_type=\"strategy\")\n",
                "    \n",
                "    # Test 3: Off-Brand check\n",
                "    print(\"\\n--- TEST 3: Isolation / Irrelevant Query ---\")\n",
                "    retrieve_context(\"wh_india_001\", \"How to be cheap and loud?\", vector_type=\"brand_voice\")\n",
                "\n",
                "run_validation()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## **Brand Brain v1.5 - Grounded Cognition Extensions**\n",
                "\n",
                "The following sections implement **Brand Brain v1.5** with strict adherence to:\n",
                "1. **Type A/B/C Memory separation**\n",
                "2. **Evidence-based Grounding**\n",
                "3. **Deterministic Safety Rules**\n",
                "4. **No implicit memory growth**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "347a5efd",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ v1.5 Libraries Loaded\n"
                    ]
                }
            ],
            "source": [
                "# v1.5 Imports\n",
                "import numpy as np\n",
                "from google.genai import types\n",
                "import statistics\n",
                "\n",
                "print(\"‚úÖ v1.5 Libraries Loaded\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "300959cb",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Section A: Grounding-Assisted Ingestion Implementation Ready\n"
                    ]
                }
            ],
            "source": [
                "# SECTION A: Grounding-Assisted Ingestion (Type B Memory)\n",
                "\n",
                "def grounding_assisted_ingest(brand_data: Dict, target_vector_type=\"strategy\"):\n",
                "    \"\"\"\n",
                "    Uses Gemini Google Search tools to extract ONLY evergreen brand philosophy.\n",
                "    Enforces strict prompt filters.\n",
                "    Stores as Type B memory with version tags.\n",
                "    \"\"\"\n",
                "    brand_name = brand_data['name']\n",
                "    website = brand_data.get('website', '')\n",
                "    \n",
                "    print(f\"\\nüåç Starting Grounding-Assisted Ingestion for {brand_name}...\")\n",
                "\n",
                "    # 1. Define Prompt with HARD FILTERS\n",
                "    prompt = f\"\"\"\n",
                "    You are a Brand Identity Expert.\n",
                "    SEARCH for \"{brand_name} brand philosophy design principles manifesto\".\n",
                "    Also check the provided website: {website}\n",
                "\n",
                "    EXTRACT ONLY evergreen, high-level brand identity content.\n",
                "    \n",
                "    ‚ùå STRICTLY IGNORE:\n",
                "    - pricing, offers, discounts\n",
                "    - launches, new arrivals\n",
                "    - comparisons, awards\n",
                "    - timelines, history dates\n",
                "    - \"latest\", \"new\", \"recent\", \"2024\", \"2025\"\n",
                "\n",
                "    ‚úÖ EXTRACT ONLY:\n",
                "    - philosophy & mission\n",
                "    - design principles\n",
                "    - core values\n",
                "    - identity statements\n",
                "    \n",
                "    RETURN JSON in this format:\n",
                "    {{\n",
                "      \"brand_philosophy\": \"string\",\n",
                "      \"design_principles\": \"string\",\n",
                "      \"positioning\": \"string\"\n",
                "    }}\n",
                "    \"\"\"\n",
                "\n",
                "    try:\n",
                "        # 2. Call Gemini with Search Tool\n",
                "        # [FIX] Removed response_mime_type to allow Tools to work correctly\n",
                "        response = client.models.generate_content(\n",
                "            model=\"gemini-2.5-flash\", # Using Flash for speed/tools\n",
                "            contents=prompt,\n",
                "            config=types.GenerateContentConfig(\n",
                "                tools=[types.Tool(google_search=types.GoogleSearchRetrieval)]\n",
                "            )\n",
                "        )\n",
                "        \n",
                "        # 3. Robust JSON Parsing (Manual)\n",
                "        text = response.text.strip()\n",
                "        if text.startswith(\"```json\"):\n",
                "            text = text[7:]\n",
                "        elif text.startswith(\"```\"):\n",
                "            text = text[3:]\n",
                "        if text.endswith(\"```\"):\n",
                "            text = text[:-3]\n",
                "            \n",
                "        extracted_data = json.loads(text.strip())\n",
                "        print(f\"   ‚úÖ Extracted Grounded Data: {list(extracted_data.keys())}\")\n",
                "\n",
                "        # 3. Format as Assets (Type B)\n",
                "        # Merging into a single text block for embedding is usually better for 'strategy'\n",
                "        combined_text = f\"Philosophy: {extracted_data.get('brand_philosophy', '')}\\n\"\n",
                "        combined_text += f\"Design Principles: {extracted_data.get('design_principles', '')}\\n\"\n",
                "        combined_text += f\"Positioning: {extracted_data.get('positioning', '')}\"\n",
                "\n",
                "        grounded_asset = {\n",
                "            \"asset_id\": str(uuid.uuid4()),\n",
                "            \"brand_id\": brand_data['brandId'],\n",
                "            \"asset_type\": \"guideline\", # Fixed: Must be one of 'copy', 'guideline', 'website'\n",
                "            \"vector_type\": target_vector_type,\n",
                "            \"source_field\": \"grounding_assisted_ingestion\",\n",
                "            \"content\": combined_text\n",
                "        }\n",
                "\n",
                "        # 4. Store & Embed (Reusing ingestion logic pattern)\n",
                "        ingest_single_asset(grounded_asset, brand_data) # Helper to be defined below\n",
                "\n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Grounding Ingestion Failed: {e}\")\n",
                "\n",
                "\n",
                "def ingest_single_asset(asset: Dict, brand_data: Dict):\n",
                "    \"\"\"Helper to ingest a single constructed asset.\"\"\"\n",
                "    brand_id_str = brand_data['brandId']\n",
                "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
                "    org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
                "    \n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    idx = pc.Index(\"brand-brain-index\")\n",
                "\n",
                "    try:\n",
                "        # Store Asset in Postgres\n",
                "        # Note: metadata like source_version is stored in source or handled via separate columns in prod\n",
                "        # Here we pack it into 'source' string or similar for v1 demo\n",
                "        source_tag = f\"{asset['source_field']} | v1.5 | confidence:inferred\"\n",
                "        \n",
                "        cur.execute(\n",
                "            \"INSERT INTO brand_assets (asset_id, brand_id, asset_type, raw_text, source) VALUES (%s, %s, %s, %s, %s) ON CONFLICT (asset_id) DO NOTHING\",\n",
                "            (asset['asset_id'], brand_uuid, asset['asset_type'], asset['content'], source_tag)\n",
                "        )\n",
                "\n",
                "        chunks = chunk_text(asset['content'])\n",
                "        for chunk_text_content in chunks:\n",
                "            chunk_id = str(uuid.uuid4())\n",
                "            embedding_id = str(uuid.uuid4())\n",
                "            vector = generate_embedding(chunk_text_content)\n",
                "            \n",
                "            if not vector: continue\n",
                "\n",
                "            cur.execute(\n",
                "                \"INSERT INTO brand_chunks (chunk_id, asset_id, brand_id, vector_type, content, token_count) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
                "                (chunk_id, asset['asset_id'], brand_uuid, asset['vector_type'], chunk_text_content, len(chunk_text_content.split()))\n",
                "            )\n",
                "            \n",
                "            namespace = f\"{org_id}:{brand_uuid}:{asset['vector_type']}\"\n",
                "            \n",
                "            cur.execute(\n",
                "                 \"INSERT INTO embeddings (embedding_id, chunk_id, brand_id, vector_type, namespace, model) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
                "                (embedding_id, chunk_id, brand_uuid, asset['vector_type'], namespace, \"gemini-embedding-001\")\n",
                "            )\n",
                "            \n",
                "            idx.upsert(\n",
                "                vectors=[(chunk_id, vector, {\"source\": source_tag})],\n",
                "                namespace=namespace\n",
                "            )\n",
                "        \n",
                "        conn.commit()\n",
                "        print(f\"   ‚úÖ Successfully stored Type B memory for {brand_data['name']}\")\n",
                "    finally:\n",
                "        cur.close()\n",
                "        conn.close()\n",
                "\n",
                "print(\"‚úÖ Section A: Grounding-Assisted Ingestion Implementation Ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "a7312ee2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Section B: Off-Brand Rule Engine Ready\n"
                    ]
                }
            ],
            "source": [
                "# SECTION B: Off-Brand Rule Engine (Deterministic)\n",
                "\n",
                "ALLOWED_INTENTS = {\"explain_brand\", \"validate_copy\", \"justify_decision\", \"minimal_rewrite\"}\n",
                "FORBIDDEN_KEYWORDS = {\"cheap\", \"free\", \"lowest price\", \"clearance\", \"sale\", \"loud\"} # removed discount\n",
                "\n",
                "def calculate_brand_centroid(brand_id: str, org_id: str, top_n=5) -> List[float]:\n",
                "    \"\"\"\n",
                "    Calculates deterministic centroid from top-N 'brand_voice' chunks.\n",
                "    In a real system, this is pre-computed. Here we fetch via a 'neutral' query.\n",
                "    \"\"\"\n",
                "    idx = pc.Index(\"brand-brain-index\")\n",
                "    namespace = f\"{org_id}:{brand_id}:brand_voice\"\n",
                "    \n",
                "    # Deterministic query to fetch representative chunks\n",
                "    # We use a static string that represents the ideal voice to find core chunks\n",
                "    query_vec = generate_embedding(\"brand voice tone philosophy identity\")\n",
                "    \n",
                "    results = idx.query(\n",
                "        vector=query_vec,\n",
                "        top_k=top_n,\n",
                "        namespace=namespace\n",
                "    )\n",
                "    \n",
                "    vectors = []\n",
                "    # Pinecone doesn't always return vectors in query results unless requested\n",
                "    # Assuming we need to fetch items. Actually idx.query(..., include_values=True)\n",
                "    if results['matches']:\n",
                "         # Re-query by ID to get values if needed, or just set include_values=True above\n",
                "         # Let's adjust query to include values\n",
                "         results_with_values = idx.query(\n",
                "            vector=query_vec,\n",
                "            top_k=top_n,\n",
                "            namespace=namespace,\n",
                "            include_values=True\n",
                "        )\n",
                "         for m in results_with_values['matches']:\n",
                "             vectors.append(m['values'])\n",
                "             \n",
                "    if not vectors:\n",
                "        return []\n",
                "    \n",
                "    return np.mean(vectors, axis=0).tolist()\n",
                "\n",
                "def check_brand_safety(user_query: str, brand_id_str: str, intent: str) -> Dict:\n",
                "    # 1. Intent Check\n",
                "    if intent not in ALLOWED_INTENTS:\n",
                "        return {\"status\": \"FAIL\", \"reason\": f\"Intent '{intent}' is not allowed in v1.5\"}\n",
                "    \n",
                "    # 2. Keyword Check\n",
                "    query_lower = user_query.lower()\n",
                "    violated_keywords = [kw for kw in FORBIDDEN_KEYWORDS if kw in query_lower]\n",
                "    if violated_keywords:\n",
                "         return {\"status\": \"FAIL\", \"reason\": f\"Forbidden keywords detected: {violated_keywords}\"}\n",
                "    \n",
                "    # 3. Semantic Drift Check\n",
                "    # Setup IDs\n",
                "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
                "    org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
                "    \n",
                "    centroid = calculate_brand_centroid(brand_uuid, org_id)\n",
                "    if not centroid:\n",
                "        # Fallback if no memory exists yet\n",
                "        return {\"status\": \"PASS\", \"reason\": \"No brand memory to validate against (Cold Start)\"}\n",
                "        \n",
                "    query_vec = generate_embedding(user_query)\n",
                "    similarity = np.dot(query_vec, centroid) / (np.linalg.norm(query_vec) * np.linalg.norm(centroid))\n",
                "    \n",
                "    # Threshold: If query is extremely dissimilar to brand voice AND contains questionable terms (handled by keywords)\n",
                "    # For v1.5, we enforce a baseline relevance\n",
                "    if similarity < 0.4: # Arbitrary strictness\n",
                "         return {\"status\": \"FAIL\", \"reason\": f\"Semantic drift detected (Score: {similarity:.2f}). Query not aligned with Brand Voice.\"}\n",
                "\n",
                "    return {\"status\": \"PASS\", \"reason\": \"All checks passed\"}\n",
                "\n",
                "print(\"‚úÖ Section B: Off-Brand Rule Engine Ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "1679150f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Section C: Brand Reasoner Ready\n"
                    ]
                }
            ],
            "source": [
                "# SECTION C: Brand Reasoner\n",
                "\n",
                "def generate_brand_response(query: str, context: List[Dict], safety_status: Dict, temp_grounding: str = None) -> str:\n",
                "    if safety_status['status'] == \"FAIL\":\n",
                "        return f\"üö´ BRAND SAFETY BLOCK: {safety_status['reason']}\"\n",
                "        \n",
                "    context_str = \"\\n\".join([f\"- {c['content']}\" for c in context])\n",
                "    if temp_grounding:\n",
                "        context_str += f\"\\n[EXTERNAL EVIDENCE]: {temp_grounding}\"\n",
                "        \n",
                "    prompt = f\"\"\"\n",
                "    You are Brand Brain. Your job is to Explain, Justify, or Minimally Rewrite.\n",
                "    Use the provided BRAND MEMORY as the source of truth.\n",
                "    If external evidence is provided, use it for context but subordinate it to Brand Memory.\n",
                "    \n",
                "    QUERY: {query}\n",
                "    \n",
                "    BRAND MEMORY:\n",
                "    {context_str}\n",
                "    \n",
                "    INSTRUCTIONS:\n",
                "    - Do not invent facts.\n",
                "    - Adhere to the tone found in memory.\n",
                "    \"\"\"\n",
                "    \n",
                "    response = client.models.generate_content(\n",
                "        model=\"gemini-2.5-flash\",\n",
                "        contents=prompt\n",
                "    )\n",
                "    return response.text\n",
                "\n",
                "print(\"‚úÖ Section C: Brand Reasoner Ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "427ab1e5",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Section D: Ephemeral Live Fetch Ready\n"
                    ]
                }
            ],
            "source": [
                "# SECTION D: Ephemeral Live Fetch (Type C Memory)\n",
                "\n",
                "def ephemeral_live_fetch(query: str) -> str:\n",
                "    \"\"\"\n",
                "    Fetches live data for Type C memory.\n",
                "    Guaranteed NO persistence.\n",
                "    \"\"\"\n",
                "    print(f\"   üåê Triggering Ephemeral Live Fetch for: '{query}'\")\n",
                "    \n",
                "    prompt = f\"Search Google for: {query}. Summarize the answer in 2 sentences.\"\n",
                "    \n",
                "    response = client.models.generate_content(\n",
                "        model=\"gemini-2.5-flash\",\n",
                "        contents=prompt,\n",
                "        config=types.GenerateContentConfig(\n",
                "            tools=[types.Tool(google_search=types.GoogleSearchRetrieval)]\n",
                "        )\n",
                "    )\n",
                "    \n",
                "    # Extract text from response (ignoring grounding metadata for the summary text)\n",
                "    return response.text\n",
                "\n",
                "print(\"‚úÖ Section D: Ephemeral Live Fetch Ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "baea23a3",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- TEST 1: Grounding-Assisted Ingestion ---\n",
                        "\n",
                        "üåç Starting Grounding-Assisted Ingestion for Westinghouse India...\n",
                        "   ‚úÖ Extracted Grounded Data: ['brand_philosophy', 'design_principles', 'positioning']\n",
                        "   ‚úÖ Successfully stored Type B memory for Westinghouse India\n",
                        "\n",
                        "--- VERIFYING TYPE B ASSETS IN DB ---\n",
                        "‚úÖ Found 8 Type B assets in Postgres.\n",
                        "\n",
                        "--- TEST 3: Live Query with Ephemeral Context ---\n",
                        "\n",
                        "üîé Querying Brand wh_india_001 (UUID: 25ecf8da-150a-506d-aef6-7b2794b4b114) [strategy]: 'What are the latest appliance trends suitable for our brand?'\n",
                        "   [1] Score: 0.6952 | Content: . The brand is committed to delivering solutions that make appliances future-ready, emphasizing exce...\n",
                        "   [2] Score: 0.6883 | Content: . It is perceived as a forward-thinking brand offering durable, elegant, and future-ready technology...\n",
                        "   [3] Score: 0.6818 | Content: . The brand demonstrates a strong commitment to innovations, aiming to deliver solutions that meet d...\n",
                        "   üåê Triggering Ephemeral Live Fetch for: 'What are the latest appliance trends suitable for our brand?'\n",
                        "\n",
                        "ü§ñ Final Response:\n",
                        "The latest appliance trends that align with our brand's ethos are those centered on advanced technology, sophisticated design, and a commitment to longevity and enhanced living. These trends are not merely passing fads but rather a natural evolution of the solutions our brand is dedicated to delivering.\n",
                        "\n",
                        "Foremost, there is a significant emphasis on **smart technology and AI integration**. This aligns perfectly with our brand's mission to offer future-ready solutions that meet demanding technological needs and leverage a passion for technology to transform human experience. Integrating smart capabilities allows us to further our commitment to innovations, enabling appliances to offer enhanced functionality, personalized services, and advanced energy management that truly elevate the everyday experience.\n",
                        "\n",
                        "Furthermore, **sustainability and energy efficiency** are critical. While ensuring our appliances are future-ready, we understand that this inherently includes efficiency. Customers seeking an investment in high-performing, long-lasting appliances expect solutions that are not only durable but also efficient, reflecting excellence in engineering and design.\n",
                        "\n",
                        "Finally, the demand for **versatile, compact, and aesthetically pleasing designs** resonates deeply with our brand. Our appeal to customers looking for durable, elegant, and future-ready technology means we prioritize designs that are not only stylish but also contribute to an elegant style in modern living spaces. This commitment to design excellence ensures that our solutions continue to be perceived as a valuable, long-term investment, truly elevating the everyday through thoughtful innovation and enduring beauty.\n",
                        "\n",
                        "üîí Verifying Type C Non-Persistence...\n",
                        "‚úÖ SUCCESS: Live trend data NOT found in Postgres (ignoring intentional Type A/B).\n"
                    ]
                }
            ],
            "source": [
                "# SECTION E: v1.5 Validation Harness\n",
                "\n",
                "def run_v1_5_validation():\n",
                "    brand_id = \"wh_india_001\"\n",
                "    \n",
                "    # 1. Simulate Type B Ingestion\n",
                "    print(\"\\n--- TEST 1: Grounding-Assisted Ingestion ---\")\n",
                "    grounding_assisted_ingest(westinghouse_json)\n",
                "    \n",
                "    # VERIFICATION OF TYPE B ASSETS\n",
                "    print(\"\\n--- VERIFYING TYPE B ASSETS IN DB ---\")\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    try:\n",
                "        cur.execute(\"SELECT count(*) FROM brand_assets WHERE source LIKE '%grounding_assisted%'\")\n",
                "        count = cur.fetchone()[0]\n",
                "        print(f\"‚úÖ Found {count} Type B assets in Postgres.\")\n",
                "        if count == 0:\n",
                "             print(\"‚ùå ERROR: Type B ingestion failed (no rows affected).\")\n",
                "    finally:\n",
                "        cur.close()\n",
                "        conn.close()\n",
                "        \n",
                "    # 2. Rejection Logic (OMITTED AS REQUESTED)\n",
                "    # print(\"\\n--- TEST 2: Off-Brand Rejection ---\")\n",
                "\n",
                "    # 3. End-to-End Success + Type C\n",
                "    print(\"\\n--- TEST 3: Live Query with Ephemeral Context ---\")\n",
                "    good_query = \"What are the latest appliance trends suitable for our brand?\"\n",
                "    safety_3 = check_brand_safety(good_query, brand_id, \"justify_decision\")\n",
                "    \n",
                "    if safety_3['status'] == \"PASS\":\n",
                "        # Retrieve Memory (Type A/B)\n",
                "        context = retrieve_context(brand_id, good_query, \"strategy\")\n",
                "        \n",
                "        # Trigger Live Fetch (Type C)\n",
                "        type_c_data = ephemeral_live_fetch(good_query)\n",
                "        \n",
                "        # Reason\n",
                "        response = generate_brand_response(good_query, context, safety_3, type_c_data)\n",
                "        print(f\"\\nü§ñ Final Response:\\n{response}\")\n",
                "\n",
                "        # PROOF OF NO PERSISTENCE\n",
                "        print(\"\\nüîí Verifying Type C Non-Persistence...\")\n",
                "        conn = get_db_connection()\n",
                "        cur = conn.cursor()\n",
                "        # Search for 'trends' which comes from live fetch\n",
                "        # but ensure we don't count type B or A if they happened to have it.\n",
                "        # We specifically check for *recent* assets that are NOT type B/A?\n",
                "        # Simple check: search for 'trends' in text, but EXCLUDE source='grounding_assisted_ingestion'\n",
                "        cur.execute(\"SELECT count(*) FROM brand_assets WHERE raw_text ILIKE '%trends%' AND source NOT LIKE '%grounding_assisted%'\")\n",
                "        count = cur.fetchone()[0]\n",
                "        if count == 0:\n",
                "             print(\"‚úÖ SUCCESS: Live trend data NOT found in Postgres (ignoring intentional Type A/B).\")\n",
                "        else:\n",
                "             print(\"‚ö†Ô∏è NOTE: 'trends' keyword found. Verify it is not from ephemeral fetch.\")\n",
                "        cur.close()\n",
                "        conn.close()\n",
                "\n",
                "run_v1_5_validation()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "54cc52c8",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## **Brand Brain v1.6 - Memory Governance Upgrade**\n",
                "\n",
                "The following cells implement **Brand Brain v1.6** extensions, adding human-governed memory control, confidence scoring, and memory review workflows.\n",
                "\n",
                "**Upgrades:**\n",
                "1. **Schema**: Added `confidence` field (inferred/reviewed/approved/deprecated).\n",
                "2. **Retrieval**: Prioritizes approved memory; excludes deprecated memory.\n",
                "3. **Governance**: Added functions to approve, reject, and edit memory."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ [v1.6] Ingestion Logic Updated\n"
                    ]
                }
            ],
            "source": [
                "# [v1.6 UPGRADE] Redefining Ingestion to support Confidence Scoring\n",
                "\n",
                "def ingest_single_asset(asset: Dict, brand_data: Dict):\n",
                "    \"\"\"[v1.6] Helper to ingest a single constructed asset with confidence defaults.\"\"\"\n",
                "    brand_id_str = brand_data['brandId']\n",
                "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
                "    org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
                "    \n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    idx = pc.Index(\"brand-brain-index\")\n",
                "\n",
                "    try:\n",
                "        # Store Asset in Postgres\n",
                "        source_tag = f\"{asset['source_field']} | v1.6 | confidence:inferred\"\n",
                "        \n",
                "        # [MODIFIED v1.6] Explicitly inserting confidence='inferred'\n",
                "        # Note: We rely on the schema update (ADD COLUMN confidence) having been run.\n",
                "        cur.execute(\n",
                "            \"INSERT INTO brand_assets (asset_id, brand_id, asset_type, raw_text, source, confidence) VALUES (%s, %s, %s, %s, %s, %s) ON CONFLICT (asset_id) DO NOTHING\",\n",
                "            (asset['asset_id'], brand_uuid, asset['asset_type'], asset['content'], source_tag, 'inferred')\n",
                "        )\n",
                "\n",
                "        chunks = chunk_text(asset['content'])\n",
                "        for chunk_text_content in chunks:\n",
                "            chunk_id = str(uuid.uuid4())\n",
                "            embedding_id = str(uuid.uuid4())\n",
                "            vector = generate_embedding(chunk_text_content)\n",
                "            \n",
                "            if not vector: continue\n",
                "            \n",
                "            vt = asset.get('vector_type', 'strategy')\n",
                "\n",
                "            cur.execute(\n",
                "                \"INSERT INTO brand_chunks (chunk_id, asset_id, brand_id, vector_type, content, token_count) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
                "                (chunk_id, asset['asset_id'], brand_uuid, vt, chunk_text_content, len(chunk_text_content.split()))\n",
                "            )\n",
                "            \n",
                "            namespace = f\"{org_id}:{brand_uuid}:{vt}\"\n",
                "            \n",
                "            cur.execute(\n",
                "                 \"INSERT INTO embeddings (embedding_id, chunk_id, brand_id, vector_type, namespace, model) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
                "                (embedding_id, chunk_id, brand_uuid, vt, namespace, \"gemini-embedding-001\")\n",
                "            )\n",
                "            \n",
                "            idx.upsert(\n",
                "                vectors=[(chunk_id, vector, {\"source\": source_tag})],\n",
                "                namespace=namespace\n",
                "            )\n",
                "        \n",
                "        conn.commit()\n",
                "        print(f\"   ‚úÖ [v1.6] Successfully stored Type B memory for {brand_data['name']} (Confidence: Inferred)\")\n",
                "    except Exception as e:\n",
                "        conn.rollback()\n",
                "        print(f\"‚ùå Ingestion Error: {e}\")\n",
                "    finally:\n",
                "        cur.close()\n",
                "        conn.close()\n",
                "print(\"‚úÖ [v1.6] Ingestion Logic Updated\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ [v1.6] Retrieval Logic Updated\n"
                    ]
                }
            ],
            "source": [
                "# [v1.6 UPGRADE] Redefining Retrieval to Prioritize Confidence & Filter Deprecated\n",
                "\n",
                "def retrieve_context(brand_name_str: str, query: str, vector_type: str = \"brand_voice\", top_k: int = 3):\n",
                "    if brand_name_str == \"wh_india_001\":\n",
                "        brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_name_str))\n",
                "        org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
                "    else:\n",
                "        brand_uuid = brand_name_str\n",
                "        org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
                "\n",
                "    print(f\"\\nüîé [v1.6] Querying Brand {brand_name_str} (UUID: {brand_uuid}) [{vector_type}]: '{query}'\")\n",
                "    \n",
                "    try:\n",
                "        query_embedding_result = client.models.embed_content(\n",
                "            model=\"gemini-embedding-001\",\n",
                "            contents=query,\n",
                "            config={\n",
                "                'output_dimensionality': 768,\n",
                "                'task_type': 'RETRIEVAL_QUERY'\n",
                "            }\n",
                "        )\n",
                "        query_embedding = query_embedding_result.embeddings[0].values\n",
                "    except Exception as e:\n",
                "        print(f\"Embedding Error during retrieval: {e}\")\n",
                "        return []\n",
                "    \n",
                "    namespace = f\"{org_id}:{brand_uuid}:{vector_type}\"\n",
                "    index_name = \"brand-brain-index\"\n",
                "    idx = pc.Index(index_name)\n",
                "    \n",
                "    # Fetch more candidates to allow for filtering of deprecated items\n",
                "    results = idx.query(\n",
                "        vector=query_embedding,\n",
                "        top_k=top_k * 3,\n",
                "        namespace=namespace,\n",
                "        include_metadata=True\n",
                "    )\n",
                "    \n",
                "    if not results['matches']:\n",
                "        print(\"   ‚ö†Ô∏è No matches found in namespace:\", namespace)\n",
                "        return []\n",
                "        \n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    \n",
                "    retrieved_docs = []\n",
                "    chunk_ids = [m['id'] for m in results['matches']]\n",
                "    \n",
                "    if chunk_ids:\n",
                "        placeholders = ', '.join(['%s'] * len(chunk_ids))\n",
                "        # [MODIFIED v1.6] Join with brand_assets to fetch 'confidence'\n",
                "        query_sql = f\"\"\"\n",
                "            SELECT c.chunk_id, c.content, c.vector_type, a.confidence \n",
                "            FROM brand_chunks c\n",
                "            JOIN brand_assets a ON c.asset_id = a.asset_id\n",
                "            WHERE c.chunk_id IN ({placeholders})\n",
                "        \"\"\"\n",
                "        cur.execute(query_sql, tuple(chunk_ids))\n",
                "        rows = cur.fetchall()\n",
                "        \n",
                "        # Lookup map\n",
                "        db_map = {row[0]: {\"content\": row[1], \"confidence\": row[3]} for row in rows}\n",
                "        \n",
                "        valid_candidates = []\n",
                "        \n",
                "        for match in results['matches']:\n",
                "            c_id = match['id']\n",
                "            score = match['score']\n",
                "            if c_id not in db_map: \n",
                "                continue\n",
                "                \n",
                "            data = db_map[c_id]\n",
                "            confidence = data['confidence'] or 'inferred' # Handle legacy rows where confidence might be NULL\n",
                "            \n",
                "            # [RULE] Exclude Deprecated\n",
                "            if confidence == 'deprecated':\n",
                "                continue\n",
                "                \n",
                "            # [RULE] Prioritize: approved (3) > reviewed (2) > inferred (1)\n",
                "            priority_score = 1\n",
                "            if confidence == 'approved': priority_score = 3\n",
                "            elif confidence == 'reviewed': priority_score = 2\n",
                "            \n",
                "            valid_candidates.append({\n",
                "                \"content\": data['content'],\n",
                "                \"score\": score,\n",
                "                \"confidence\": confidence,\n",
                "                \"priority\": priority_score\n",
                "            })\n",
                "            \n",
                "        # Sort by Priority (desc), then Similarity Score (desc)\n",
                "        valid_candidates.sort(key=lambda x: (x['priority'], x['score']), reverse=True)\n",
                "        \n",
                "        # Return top_k\n",
                "        final_results = valid_candidates[:top_k]\n",
                "        \n",
                "        for i, res in enumerate(final_results):\n",
                "            print(f\"   [{i+1}] [{res['confidence'].upper()}] Score: {res['score']:.4f} | Content: {res['content'][:100]}...\")\n",
                "            retrieved_docs.append(res)\n",
                "            \n",
                "    cur.close()\n",
                "    conn.close()\n",
                "    return retrieved_docs\n",
                "print(\"‚úÖ [v1.6] Retrieval Logic Updated\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ [v1.6] Section C: Functions Ready\n"
                    ]
                }
            ],
            "source": [
                "# SECTION C: Memory Review Functions (v1.6)\n",
                "\n",
                "def list_inferred_assets(brand_id_str: str):\n",
                "    print(f\"\\nüìã Listing Inferred Assets for {brand_id_str}...\")\n",
                "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor(cursor_factory=RealDictCursor)\n",
                "    cur.execute(\"SELECT asset_id, asset_type, raw_text, source, confidence FROM brand_assets WHERE brand_id = %s AND confidence = 'inferred'\", (brand_uuid,))\n",
                "    rows = cur.fetchall()\n",
                "    cur.close()\n",
                "    conn.close()\n",
                "    for r in rows:\n",
                "        print(f\"   [ID: {r['asset_id']}] {r['raw_text'][:50]}... (Source: {r['source']})\")\n",
                "    return rows\n",
                "\n",
                "def approve_asset(asset_id: str, reviewer: str, notes: str):\n",
                "    print(f\"\\n‚úÖ Approving Asset {asset_id}...\")\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    try:\n",
                "        cur.execute(\"SELECT confidence FROM brand_assets WHERE asset_id = %s\", (asset_id,))\n",
                "        res = cur.fetchone()\n",
                "        if not res: return\n",
                "        prev_conf = res[0]\n",
                "        cur.execute(\"UPDATE brand_assets SET confidence = 'approved', reviewed_by = %s, review_notes = %s, reviewed_at = NOW() WHERE asset_id = %s\", (reviewer, notes, asset_id))\n",
                "        cur.execute(\"INSERT INTO memory_reviews (review_id, asset_id, action, previous_confidence, new_confidence, reviewer, notes) VALUES (%s, %s, %s, %s, %s, %s, %s)\", (str(uuid.uuid4()), asset_id, 'approve', prev_conf, 'approved', reviewer, notes))\n",
                "        conn.commit()\n",
                "        print(\"   -> Asset Approved.\")\n",
                "    except Exception as e:\n",
                "        conn.rollback(); print(f\"‚ùå {e}\")\n",
                "    finally:\n",
                "        cur.close(); conn.close()\n",
                "\n",
                "def reject_asset(asset_id: str, reviewer: str, notes: str):\n",
                "    print(f\"\\n‚õî Rejecting Asset {asset_id}...\")\n",
                "    conn = get_db_connection(); cur = conn.cursor()\n",
                "    try:\n",
                "        cur.execute(\"SELECT confidence FROM brand_assets WHERE asset_id = %s\", (asset_id,))\n",
                "        res = cur.fetchone()\n",
                "        if not res: return\n",
                "        prev_conf = res[0]\n",
                "        cur.execute(\"UPDATE brand_assets SET confidence = 'deprecated', reviewed_by = %s, review_notes = %s, reviewed_at = NOW() WHERE asset_id = %s\", (reviewer, notes, asset_id))\n",
                "        cur.execute(\"INSERT INTO memory_reviews (review_id, asset_id, action, previous_confidence, new_confidence, reviewer, notes) VALUES (%s, %s, %s, %s, %s, %s, %s)\", (str(uuid.uuid4()), asset_id, 'deprecate', prev_conf, 'deprecated', reviewer, notes))\n",
                "        conn.commit()\n",
                "        print(\"   -> Asset Deprecated.\")\n",
                "    except Exception as e:\n",
                "        conn.rollback(); print(f\"‚ùå {e}\")\n",
                "    finally:\n",
                "        cur.close(); conn.close()\n",
                "\n",
                "def edit_and_promote_asset(asset_id: str, new_text: str, reviewer: str):\n",
                "    print(f\"\\nüìù Editing & Promoting Asset {asset_id}...\")\n",
                "    conn = get_db_connection(); cur = conn.cursor(cursor_factory=RealDictCursor)\n",
                "    try:\n",
                "        cur.execute(\"SELECT * FROM brand_assets WHERE asset_id = %s\", (asset_id,))\n",
                "        original = cur.fetchone()\n",
                "        if not original: return\n",
                "        # Deprecate Old\n",
                "        cur.execute(\"UPDATE brand_assets SET confidence = 'deprecated', reviewed_by = %s, review_notes = 'Replaced by edit', reviewed_at = NOW() WHERE asset_id = %s\", (reviewer, asset_id))\n",
                "        # Insert New Approved\n",
                "        new_asset_id = str(uuid.uuid4())\n",
                "        cur.execute(\"INSERT INTO brand_assets (asset_id, brand_id, asset_type, raw_text, source, confidence, reviewed_by, reviewed_at, review_notes) VALUES (%s, %s, %s, %s, %s, %s, %s, NOW(), 'Created via Edit')\", (new_asset_id, original['brand_id'], original['asset_type'], new_text, original['source'], 'approved', reviewer))\n",
                "        conn.commit()\n",
                "        print(f\"   -> Old Asset Deprecated. New Asset {new_asset_id} Created.\")\n",
                "        # Chunk & Embed New Asset\n",
                "        chunks = chunk_text(new_text)\n",
                "        idx = pc.Index(\"brand-brain-index\")\n",
                "        org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
                "        # Need vector_type\n",
                "        cur.execute(\"SELECT vector_type FROM brand_chunks WHERE asset_id = %s LIMIT 1\", (asset_id,))\n",
                "        vt = cur.fetchone()['vector_type']\n",
                "        for i, chunk in enumerate(chunks):\n",
                "            chunk_id = str(uuid.uuid4())\n",
                "            vec = generate_embedding(chunk)\n",
                "            cur.execute(\"INSERT INTO brand_chunks (chunk_id, asset_id, brand_id, vector_type, content, token_count) VALUES (%s, %s, %s, %s, %s, %s)\", (chunk_id, new_asset_id, original['brand_id'], vt, chunk, len(chunk.split())))\n",
                "            cur.execute(\"INSERT INTO embeddings (embedding_id, chunk_id, brand_id, vector_type, namespace, model) VALUES (%s, %s, %s, %s, %s, %s)\", (str(uuid.uuid4()), chunk_id, original['brand_id'], vt, f\"{org_id}:{original['brand_id']}:{vt}\", \"gemini-embedding-001\"))\n",
                "            idx.upsert(vectors=[(chunk_id, vec, {\"source\": original['source']})], namespace=f\"{org_id}:{original['brand_id']}:{vt}\")\n",
                "        conn.commit()\n",
                "        print(\"   -> New/Edited Asset Embeddings Generated.\")\n",
                "    except Exception as e:\n",
                "        conn.rollback(); print(f\"‚ùå Edit Failed: {e}\")\n",
                "    finally:\n",
                "        cur.close(); conn.close()\n",
                "print(\"‚úÖ [v1.6] Section C: Functions Ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "--- üß™ TEST 1: Ingestion starts as 'inferred' ---\n",
                        "‚úÖ Found 26 'inferred' assets\n",
                        "\n",
                        "--- üß™ TEST 2: Retrieval Priority (Approved > Inferred) [brand_voice] ---\n",
                        "\n",
                        "üìã Listing Inferred Assets for wh_india_001...\n",
                        "   [ID: 7bc146d0-7068-486b-bc28-4da657e10966] Morphy Richards (Strong British Heritage, Wide Por... (Source: competitors)\n",
                        "   [ID: d70f75c2-a5be-485f-864a-a7c5842a48bf] Morphy Richards... (Source: inspiration)\n",
                        "   [ID: 93215377-316d-4130-b009-4fb6136c437d] https://www.westinghousehomeware.in/... (Source: website)\n",
                        "   [ID: 870e34f5-8969-42d0-90ab-b07309685a65] To enrich everyday living with reliable, thoughtfu... (Source: mission)\n",
                        "   [ID: cc087901-bafe-4b2e-baff-3775407863b9] All genders, 25‚Äì45 years (core). Upper-middle to a... (Source: audience)\n",
                        "   [ID: 5f50d7d9-d4f0-4eb7-aa94-4bab4ce2a09b] Morphy Richards (Strong British Heritage, Wide Por... (Source: competitors)\n",
                        "   [ID: 0044f9e9-e6f4-4ec3-90ed-b93155d759be] Morphy Richards... (Source: inspiration)\n",
                        "   [ID: aae3ebaa-70d4-43fd-ba63-c278bffa4ffd] https://www.westinghousehomeware.in/... (Source: website)\n",
                        "   [ID: 514cdb81-822d-4fc9-b961-e634fe77e07e] Philosophy: Westinghouse's philosophy is to power ... (Source: grounding_assisted_ingestion | v1.5 | confidence:inferred)\n",
                        "   [ID: 6d446544-6ba4-45c9-9370-b011901f556d] Philosophy: At Westinghouse, the mission is to pow... (Source: grounding_assisted_ingestion | v1.5 | confidence:inferred)\n",
                        "   [ID: 9087537c-4800-41ae-9596-ea161900216a] Philosophy: Westinghouse's mission is to power mea... (Source: grounding_assisted_ingestion | v1.5 | confidence:inferred)\n",
                        "   [ID: e58d9a92-da98-44f2-863b-b2549b9a2ddd] Philosophy: Westinghouse is driven by a mission to... (Source: grounding_assisted_ingestion | v1.5 | confidence:inferred)\n",
                        "   [ID: 5a6bb33f-6c61-4e0d-901c-00de50271be6] To enrich everyday living with reliable, thoughtfu... (Source: mission)\n",
                        "   [ID: 4eeddc99-6d35-46c7-a8a3-3adf981bbd85] All genders, 25‚Äì45 years (core). Upper-middle to a... (Source: audience)\n",
                        "   [ID: 58779a7c-62a6-4f8e-9926-46e4c3232bd5] Morphy Richards (Strong British Heritage, Wide Por... (Source: competitors)\n",
                        "   [ID: 97c09bb2-c1c3-4890-8049-27ec066b320c] Morphy Richards... (Source: inspiration)\n",
                        "   [ID: 668a3420-b15e-4f20-8bc1-f5f2c0ad9ede] https://www.westinghousehomeware.in/... (Source: website)\n",
                        "   [ID: e730b6a9-c703-4f5b-9e26-e666e72c61a2] To enrich everyday living with reliable, thoughtfu... (Source: mission)\n",
                        "   [ID: be71e2bf-6d7d-4e5c-8622-a6d9e1147133] All genders, 25‚Äì45 years (core). Upper-middle to a... (Source: audience)\n",
                        "   [ID: ebfb5718-361a-4d80-b67d-8b53048dbecc] Morphy Richards (Strong British Heritage, Wide Por... (Source: competitors)\n",
                        "   [ID: 7fb9b1cb-0e94-44f8-9f5d-264358f33e44] Morphy Richards... (Source: inspiration)\n",
                        "   [ID: 1da8392a-f784-4a6d-93a7-660bb4cb8966] https://www.westinghousehomeware.in/... (Source: website)\n",
                        "   [ID: 8aca5285-86b1-447c-b729-635cfd6357a0] Philosophy: Westinghouse Homeware's mission is to ... (Source: grounding_assisted_ingestion | v1.5 | confidence:inferred)\n",
                        "   [ID: e1ab1962-c757-4f77-82f6-e754ed4bc250] Philosophy: Westinghouse's philosophy is rooted in... (Source: grounding_assisted_ingestion | v1.5 | confidence:inferred)\n",
                        "   [ID: 983898c7-e78c-4ffc-bdf3-0618c618ad78] Philosophy: Westinghouse's mission is to power mea... (Source: grounding_assisted_ingestion | v1.5 | confidence:inferred)\n",
                        "   [ID: ceb22e98-6615-48e3-9c99-cf1e950b1603] Philosophy: Westinghouse aims to power meaningful ... (Source: grounding_assisted_ingestion | v1.5 | confidence:inferred)\n",
                        "‚ùå No inferred brand_voice asset found to test.\n",
                        "\n",
                        "--- üß™ TEST 3: Deprecation (Exclude from Retrieval) ---\n",
                        "‚ö†Ô∏è Skipping TEST 3: No approved asset available.\n",
                        "\n",
                        "--- üß™ TEST 4: Audit Trail ---\n",
                        "   - Action: deprecate | Old: approved -> New: deprecated\n",
                        "   - Action: approve | Old: inferred -> New: approved\n",
                        "   - Action: deprecate | Old: approved -> New: deprecated\n",
                        "   - Action: approve | Old: inferred -> New: approved\n",
                        "   - Action: deprecate | Old: approved -> New: deprecated\n",
                        "\n",
                        "\n",
                        "--- üß™ TEST 1: Ingestion starts as 'inferred' ---\n",
                        "‚úÖ Found 26 'inferred' assets\n",
                        "\n",
                        "--- üß™ TEST 2: Retrieval Priority (Approved > Inferred) [brand_voice] ---\n",
                        "‚ö†Ô∏è No inferred brand_voice asset available. TEST 2 skipped (expected if already curated).\n",
                        "\n",
                        "--- üß™ TEST 3: Deprecation (Exclude from Retrieval) ---\n",
                        "‚ö†Ô∏è Skipping TEST 3: No approved asset available.\n",
                        "\n",
                        "--- üß™ TEST 4: Audit Trail ---\n",
                        "   - Action: deprecate | Old: approved -> New: deprecated\n",
                        "   - Action: approve | Old: inferred -> New: approved\n",
                        "   - Action: deprecate | Old: approved -> New: deprecated\n",
                        "   - Action: approve | Old: inferred -> New: approved\n",
                        "   - Action: deprecate | Old: approved -> New: deprecated\n"
                    ]
                }
            ],
            "source": [
                "# SECTION D: Validation Tests (v1.6)\n",
                "\n",
                "def run_v1_6_validation():\n",
                "    brand_id_str = \"wh_india_001\"\n",
                "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
                "\n",
                "    approved_asset_id = None\n",
                "    approved_asset_text = None\n",
                "\n",
                "    print(\"\\n\\n--- üß™ TEST 1: Ingestion starts as 'inferred' ---\")\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    cur.execute(\n",
                "        \"SELECT count(*) FROM brand_assets WHERE brand_id = %s AND confidence = 'inferred'\",\n",
                "        (brand_uuid,)\n",
                "    )\n",
                "    count = cur.fetchone()[0]\n",
                "    cur.close()\n",
                "    conn.close()\n",
                "    print(f\"‚úÖ Found {count} 'inferred' assets\")\n",
                "\n",
                "    # -------------------------------------------------\n",
                "\n",
                "    print(\"\\n--- üß™ TEST 2: Retrieval Priority (Approved > Inferred) [brand_voice] ---\")\n",
                "\n",
                "    # 1Ô∏è‚É£ List inferred assets\n",
                "    inferred = list_inferred_assets(brand_id_str)\n",
                "\n",
                "    # 2Ô∏è‚É£ Select an inferred BRAND_VOICE asset explicitly\n",
                "    brand_voice_target = None\n",
                "    for asset in inferred:\n",
                "        if asset[\"source\"] in [\"brandVoice\", \"visualStyle\"]:\n",
                "            brand_voice_target = asset\n",
                "            break\n",
                "\n",
                "    if not brand_voice_target:\n",
                "        print(\"‚ùå No inferred brand_voice asset found to test.\")\n",
                "    else:\n",
                "        approved_asset_id = brand_voice_target[\"asset_id\"]\n",
                "        approved_asset_text = brand_voice_target[\"raw_text\"]\n",
                "\n",
                "        print(\n",
                "            f\"   üéØ Targeting Brand Voice Asset: \"\n",
                "            f\"{approved_asset_text[:40]}...\"\n",
                "        )\n",
                "\n",
                "        # 3Ô∏è‚É£ Approve the brand_voice asset\n",
                "        approve_asset(\n",
                "            approved_asset_id,\n",
                "            reviewer=\"Admin\",\n",
                "            notes=\"Approved brand voice memory\"\n",
                "        )\n",
                "\n",
                "        # 4Ô∏è‚É£ Query SAME semantic space + namespace\n",
                "        res = retrieve_context(\n",
                "            brand_id_str,\n",
                "            \"design philosophy\",\n",
                "            \"brand_voice\"\n",
                "        )\n",
                "\n",
                "        # 5Ô∏è‚É£ Assert approved asset is prioritized\n",
                "        if res and res[0][\"confidence\"] == \"approved\":\n",
                "            print(\"‚úÖ SUCCESS: Approved brand_voice asset correctly prioritized.\")\n",
                "        else:\n",
                "            print(\n",
                "                f\"‚ùå FAILURE: Expected approved asset first, got \"\n",
                "                f\"{res[0]['confidence'] if res else 'None'}\"\n",
                "            )\n",
                "\n",
                "    # -------------------------------------------------\n",
                "\n",
                "    print(\"\\n--- üß™ TEST 3: Deprecation (Exclude from Retrieval) ---\")\n",
                "\n",
                "    if approved_asset_id:\n",
                "        reject_asset(\n",
                "            approved_asset_id,\n",
                "            reviewer=\"Admin\",\n",
                "            notes=\"Deprecating for validation test\"\n",
                "        )\n",
                "\n",
                "        res = retrieve_context(\n",
                "            brand_id_str,\n",
                "            \"design philosophy\",\n",
                "            \"brand_voice\"\n",
                "        )\n",
                "\n",
                "        found = any(\n",
                "            d[\"content\"] == approved_asset_text\n",
                "            for d in res\n",
                "        )\n",
                "\n",
                "        if not found:\n",
                "            print(\"‚úÖ Deprecated asset successfully EXCLUDED.\")\n",
                "        else:\n",
                "            print(\"‚ùå FAILURE: Deprecated asset still retrieved!\")\n",
                "\n",
                "    else:\n",
                "        print(\"‚ö†Ô∏è Skipping TEST 3: No approved asset available.\")\n",
                "\n",
                "    # -------------------------------------------------\n",
                "\n",
                "    print(\"\\n--- üß™ TEST 4: Audit Trail ---\")\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    cur.execute(\n",
                "        \"SELECT action, previous_confidence, new_confidence \"\n",
                "        \"FROM memory_reviews ORDER BY created_at DESC LIMIT 5\"\n",
                "    )\n",
                "    rows = cur.fetchall()\n",
                "    cur.close()\n",
                "    conn.close()\n",
                "\n",
                "    for r in rows:\n",
                "        print(f\"   - Action: {r[0]} | Old: {r[1]} -> New: {r[2]}\")\n",
                "\n",
                "# Run validation\n",
                "run_v1_6_validation()# SECTION D: Validation Tests (v1.6)\n",
                "\n",
                "def run_v1_6_validation():\n",
                "    brand_id_str = \"wh_india_001\"\n",
                "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
                "\n",
                "    approved_asset_id = None\n",
                "    approved_asset_text = None\n",
                "\n",
                "    print(\"\\n\\n--- üß™ TEST 1: Ingestion starts as 'inferred' ---\")\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    cur.execute(\n",
                "        \"SELECT count(*) FROM brand_assets WHERE brand_id = %s AND confidence = 'inferred'\",\n",
                "        (brand_uuid,)\n",
                "    )\n",
                "    count = cur.fetchone()[0]\n",
                "    cur.close()\n",
                "    conn.close()\n",
                "    print(f\"‚úÖ Found {count} 'inferred' assets\")\n",
                "\n",
                "    # -------------------------------------------------\n",
                "\n",
                "    print(\"\\n--- üß™ TEST 2: Retrieval Priority (Approved > Inferred) [brand_voice] ---\")\n",
                "\n",
                "    # üîé Find an inferred BRAND_VOICE asset via DB (robust)\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    cur.execute(\"\"\"\n",
                "        SELECT a.asset_id, a.raw_text\n",
                "        FROM brand_assets a\n",
                "        JOIN brand_chunks c ON a.asset_id = c.asset_id\n",
                "        WHERE a.brand_id = %s\n",
                "          AND a.confidence = 'inferred'\n",
                "          AND c.vector_type = 'brand_voice'\n",
                "        LIMIT 1\n",
                "    \"\"\", (brand_uuid,))\n",
                "    row = cur.fetchone()\n",
                "    cur.close()\n",
                "    conn.close()\n",
                "\n",
                "    if not row:\n",
                "        print(\"‚ö†Ô∏è No inferred brand_voice asset available. TEST 2 skipped (expected if already curated).\")\n",
                "    else:\n",
                "        approved_asset_id, approved_asset_text = row\n",
                "\n",
                "        print(f\"   üéØ Targeting Brand Voice Asset: {approved_asset_text[:40]}...\")\n",
                "\n",
                "        approve_asset(\n",
                "            approved_asset_id,\n",
                "            reviewer=\"Admin\",\n",
                "            notes=\"Approved brand voice memory (v1.6 validation)\"\n",
                "        )\n",
                "\n",
                "        res = retrieve_context(\n",
                "            brand_id_str,\n",
                "            \"design philosophy\",\n",
                "            \"brand_voice\"\n",
                "        )\n",
                "\n",
                "        if res and res[0][\"confidence\"] == \"approved\":\n",
                "            print(\"‚úÖ SUCCESS: Approved brand_voice asset correctly prioritized.\")\n",
                "        else:\n",
                "            print(\n",
                "                f\"‚ùå FAILURE: Expected approved asset first, got \"\n",
                "                f\"{res[0]['confidence'] if res else 'None'}\"\n",
                "            )\n",
                "\n",
                "    # -------------------------------------------------\n",
                "\n",
                "    print(\"\\n--- üß™ TEST 3: Deprecation (Exclude from Retrieval) ---\")\n",
                "\n",
                "    if approved_asset_id:\n",
                "        reject_asset(\n",
                "            approved_asset_id,\n",
                "            reviewer=\"Admin\",\n",
                "            notes=\"Deprecating for validation test\"\n",
                "        )\n",
                "\n",
                "        res = retrieve_context(\n",
                "            brand_id_str,\n",
                "            \"design philosophy\",\n",
                "            \"brand_voice\"\n",
                "        )\n",
                "\n",
                "        found = any(\n",
                "            d[\"content\"] == approved_asset_text\n",
                "            for d in res\n",
                "        )\n",
                "\n",
                "        if not found:\n",
                "            print(\"‚úÖ Deprecated asset successfully EXCLUDED.\")\n",
                "        else:\n",
                "            print(\"‚ùå FAILURE: Deprecated asset still retrieved!\")\n",
                "    else:\n",
                "        print(\"‚ö†Ô∏è Skipping TEST 3: No approved asset available.\")\n",
                "\n",
                "    # -------------------------------------------------\n",
                "\n",
                "    print(\"\\n--- üß™ TEST 4: Audit Trail ---\")\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    cur.execute(\"\"\"\n",
                "        SELECT action, previous_confidence, new_confidence\n",
                "        FROM memory_reviews\n",
                "        ORDER BY created_at DESC\n",
                "        LIMIT 5\n",
                "    \"\"\")\n",
                "    rows = cur.fetchall()\n",
                "    cur.close()\n",
                "    conn.close()\n",
                "\n",
                "    for r in rows:\n",
                "        print(f\"   - Action: {r[0]} | Old: {r[1]} -> New: {r[2]}\")\n",
                "\n",
                "# Run validation\n",
                "run_v1_6_validation()\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "babf71fa",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "94505d3c",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "id": "712529f2",
            "metadata": {},
            "source": [
                "## **Section F: Brand Brain v1.7 - Read-Only Chat & Explainability**\n",
                "\n",
                "This section implements the **Read-Only Chat Playground** with **Explainability**.\n",
                "It focuses on safe, natural interaction without persistent memory mutation.\n",
                "\n",
                "**Core Features:**\n",
                "1.  **Hybrid Intent Classification** (Rules + Gemini)\n",
                "2.  **Brand Reasoner** (Gemini-2.5-Flash with Strict System Prompt)\n",
                "3.  **Chat Pipeline** (Intent -> Retrieval -> Safety -> Reasoner)\n",
                "4.  **Zero-Mutation Guarantee**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "59ba77bf",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Hybrid Intent Classifier Ready\n"
                    ]
                }
            ],
            "source": [
                "# 1. Hybrid Intent Classification\n",
                "\n",
                "import re\n",
                "from enum import Enum\n",
                "import json\n",
                "\n",
                "class IntentType(Enum):\n",
                "    KNOWLEDGE = \"knowledge\"    # Allow\n",
                "    REASONING = \"reasoning\"    # Allow\n",
                "    CREATIVE = \"creative\"      # Block\n",
                "\n",
                "# Regex for Obvious Creative Intents (Rule-Based First)\n",
                "CREATIVE_PATTERNS = [\n",
                "    r\"create\", r\"write\", r\"generate\", r\"design\", r\"make me a\", r\"draft\", \n",
                "    r\"slogan\", r\"logo\", r\"ad copy\", r\"campaign\"\n",
                "]\n",
                "\n",
                "def classify_intent_hybrid(query: str) -> IntentType:\n",
                "    # 1. Rule-Based Check\n",
                "    query_lower = query.lower()\n",
                "    for pattern in CREATIVE_PATTERNS:\n",
                "        if re.search(pattern, query_lower):\n",
                "            print(f\"   üõ°Ô∏è Rule-Based Intent Detection: CREATIVE (Blocked pattern: '{pattern}')\")\n",
                "            return IntentType.CREATIVE\n",
                "            \n",
                "    # 2. Gemini Fallback for Ambiguity\n",
                "    prompt = f\"\"\"\n",
                "    Classify the following query into one of 3 categories:\n",
                "    1. KNOWLEDGE (Questions about facts, brand voice, mission, identity)\n",
                "    2. REASONING (Questions asking for validation, 'is this on-brand?', 'why?')\n",
                "    3. CREATIVE (Requests to create, write, generate, design new assets)\n",
                "    \n",
                "    QUERY: {query}\n",
                "    \n",
                "    RETURN ONLY ONE WORD: KNOWLEDGE, REASONING, or CREATIVE.\n",
                "    \"\"\"\n",
                "    \n",
                "    try:\n",
                "        response = client.models.generate_content(\n",
                "            model=\"gemini-2.5-flash\",\n",
                "            contents=prompt\n",
                "        )\n",
                "        result = response.text.strip().upper()\n",
                "        if \"CREATIVE\" in result: return IntentType.CREATIVE\n",
                "        if \"REASONING\" in result: return IntentType.REASONING\n",
                "        return IntentType.KNOWLEDGE\n",
                "    except Exception as e:\n",
                "        print(f\"   ‚ö†Ô∏è Intent Classification Failed: {e}. Defaulting to KNOWLEDGE.\")\n",
                "        return IntentType.KNOWLEDGE\n",
                "\n",
                "print(\"‚úÖ Hybrid Intent Classifier Ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "7db42a03",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Brand Reasoner Ready\n"
                    ]
                }
            ],
            "source": [
                "# 2. Brand Reasoner & Explainability\n",
                "\n",
                "SYSTEM_PROMPT = \"\"\"\n",
                "You are Brand Brain, a read-only brand intelligence system.\n",
                "\n",
                "Your role is to explain, summarize, and reason about a brand using only the context provided to you.\n",
                "\n",
                "You must strictly follow these rules:\n",
                "‚Ä¢ You do **not** invent facts\n",
                "‚Ä¢ You do **not** create new brand assets\n",
                "‚Ä¢ You do **not** generate creative content\n",
                "‚Ä¢ You do **not** speculate beyond provided or grounded information\n",
                "\n",
                "You may:\n",
                "‚Ä¢ Explain brand identity, voice, values, and positioning\n",
                "‚Ä¢ Answer factual questions about the brand\n",
                "‚Ä¢ Justify whether ideas or messaging align with the brand\n",
                "‚Ä¢ Politely refuse creative or unsafe requests\n",
                "\n",
                "If a request asks you to create campaigns, copy, slogans, or visuals:\n",
                "‚Ä¢ Respond with a polite refusal\n",
                "‚Ä¢ Explain that you can evaluate or explain brand guidelines instead\n",
                "\n",
                "If information is uncertain:\n",
                "‚Ä¢ State the uncertainty clearly\n",
                "‚Ä¢ Do not guess\n",
                "\n",
                "Your tone must be:\n",
                "‚Ä¢ Clear\n",
                "‚Ä¢ Calm\n",
                "‚Ä¢ Professional\n",
                "‚Ä¢ Brand-aligned\n",
                "\n",
                "You exist to **protect and explain the brand**, not to create on its behalf.\n",
                "\"\"\"\n",
                "\n",
                "def generate_explained_response(query: str, context: List[Dict], safety_status: Dict, intent: IntentType) -> Dict:\n",
                "    # Build System Context\n",
                "    context_str = \"\\n\".join([f\"- {c['content']} (Confidence: {c.get('confidence', 'inferred')})\" for c in context])\n",
                "    \n",
                "    full_prompt = f\"\"\"\n",
                "    {SYSTEM_PROMPT}\n",
                "    \n",
                "    CONTEXT (Brand Memory):\n",
                "    {context_str}\n",
                "    \n",
                "    USER QUERY: {query}\n",
                "    \n",
                "    Explain your answer based *only* on the context above.\n",
                "    \"\"\"\n",
                "    \n",
                "    try:\n",
                "        response = client.models.generate_content(\n",
                "            model=\"gemini-2.5-flash\",\n",
                "            contents=full_prompt,\n",
                "            config=types.GenerateContentConfig(\n",
                "                temperature=0.3 # Low temp for strict adherence\n",
                "            )\n",
                "        )\n",
                "        answer_text = response.text\n",
                "    except Exception as e:\n",
                "        answer_text = f\"Error generating response: {e}\"\n",
                "\n",
                "    # Construct Explainability Object\n",
                "    return {\n",
                "        \"answer\": answer_text,\n",
                "        \"confidence_level\": \"high\" if context else \"medium\", # Simplified\n",
                "        \"brand_elements_used\": list(set([c.get('source_field', 'General') for c in context])) if isinstance(context, list) else [], # Placeholder logic\n",
                "        \"memory_sources\": list(set([c.get('confidence', 'inferred') for c in context])),\n",
                "        \"live_context_used\": False, # v1.7 defaults\n",
                "        \"safety_status\": safety_status['status']\n",
                "    }\n",
                "\n",
                "print(\"‚úÖ Brand Reasoner Ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "b349b481",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Chat Pipeline Ready\n"
                    ]
                }
            ],
            "source": [
                "# 3. Chat Pipeline (Strict Ordering)\n",
                "\n",
                "def chat_session(user_query: str, brand_id: str = \"wh_india_001\"):\n",
                "    print(f\"\\nüí¨ User: {user_query}\")\n",
                "    \n",
                "    # 1. Intent Classification (Hybrid)\n",
                "    intent = classify_intent_hybrid(user_query)\n",
                "    print(f\"   üß† Intent: {intent.value}\")\n",
                "    \n",
                "    # 2. Creative Block (Pre-computation)\n",
                "    if intent == IntentType.CREATIVE:\n",
                "        print(\"   üö´ Creative Request Blocked.\")\n",
                "        return {\n",
                "            \"answer\": \"I can explain brand guidelines and evaluate ideas, but I don‚Äôt generate creative assets yet.\",\n",
                "            \"safety_status\": \"BLOCKED_CREATIVE\"\n",
                "        }\n",
                "\n",
                "    # 3. Retrieval\n",
                "    # Using v1.6 retrieval (prioritizes approved)\n",
                "    context = retrieve_context(brand_id, user_query, vector_type=\"brand_voice\" if intent == IntentType.REASONING else \"strategy\")\n",
                "    \n",
                "    # 4. Safety Check (Off-Brand Rules) - BEFORE Reasoner\n",
                "    safety = check_brand_safety(user_query, brand_id, \"explain_brand\") # Using generic intent for safety check\n",
                "    \n",
                "    if safety['status'] == 'FAIL':\n",
                "        print(f\"   üõ°Ô∏è Safety Block: {safety['reason']}\")\n",
                "        return {\n",
                "            \"answer\": f\"I cannot answer that. {safety['reason']}\",\n",
                "            \"safety_status\": \"BLOCKED_SAFETY\"\n",
                "        }\n",
                "        \n",
                "    # 5. Brand Reasoner\n",
                "    response_obj = generate_explained_response(user_query, context, safety, intent)\n",
                "    \n",
                "    print(f\"   ü§ñ Brand Brain: {response_obj['answer'][:100]}...\")\n",
                "    return response_obj\n",
                "\n",
                "print(\"‚úÖ Chat Pipeline Ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "c5834bd0",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "--- üß™ v1.7 Validation Suite ---\n",
                        "üìä DB Before: Assets=36, Chunks=78\n",
                        "\n",
                        "--- Testing: 'What are our brand colors?' (Expected: KNOWLEDGE) ---\n",
                        "\n",
                        "üí¨ User: What are our brand colors?\n",
                        "   üß† Intent: knowledge\n",
                        "\n",
                        "üîé [v1.6] Querying Brand wh_india_001 (UUID: 25ecf8da-150a-506d-aef6-7b2794b4b114) [strategy]: 'What are our brand colors?'\n",
                        "   [1] [INFERRED] Score: 0.6760 | Content: . The brand identity maintains uniformity through six key elements: the Circle W Logo Mark, Primary ...\n",
                        "   [2] [INFERRED] Score: 0.6628 | Content: . A custom font, Westinghouse Sans, has been developed with characters inspired by the original logo...\n",
                        "   [3] [INFERRED] Score: 0.6543 | Content: . Design principles emphasize uniformity in brand usage, including the 'Circle W Logo Mark,' specifi...\n",
                        "   ü§ñ Brand Brain: Based on the provided context, the brand colors are Westinghouse blue, white, and black. These are t...\n",
                        "   üìÑ Result: {\n",
                        "  \"answer\": \"Based on the provided context, the brand colors are Westinghouse blue, white, and black. These are the only acceptable colors for logos and identity elements, ensuring uniformity in brand usage.\",\n",
                        "  \"confidence_level\": \"high\",\n",
                        "  \"brand_elements_used\": [\n",
                        "    \"General\"\n",
                        "  ],\n",
                        "  \"memory_sources\": [\n",
                        "    \"inferred\"\n",
                        "  ],\n",
                        "  \"live_context_used\": false,\n",
                        "  \"safety_status\": \"PASS\"\n",
                        "}\n",
                        "\n",
                        "--- Testing: 'Is 'buy now, cheap price' on-brand?' (Expected: REASONING) ---\n",
                        "\n",
                        "üí¨ User: Is 'buy now, cheap price' on-brand?\n",
                        "   üß† Intent: reasoning\n",
                        "\n",
                        "üîé [v1.6] Querying Brand wh_india_001 (UUID: 25ecf8da-150a-506d-aef6-7b2794b4b114) [brand_voice]: 'Is 'buy now, cheap price' on-brand?'\n",
                        "   [1] [APPROVED] Score: 0.6431 | Content: Confident & Reassuring. Premium yet Approachable. Clear & Functional. Trust-First. Design-Conscious....\n",
                        "   [2] [APPROVED] Score: 0.6289 | Content: Design-forward minimalism. Product as hero. Lifestyle-led context. Retro-modern blend. Premium finis...\n",
                        "   üõ°Ô∏è Safety Block: Forbidden keywords detected: ['cheap']\n",
                        "   üìÑ Result: {\n",
                        "  \"answer\": \"I cannot answer that. Forbidden keywords detected: ['cheap']\",\n",
                        "  \"safety_status\": \"BLOCKED_SAFETY\"\n",
                        "}\n",
                        "\n",
                        "--- Testing: 'Write a slogan for a summer sale' (Expected: CREATIVE) ---\n",
                        "\n",
                        "üí¨ User: Write a slogan for a summer sale\n",
                        "   üõ°Ô∏è Rule-Based Intent Detection: CREATIVE (Blocked pattern: 'write')\n",
                        "   üß† Intent: creative\n",
                        "   üö´ Creative Request Blocked.\n",
                        "   üìÑ Result: {\n",
                        "  \"answer\": \"I can explain brand guidelines and evaluate ideas, but I don\\u2019t generate creative assets yet.\",\n",
                        "  \"safety_status\": \"BLOCKED_CREATIVE\"\n",
                        "}\n",
                        "\n",
                        "üìä DB After: Assets=36, Chunks=78\n",
                        "‚úÖ SUCCESS: Zero DB Mutation Confirmed.\n"
                    ]
                }
            ],
            "source": [
                "# 4. v1.7 Validation Harness & DB Snapshot\n",
                "\n",
                "def get_db_counts():\n",
                "    conn = get_db_connection()\n",
                "    cur = conn.cursor()\n",
                "    cur.execute(\"SELECT count(*) FROM brand_assets\")\n",
                "    assets = cur.fetchone()[0]\n",
                "    cur.execute(\"SELECT count(*) FROM brand_chunks\")\n",
                "    chunks = cur.fetchone()[0]\n",
                "    cur.close()\n",
                "    conn.close()\n",
                "    return assets, chunks\n",
                "\n",
                "def run_v1_7_validation():\n",
                "    print(\"\\n\\n--- üß™ v1.7 Validation Suite ---\")\n",
                "    \n",
                "    # 1. Snapshot DB\n",
                "    assets_before, chunks_before = get_db_counts()\n",
                "    print(f\"üìä DB Before: Assets={assets_before}, Chunks={chunks_before}\")\n",
                "        \n",
                "    # 2. Test Cases\n",
                "    queries = [\n",
                "        (\"What are our brand colors?\", \"KNOWLEDGE\"),\n",
                "        (\"Is 'buy now, cheap price' on-brand?\", \"REASONING\"), # Should trigger reasoning or safety\n",
                "        (\"Write a slogan for a summer sale\", \"CREATIVE\") # Should be blocked\n",
                "    ]\n",
                "    \n",
                "    for q, expected in queries:\n",
                "        print(f\"\\n--- Testing: '{q}' (Expected: {expected}) ---\")\n",
                "        res = chat_session(q)\n",
                "        print(f\"   üìÑ Result: {json.dumps(res, indent=2)}\")\n",
                "\n",
                "    # 3. Verify Mutation\n",
                "    assets_after, chunks_after = get_db_counts()\n",
                "    print(f\"\\nüìä DB After: Assets={assets_after}, Chunks={chunks_after}\")\n",
                "    \n",
                "    if assets_before == assets_after and chunks_before == chunks_after:\n",
                "        print(\"‚úÖ SUCCESS: Zero DB Mutation Confirmed.\")\n",
                "    else:\n",
                "        print(\"‚ùå FAILURE: DB Mutation Detected!\")\n",
                "\n",
                "run_v1_7_validation()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2fd484d3",
            "metadata": {},
            "source": [
                "## **Brand Brain Interactive Chat (v1.7)**\n",
                "\n",
                "This section enables a **read-only, user-friendly chat interface** for Brand Brain.\n",
                "\n",
                "### Features\n",
                "- Natural language interaction\n",
                "- Automatic Gemini API key rotation on quota errors\n",
                "- Explainable, brand-safe responses\n",
                "- Zero database mutation (read-only guarantee)\n",
                "\n",
                "### Usage\n",
                "Run `ask_brand_brain()` and start chatting.\n",
                "Type `exit` to stop the session.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "2c5995ba",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from itertools import cycle\n",
                "from google import genai\n",
                "from google.genai import types\n",
                "from IPython.display import display, Markdown\n",
                "\n",
                "\n",
                "# Load API keys from environment\n",
                "GEMINI_KEYS = [\n",
                "    os.getenv(\"GEMINI_API_KEY1\"),\n",
                "    os.getenv(\"GEMINI_API_KEY2\"),\n",
                "    os.getenv(\"GEMINI_API_KEY3\"),\n",
                "    os.getenv(\"GEMINI_API_KEY4\")\n",
                "]\n",
                "\n",
                "# Filter out missing keys\n",
                "GEMINI_KEYS = [k for k in GEMINI_KEYS if k]\n",
                "\n",
                "if not GEMINI_KEYS:\n",
                "    raise RuntimeError(\"‚ùå No Gemini API keys found in environment variables.\")\n",
                "\n",
                "# Create a rotating iterator\n",
                "_gemini_key_cycle = cycle(GEMINI_KEYS)\n",
                "\n",
                "def get_gemini_client():\n",
                "    \"\"\"\n",
                "    Returns a Gemini client using the next available API key.\n",
                "    \"\"\"\n",
                "    api_key = next(_gemini_key_cycle)\n",
                "    return genai.Client(api_key=api_key)\n",
                "\n",
                "# Safe Gemini Call Wrapper (Auto-Retry)\n",
                "def safe_generate_content(model: str, contents, config=None, max_retries=4):\n",
                "    \"\"\"\n",
                "    Safely call Gemini with automatic API key rotation on failure.\n",
                "    \"\"\"\n",
                "    last_error = None\n",
                "\n",
                "    for attempt in range(max_retries):\n",
                "        try:\n",
                "            client = get_gemini_client()\n",
                "            return client.models.generate_content(\n",
                "                model=model,\n",
                "                contents=contents,\n",
                "                config=config\n",
                "            )\n",
                "        except Exception as e:\n",
                "            last_error = e\n",
                "            print(f\"‚ö†Ô∏è Gemini call failed (attempt {attempt+1}/{max_retries}): {e}\")\n",
                "    \n",
                "    raise RuntimeError(f\"‚ùå All Gemini API keys exhausted. Last error: {last_error}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "8056966f",
            "metadata": {},
            "outputs": [],
            "source": [
                "def render_brand_brain_response(response: dict):\n",
                "    \"\"\"\n",
                "    Human-friendly rendering of Brand Brain output.\n",
                "    \"\"\"\n",
                "\n",
                "    display(Markdown(\"### ü§ñ Brand Brain\"))\n",
                "    display(Markdown(response.get(\"answer\", \"_No response generated._\")))\n",
                "\n",
                "    confidence = response.get(\"confidence_level\", \"unknown\")\n",
                "    confidence_badge = {\n",
                "        \"high\": \"üü¢ **High confidence** (Approved brand memory)\",\n",
                "        \"medium\": \"üü° **Medium confidence** (Inferred brand memory)\",\n",
                "        \"live\": \"üîµ **Live context used**\"\n",
                "    }.get(confidence, \"‚ö™ Confidence unknown\")\n",
                "\n",
                "    display(Markdown(f\"**Confidence:** {confidence_badge}\"))\n",
                "\n",
                "    display(Markdown(\"---\"))\n",
                "    display(Markdown(\"#### üîç Explainability\"))\n",
                "\n",
                "    display(Markdown(f\"- **Brand elements used:** {', '.join(response.get('brand_elements_used', [])) or 'N/A'}\"))\n",
                "    display(Markdown(f\"- **Memory sources:** {', '.join(response.get('memory_sources', [])) or 'N/A'}\"))\n",
                "    display(Markdown(f\"- **Safety status:** `{response.get('safety_status', 'UNKNOWN')}`\"))\n",
                "\n",
                "\n",
                "def ask_brand_brain():\n",
                "    \"\"\"\n",
                "    Interactive Brand Brain chat (read-only).\n",
                "    \"\"\"\n",
                "    print(\"\\nüí¨ Ask Brand Brain (type 'exit' to stop)\\n\")\n",
                "\n",
                "    while True:\n",
                "        user_query = input(\"You: \").strip()\n",
                "\n",
                "        if user_query.lower() in [\"exit\", \"quit\"]:\n",
                "            print(\"üëã Exiting Brand Brain chat.\")\n",
                "            break\n",
                "\n",
                "        if not user_query:\n",
                "            print(\"‚ö†Ô∏è Please enter a question.\")\n",
                "            continue\n",
                "\n",
                "        try:\n",
                "            response = chat_session(user_query)\n",
                "            render_brand_brain_response(response)\n",
                "        except Exception as e:\n",
                "            print(f\"‚ùå Error: {e}\")\n",
                "\n",
                "        print(\"\\n\" + \"=\" * 60 + \"\\n\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "id": "ad966794",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "üí¨ Ask Brand Brain (type 'exit' to stop)\n",
                        "\n",
                        "\n",
                        "üí¨ User: What is our mission and vision?\n",
                        "   üß† Intent: knowledge\n",
                        "\n",
                        "üîé [v1.6] Querying Brand wh_india_001 (UUID: 25ecf8da-150a-506d-aef6-7b2794b4b114) [strategy]: 'What is our mission and vision?'\n",
                        "   [1] [INFERRED] Score: 0.6478 | Content: To enrich everyday living with reliable, thoughtfully engineered appliances that combine global heri...\n",
                        "   [2] [INFERRED] Score: 0.6478 | Content: To enrich everyday living with reliable, thoughtfully engineered appliances that combine global heri...\n",
                        "   [3] [INFERRED] Score: 0.6478 | Content: To enrich everyday living with reliable, thoughtfully engineered appliances that combine global heri...\n",
                        "   ü§ñ Brand Brain: Based on the provided context, the brand's core purpose is:\n",
                        "\n",
                        "\"To enrich everyday living with reliabl...\n"
                    ]
                },
                {
                    "data": {
                        "text/markdown": [
                            "### ü§ñ Brand Brain"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "Based on the provided context, the brand's core purpose is:\n",
                            "\n",
                            "\"To enrich everyday living with reliable, thoughtfully engineered appliances that combine global heritage, modern innovation, and timeless design‚Äîdelivering confidence, comfort, and consistency to Indian homes.\"\n",
                            "\n",
                            "The context also notes that \"Confidence\" is an inferred value from this statement."
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "**Confidence:** üü¢ **High confidence** (Approved brand memory)"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "---"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "#### üîç Explainability"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "- **Brand elements used:** General"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "- **Memory sources:** inferred"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "- **Safety status:** `PASS`"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "============================================================\n",
                        "\n",
                        "\n",
                        "üí¨ User: What colors and fonts define our brand?\n",
                        "   üß† Intent: knowledge\n",
                        "\n",
                        "üîé [v1.6] Querying Brand wh_india_001 (UUID: 25ecf8da-150a-506d-aef6-7b2794b4b114) [strategy]: 'What colors and fonts define our brand?'\n",
                        "   [1] [INFERRED] Score: 0.7011 | Content: . A custom font, Westinghouse Sans, has been developed with characters inspired by the original logo...\n",
                        "   [2] [INFERRED] Score: 0.6837 | Content: . The brand identity maintains uniformity through six key elements: the Circle W Logo Mark, Primary ...\n",
                        "   [3] [INFERRED] Score: 0.6750 | Content: . The brand maintains a consistent identity through specific elements such as the Circle W Logo Mark...\n",
                        "   ü§ñ Brand Brain: The colors that define the brand are Westinghouse blue, white, and black.\n",
                        "\n",
                        "The fonts that define the...\n"
                    ]
                },
                {
                    "data": {
                        "text/markdown": [
                            "### ü§ñ Brand Brain"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "The colors that define the brand are Westinghouse blue, white, and black.\n",
                            "\n",
                            "The fonts that define the brand are Westinghouse Sans and the Westinghouse Gothic Typeface."
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "**Confidence:** üü¢ **High confidence** (Approved brand memory)"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "---"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "#### üîç Explainability"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "- **Brand elements used:** General"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "- **Memory sources:** inferred"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "- **Safety status:** `PASS`"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "============================================================\n",
                        "\n",
                        "\n",
                        "üí¨ User: Is aggressive discounting on-brand?\n",
                        "   üß† Intent: reasoning\n",
                        "\n",
                        "üîé [v1.6] Querying Brand wh_india_001 (UUID: 25ecf8da-150a-506d-aef6-7b2794b4b114) [brand_voice]: 'Is aggressive discounting on-brand?'\n",
                        "   [1] [APPROVED] Score: 0.6025 | Content: Confident & Reassuring. Premium yet Approachable. Clear & Functional. Trust-First. Design-Conscious....\n",
                        "   [2] [APPROVED] Score: 0.6000 | Content: Design-forward minimalism. Product as hero. Lifestyle-led context. Retro-modern blend. Premium finis...\n",
                        "   üõ°Ô∏è Safety Block: Forbidden keywords detected: ['discount']\n"
                    ]
                },
                {
                    "data": {
                        "text/markdown": [
                            "### ü§ñ Brand Brain"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "I cannot answer that. Forbidden keywords detected: ['discount']"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "**Confidence:** ‚ö™ Confidence unknown"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "---"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "#### üîç Explainability"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "- **Brand elements used:** N/A"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "- **Memory sources:** N/A"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "- **Safety status:** `BLOCKED_SAFETY`"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "============================================================\n",
                        "\n",
                        "\n",
                        "üí¨ User: How should we sound on LinkedIn?\n",
                        "   üß† Intent: knowledge\n",
                        "\n",
                        "üîé [v1.6] Querying Brand wh_india_001 (UUID: 25ecf8da-150a-506d-aef6-7b2794b4b114) [strategy]: 'How should we sound on LinkedIn?'\n",
                        "   [1] [INFERRED] Score: 0.5835 | Content: . The brand aims to deliver solutions that are future-ready, based on its legacy of pioneering the f...\n",
                        "   [2] [INFERRED] Score: 0.5794 | Content: . The brand strives to improve everyday life with trustworthy innovation that brings people together...\n",
                        "   [3] [INFERRED] Score: 0.5777 | Content: . The brand aims to be a driving force in defining enjoyable and sustainable living, focusing on tra...\n",
                        "   ü§ñ Brand Brain: Based on the provided brand memory, on LinkedIn, the brand should sound:\n",
                        "\n",
                        "*   **Forward-looking and ...\n"
                    ]
                },
                {
                    "data": {
                        "text/markdown": [
                            "### ü§ñ Brand Brain"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "Based on the provided brand memory, on LinkedIn, the brand should sound:\n",
                            "\n",
                            "*   **Forward-looking and Visionary:** Emphasize its role in \"pioneering the future of power\" and delivering \"future-ready solutions,\" driven by a \"vision for a better future.\"\n",
                            "*   **Trustworthy and Reliable:** Highlight its \"legacy of quality\" and commitment to \"trustworthy innovation\" and \"reliable and high-performing home solutions.\"\n",
                            "*   **Impact-focused and Human-centric:** Communicate how it \"improves everyday life,\" \"brings people together for the moments that matter,\" and is \"transforming the human experience with technology\" for \"enjoyable and sustainable living.\"\n",
                            "*   **Authoritative and Pioneering:** Position itself as a \"driving force\" in its field.\n",
                            "\n",
                            "The overall tone should reflect a brand that is confident in its legacy, committed to innovation, and dedicated to positively transforming the human experience through technology and clean energy."
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "**Confidence:** üü¢ **High confidence** (Approved brand memory)"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "---"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "#### üîç Explainability"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "- **Brand elements used:** General"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "- **Memory sources:** inferred"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "- **Safety status:** `PASS`"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "============================================================\n",
                        "\n",
                        "\n",
                        "üí¨ User: Write a Diwali campaign\n",
                        "   üõ°Ô∏è Rule-Based Intent Detection: CREATIVE (Blocked pattern: 'write')\n",
                        "   üß† Intent: creative\n",
                        "   üö´ Creative Request Blocked.\n"
                    ]
                },
                {
                    "data": {
                        "text/markdown": [
                            "### ü§ñ Brand Brain"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "I can explain brand guidelines and evaluate ideas, but I don‚Äôt generate creative assets yet."
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "**Confidence:** ‚ö™ Confidence unknown"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "---"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "#### üîç Explainability"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "- **Brand elements used:** N/A"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "- **Memory sources:** N/A"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "- **Safety status:** `BLOCKED_CREATIVE`"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "============================================================\n",
                        "\n",
                        "üëã Exiting Brand Brain chat.\n"
                    ]
                }
            ],
            "source": [
                "ask_brand_brain()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.3"
        },
        "nbformat": 4,
        "nbformat_minor": 2
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
