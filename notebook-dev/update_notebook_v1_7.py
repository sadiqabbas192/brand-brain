import json
import os

NOTEBOOK_PATH = r"d:\brand-brain\brand_brain_v1.7.ipynb"

def update_notebook():
    with open(NOTEBOOK_PATH, 'r', encoding='utf-8') as f:
        nb = json.load(f)

    cells_by_id = {cell.get('id'): cell for cell in nb['cells']}

    # 1. Update check_brand_safety (Cell ID: a7312ee2)
    new_source_a7312ee2 = [
        "# SECTION B: Off-Brand Rule Engine (Deterministic)\n",
        "\n",
        "# [v1.7 Update] Allow generic intents or IntentType\n",
        "from typing import Any\n",
        "\n",
        "ALLOWED_INTENTS = {\"explain_brand\", \"validate_copy\", \"justify_decision\", \"minimal_rewrite\"}\n",
        "FORBIDDEN_KEYWORDS = {\"cheap\", \"free\", \"lowest price\", \"clearance\", \"sale\", \"loud\"} # removed discount\n",
        "\n",
        "def calculate_brand_centroid(brand_id: str, org_id: str, top_n=5) -> List[float]:\n",
        "    \"\"\"\n",
        "    Calculates deterministic centroid from top-N 'brand_voice' chunks.\n",
        "    In a real system, this is pre-computed. Here we fetch via a 'neutral' query.\n",
        "    \"\"\"\n",
        "    idx = pc.Index(\"brand-brain-index\")\n",
        "    namespace = f\"{org_id}:{brand_id}:brand_voice\"\n",
        "    \n",
        "    # Deterministic query to fetch representative chunks\n",
        "    # We use a static string that represents the ideal voice to find core chunks\n",
        "    query_vec = generate_embedding(\"brand voice tone philosophy identity\")\n",
        "    \n",
        "    results = idx.query(\n",
        "        vector=query_vec,\n",
        "        top_k=top_n,\n",
        "        namespace=namespace,\n",
        "        include_values=True\n",
        "    )\n",
        "    \n",
        "    vectors = []\n",
        "    if results['matches']:\n",
        "         for m in results['matches']:\n",
        "             if m.get('values'):\n",
        "                 vectors.append(m['values'])\n",
        "             \n",
        "    if not vectors:\n",
        "        return []\n",
        "    \n",
        "    return np.mean(vectors, axis=0).tolist()\n",
        "\n",
        "def check_brand_safety(user_query: str, brand_id_str: str, intent: Any) -> Dict:\n",
        "    # 1. Intent Check\n",
        "    # [v1.7 Update] Allow IntentType enums or legacy strings\n",
        "    intent_val = intent.value if hasattr(intent, 'value') else intent\n",
        "    \n",
        "    # 2. Keyword Check\n",
        "    query_lower = user_query.lower()\n",
        "    violated_keywords = [kw for kw in FORBIDDEN_KEYWORDS if kw in query_lower]\n",
        "    \n",
        "    if violated_keywords:\n",
        "        # [v1.7 SOFT SAFETY]\n",
        "        # If intent is REASONING (or legacy 'justify_decision'), we Warn instead of Fail\n",
        "        if intent_val in [\"reasoning\", \"justify_decision\"] or (hasattr(IntentType, 'REASONING') and intent_val == IntentType.REASONING.value):\n",
        "             return {\n",
        "                 \"status\": \"PASS_WITH_WARNING\", \n",
        "                 \"warning_type\": \"brand_positioning_conflict\",\n",
        "                 \"reason\": f\"This idea conflicts with the brand‚Äôs premium positioning (Keywords: {violated_keywords}).\"\n",
        "             }\n",
        "        else:\n",
        "             # Creative or Knowledge requests with forbidden words still fail\n",
        "             return {\"status\": \"FAIL\", \"reason\": f\"Forbidden keywords detected: {violated_keywords}\"}\n",
        "    \n",
        "    # 3. Semantic Drift Check\n",
        "    # Setup IDs\n",
        "    brand_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, brand_id_str))\n",
        "    org_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, 'default_org'))\n",
        "    \n",
        "    centroid = calculate_brand_centroid(brand_uuid, org_id)\n",
        "    if not centroid:\n",
        "        return {\"status\": \"PASS\", \"reason\": \"No brand memory to validate against (Cold Start)\"}\n",
        "        \n",
        "    query_vec = generate_embedding(user_query)\n",
        "    similarity = np.dot(query_vec, centroid) / (np.linalg.norm(query_vec) * np.linalg.norm(centroid))\n",
        "    \n",
        "    if similarity < 0.4: \n",
        "         return {\"status\": \"FAIL\", \"reason\": f\"Semantic drift detected (Score: {similarity:.2f}). Query not aligned with Brand Voice.\"}\n",
        "\n",
        "    return {\"status\": \"PASS\", \"reason\": \"All checks passed\"}\n",
        "\n",
        "print(\"‚úÖ Section B: Off-Brand Rule Engine Ready (Soft Safety Enabled)\")\n"
    ]
    
    if 'a7312ee2' in cells_by_id:
        cells_by_id['a7312ee2']['source'] = new_source_a7312ee2
    else:
        print("‚ö†Ô∏è Cell a7312ee2 not found!")

    # 2. Update generate_explained_response (Cell ID: 7db42a03)
    new_source_7db42a03 = [
        "# 2. Brand Reasoner & Explainability\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are Brand Brain, a read-only brand intelligence system.\n",
        "\n",
        "Your role is to explain, summarize, and reason about a brand using only the context provided to you.\n",
        "\n",
        "You must strictly follow these rules:\n",
        "‚Ä¢ You do **not** invent facts\n",
        "‚Ä¢ You do **not** create new brand assets\n",
        "‚Ä¢ You do **not** generate creative content\n",
        "‚Ä¢ You do **not** speculate beyond provided or grounded information\n",
        "\n",
        "You may:\n",
        "‚Ä¢ Explain brand identity, voice, values, and positioning\n",
        "‚Ä¢ Answer factual questions about the brand\n",
        "‚Ä¢ Justify whether ideas or messaging align with the brand\n",
        "‚Ä¢ Politely refuse creative or unsafe requests\n",
        "\n",
        "If a request asks you to create campaigns, copy, slogans, or visuals:\n",
        "‚Ä¢ Respond with a polite refusal\n",
        "‚Ä¢ Explain that you can evaluate or explain brand guidelines instead\n",
        "\n",
        "If information is uncertain:\n",
        "‚Ä¢ State the uncertainty clearly\n",
        "‚Ä¢ Do not guess\n",
        "\n",
        "Your tone must be:\n",
        "‚Ä¢ Clear\n",
        "‚Ä¢ Calm\n",
        "‚Ä¢ Professional\n",
        "‚Ä¢ Brand-aligned\n",
        "\n",
        "You exist to **protect and explain the brand**, not to create on its behalf.\n",
        "\"\"\"\n",
        "\n",
        "def generate_explained_response(query: str, context: List[Dict], safety_status: Dict, intent: IntentType) -> Dict:\n",
        "    # Build System Context\n",
        "    context_str = \"\\n\".join([f\"- {c['content']} (Confidence: {c.get('confidence', 'inferred')})\" for c in context])\n",
        "    \n",
        "    # [v1.7 SOFT SAFETY INJECTION]\n",
        "    safety_instruction = \"\"\n",
        "    if safety_status.get('status') == 'PASS_WITH_WARNING':\n",
        "        safety_instruction = f\"\"\"\n",
        "        ‚ö†Ô∏è IMPORTANT: The user's idea conflicts with brand positioning: {safety_status['reason']}\n",
        "        \n",
        "        YOUR TASK:\n",
        "        1. Explain WHY this idea conflicts with the brand (using the Context below).\n",
        "        2. Suggest a principle-based alternative that aligns with the brand.\n",
        "        3. Maintain a helpful, educational tone. Do NOT scold.\n",
        "        4. DO NOT generate the requested content/slogan/copy. Just explain the misalignment.\n",
        "        \"\"\"\n",
        "    \n",
        "    full_prompt = f\"\"\"\n",
        "    {SYSTEM_PROMPT}\n",
        "    \n",
        "    CONTEXT (Brand Memory):\n",
        "    {context_str}\n",
        "    \n",
        "    {safety_instruction}\n",
        "    \n",
        "    USER QUERY: {query}\n",
        "    \n",
        "    Explain your answer based *only* on the context above.\n",
        "    \"\"\"\n",
        "    \n",
        "    try:\n",
        "        response = client.models.generate_content(\n",
        "            model=\"gemini-2.5-flash\",\n",
        "            contents=full_prompt,\n",
        "            config=types.GenerateContentConfig(\n",
        "                temperature=0.3 # Low temp for strict adherence\n",
        "            )\n",
        "        )\n",
        "        answer_text = response.text\n",
        "    except Exception as e:\n",
        "        answer_text = f\"Error generating response: {e}\"\n",
        "\n",
        "    # Construct Explainability Object\n",
        "    return {\n",
        "        \"answer\": answer_text,\n",
        "        \"confidence_level\": \"high\" if context else \"medium\", \n",
        "        \"brand_elements_used\": list(set([c.get('source_field', 'General') for c in context])) if isinstance(context, list) else [],\n",
        "        \"memory_sources\": list(set([c.get('confidence', 'inferred') for c in context])),\n",
        "        \"live_context_used\": False,\n",
        "        \"safety_status\": safety_status['status']\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Brand Reasoner Ready (Soft Safety Enabled)\")\n"
    ]
    if '7db42a03' in cells_by_id:
        cells_by_id['7db42a03']['source'] = new_source_7db42a03
    else:
        print("‚ö†Ô∏è Cell 7db42a03 not found!")

    # 3. Update chat_session (Cell ID: b349b481)
    new_source_b349b481 = [
        "# 3. Chat Pipeline (Strict Ordering)\n",
        "\n",
        "def chat_session(user_query: str, brand_id: str = \"wh_india_001\"):\n",
        "    print(f\"\\nüí¨ User: {user_query}\")\n",
        "    \n",
        "    # 1. Intent Classification (Hybrid)\n",
        "    intent = classify_intent_hybrid(user_query)\n",
        "    print(f\"   üß† Intent: {intent.value}\")\n",
        "    \n",
        "    # 2. Creative Block (Pre-computation)\n",
        "    if intent == IntentType.CREATIVE:\n",
        "        # Double check: if it was rule-based, we already blocked. \n",
        "        # But if Gemini classified it as creative and we didn't catch usage of forbidden words yet...\n",
        "        # We'll block here. \n",
        "        print(\"   üö´ Creative Request Blocked.\")\n",
        "        return {\n",
        "            \"answer\": \"I can explain brand guidelines and evaluate ideas, but I don‚Äôt generate creative assets yet.\",\n",
        "            \"safety_status\": \"BLOCKED_CREATIVE\"\n",
        "        }\n",
        "\n",
        "    # 3. Retrieval\n",
        "    # Using v1.6 retrieval (prioritizes approved)\n",
        "    context = retrieve_context(brand_id, user_query, vector_type=\"brand_voice\" if intent == IntentType.REASONING else \"strategy\")\n",
        "    \n",
        "    # 4. Safety Check (Off-Brand Rules) - BEFORE Reasoner\n",
        "    # [v1.7] Pass actual intent (IntentType) to safety check\n",
        "    safety = check_brand_safety(user_query, brand_id, intent)\n",
        "    \n",
        "    if safety['status'] == 'FAIL':\n",
        "        print(f\"   üõ°Ô∏è Safety Block: {safety['reason']}\")\n",
        "        return {\n",
        "            \"answer\": f\"I cannot answer that. {safety['reason']}\",\n",
        "            \"safety_status\": \"BLOCKED_SAFETY\"\n",
        "        }\n",
        "    elif safety['status'] == 'PASS_WITH_WARNING':\n",
        "        print(f\"   ‚ö†Ô∏è Soft Safety Warning: {safety['reason']}\")\n",
        "        # Proceed to Reasoner, passing the warning\n",
        "        \n",
        "    # 5. Brand Reasoner\n",
        "    response_obj = generate_explained_response(user_query, context, safety, intent)\n",
        "    \n",
        "    print(f\"   ü§ñ Brand Brain: {response_obj['answer'][:100]}...\")\n",
        "    return response_obj\n",
        "\n",
        "print(\"‚úÖ Chat Pipeline Ready (Soft Safety Enabled)\")\n"
    ]
    if 'b349b481' in cells_by_id:
        cells_by_id['b349b481']['source'] = new_source_b349b481
    else:
        print("‚ö†Ô∏è Cell b349b481 not found!")

    # 4. Update run_v1_7_validation (Cell ID: c5834bd0)
    new_source_c5834bd0 = [
        "# 4. v1.7 Validation Harness & DB Snapshot\n",
        "\n",
        "def get_db_counts():\n",
        "    conn = get_db_connection()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\"SELECT count(*) FROM brand_assets\")\n",
        "    assets = cur.fetchone()[0]\n",
        "    cur.execute(\"SELECT count(*) FROM brand_chunks\")\n",
        "    chunks = cur.fetchone()[0]\n",
        "    cur.close()\n",
        "    conn.close()\n",
        "    return assets, chunks\n",
        "\n",
        "def run_v1_7_validation():\n",
        "    print(\"\\n\\n--- üß™ v1.7 Validation Suite (Soft Safety) ---\")\n",
        "    \n",
        "    # 1. Snapshot DB\n",
        "    assets_before, chunks_before = get_db_counts()\n",
        "    print(f\"üìä DB Before: Assets={assets_before}, Chunks={chunks_before}\")\n",
        "        \n",
        "    # 2. Test Cases\n",
        "    queries = [\n",
        "        (\"What are our brand colors?\", \"KNOWLEDGE\"),\n",
        "        (\"Is aggressive discounting on-brand?\", \"REASONING\"), # Should trigger Soft Safety (PASS_WITH_WARNING)\n",
        "        (\"Write a Diwali campaign\", \"CREATIVE\") # Should be blocked\n",
        "    ]\n",
        "    \n",
        "    for q, expected in queries:\n",
        "        print(f\"\\n--- Testing: '{q}' (Expected Intent/Flow: {expected}) ---\")\n",
        "        res = chat_session(q)\n",
        "        print(f\"   üìÑ Result: {json.dumps(res, indent=2)}\")\n",
        "\n",
        "    # 3. Verify Mutation\n",
        "    assets_after, chunks_after = get_db_counts()\n",
        "    print(f\"\\nüìä DB After: Assets={assets_after}, Chunks={chunks_after}\")\n",
        "    \n",
        "    if assets_before == assets_after and chunks_before == chunks_after:\n",
        "        print(\"‚úÖ SUCCESS: Zero DB Mutation Confirmed.\")\n",
        "    else:\n",
        "        print(\"‚ùå FAILURE: DB Mutation Detected!\")\n",
        "\n",
        "run_v1_7_validation()\n"
    ]
    if 'c5834bd0' in cells_by_id:
        cells_by_id['c5834bd0']['source'] = new_source_c5834bd0
    else:
        print("‚ö†Ô∏è Cell c5834bd0 not found!")


    # 5. Update render_brand_brain_response (Cell ID: 8056966f)
    new_source_8056966f = [
        "def render_brand_brain_response(response: dict):\n",
        "    \"\"\"\n",
        "    Human-friendly rendering of Brand Brain output.\n",
        "    \"\"\"\n",
        "\n",
        "    display(Markdown(\"### ü§ñ Brand Brain\"))\n",
        "    display(Markdown(response.get(\"answer\", \"_No response generated._\")))\n",
        "\n",
        "    confidence = response.get(\"confidence_level\", \"unknown\")\n",
        "    confidence_badge = {\n",
        "        \"high\": \"üü¢ **High confidence** (Approved brand memory)\",\n",
        "        \"medium\": \"üü° **Medium confidence** (Inferred brand memory)\",\n",
        "        \"live\": \"üîµ **Live context used**\"\n",
        "    }.get(confidence, \"‚ö™ Confidence unknown\")\n",
        "\n",
        "    display(Markdown(f\"**Confidence:** {confidence_badge}\"))\n",
        "\n",
        "    display(Markdown(\"---\"))\n",
        "    display(Markdown(\"#### üîç Explainability\"))\n",
        "\n",
        "    display(Markdown(f\"- **Brand elements used:** {', '.join(response.get('brand_elements_used', [])) or 'N/A'}\"))\n",
        "    display(Markdown(f\"- **Memory sources:** {', '.join(response.get('memory_sources', [])) or 'N/A'}\"))\n",
        "    \n",
        "    safety_status = response.get('safety_status', 'UNKNOWN')\n",
        "    if safety_status == 'PASS_WITH_WARNING':\n",
        "        safety_display = \"‚ö†Ô∏è **Soft Safety Warning** (Brand Conflict Explained)\"\n",
        "    else:\n",
        "        safety_display = f\"`{safety_status}`\"\n",
        "    \n",
        "    display(Markdown(f\"- **Safety status:** {safety_display}\"))\n",
        "\n",
        "\n",
        "def ask_brand_brain():\n",
        "    \"\"\"\n",
        "    Interactive Brand Brain chat (read-only).\n",
        "    \"\"\"\n",
        "    print(\"\\nüí¨ Ask Brand Brain (type 'exit' to stop)\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_query = input(\"You: \").strip()\n",
        "\n",
        "        if user_query.lower() in [\"exit\", \"quit\"]:\n",
        "            print(\"üëã Exiting Brand Brain chat.\")\n",
        "            break\n",
        "\n",
        "        if not user_query:\n",
        "            print(\"‚ö†Ô∏è Please enter a question.\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            response = chat_session(user_query)\n",
        "            render_brand_brain_response(response)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: {e}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60 + \"\\n\")\n"
    ]
    if '8056966f' in cells_by_id:
        cells_by_id['8056966f']['source'] = new_source_8056966f
    else:
        print("‚ö†Ô∏è Cell 8056966f not found!")

    with open(NOTEBOOK_PATH, 'w', encoding='utf-8') as f:
        json.dump(nb, f, indent=4)
    print("‚úÖ Notebook updated successfully.")

if __name__ == "__main__":
    update_notebook()
